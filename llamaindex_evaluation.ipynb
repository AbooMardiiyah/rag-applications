{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335e9c49-79dd-48c8-a186-20f5b9b94dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/openai/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from opensearch_interface import OpenSearchClient\n",
    "from preprocessing import Vectorizor\n",
    "from llama_index.evaluation import RetrieverEvaluator\n",
    "from llama_index.vector_stores import OpensearchVectorStore, OpensearchVectorClient\n",
    "from llama_index import VectorStoreIndex, StorageContext, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55cd99eb-a73d-47bc-a9fc-45ec26ad4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "387888ea-3a74-4550-9944-06d43423e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpensearchVectorClient stores text in this field by default\n",
    "text_field = \"content\"\n",
    "# OpensearchVectorClient stores embeddings in this field by default\n",
    "embedding_field = \"content_embedding\"\n",
    "sem_index = 'semantic-impact-theory-gte'\n",
    "# OpensearchVectorClient encapsulates logic for a\n",
    "# single opensearch index with vector search enabled\n",
    "client = OpensearchVectorClient(\n",
    "     \"http://localhost:9200\", sem_index, 768, embedding_field=embedding_field, text_field=text_field,\n",
    "     http_auth=('admin', 'admin'),\n",
    "     use_ssl = True,\n",
    "     verify_certs = False,\n",
    "     ssl_assert_hostname = False,\n",
    "     ssl_show_warn = False,\n",
    "     timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b2a8e9-68ba-4cbb-bd3b-f75cecd06279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/elastic/notebooks/vector_search_applications/data/paul_graham.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd62b2b-db04-413d-8eeb-92a6adfa6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./data/paul_graham/').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e050ffd-b0be-446d-9a62-7b804c83ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0baa7992-ab98-4963-905f-c7452e1d66b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents into nodes: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.11it/s]\n",
      "Generating embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:02<00:00,  7.81it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_store = OpensearchVectorStore(client)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# initialize an index using our sample data and the client we just created\n",
    "index = VectorStoreIndex.from_documents(documents=documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85195d3-229b-4063-86a7-b3cad60fffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576d1d58-7187-45f6-8962-1c67b55b6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever\n",
    ")\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db27877b-2f38-4398-ad5c-571a6a0a3acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [01:09<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_dataset = generate_question_context_pairs(nodes, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5c72f27-35f4-40b5-83f6-4ae9e4ec5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset.save_json(path='./data/qa_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31cd570-d225-45b3-b53a-7699e5d883b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_dataset = EmbeddingQAFinetuneDataset.from_json('./data/qa_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77629e26-d09a-453b-b406-406cd8a98a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id, sample_query = list(qa_dataset.queries.items())[10]\n",
    "sample_expected = qa_dataset.relevant_docs[sample_id]\n",
    "# sample_expected = qa_dataset.corpus[sample_expected[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17cce976-4049-47e6-ac34-fa165ee4a85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('09fbb4e2-6ee7-4ae5-9d63-480879df787f',\n",
       " \"In the context of the passage, what factors influenced the protagonist's decision to write their dissertation on applications of continuations instead of macros and embedded languages?\",\n",
       " ['6e8070a4-4c55-4d22-a1bc-09c32157a4e5'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id, sample_query, sample_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f63a9af4-5b6e-4006-bf03-7d534501adb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalEvalResult(query=\"In the context of the passage, what factors influenced the protagonist's decision to write their dissertation on applications of continuations instead of macros and embedded languages?\", expected_ids=['6e8070a4-4c55-4d22-a1bc-09c32157a4e5'], retrieved_ids=['1e811809-1b7d-45ee-a3f3-2bf93fb0ed0c', 'b33a0d1b-9a14-4cbd-a0ad-12ab298ea685', '2499e887-b272-41e3-8505-a7f7a0e01c26', '2420f677-0307-47b6-9de5-78feecd5d5e3', '76d9a861-2264-4433-a6f3-13b277ddeafb'], metric_dict={'mrr': RetrievalMetricResult(score=0.0, metadata={}), 'hit_rate': RetrievalMetricResult(score=0.0, metadata={})})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30f8f50f-5513-49ad-ab6d-0f07e3274593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET https://localhost:9200/_cat/indices?v=true [status:200 request:0.043s]\n",
      "health status index                              uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
      "yellow open   semantic-538-testrun               DjBPg6CdQwKbOGhJrI4YIQ   3   1        284            0      2.9mb          2.9mb\n",
      "yellow open   kw-impact-theory                   2MjMun4bQYOoeUpv5UsJxg   3   1      33164            0     29.4mb         29.4mb\n",
      "yellow open   security-auditlog-2023.10.10       rg-NByyNTvW0jEQQdYWdKA   1   1       1757            0      3.5mb          3.5mb\n",
      "yellow open   test-kw-index                      6EF4Q2xDT9Gz1wua5a2IpQ   3   1        158            0      5.6mb          5.6mb\n",
      "yellow open   security-auditlog-2023.10.11       OHTeNLijSHCkPzDXbzx7Gg   1   1       1731            0        2mb            2mb\n",
      "yellow open   kw-full                            uNhdaqbnRVuyJci_L1Om8Q   3   1       6678            0     12.1mb         12.1mb\n",
      "yellow open   paul-graham3                       -74ZPvxoSMmtCPSzAI9o1A   1   1         18            0    768.1kb        768.1kb\n",
      "yellow open   security-auditlog-2023.09.13       nL3pRS4ATEqIiNOxME2lyw   1   1          5            0     86.4kb         86.4kb\n",
      "yellow open   semantic-full                      ydvbifM0Rcu0DBz-rjCHzQ   3   1       6678            0     74.2mb         74.2mb\n",
      "yellow open   squad-stop-step                    cpt_h1HSTzW0ZlqccCLnHg   1   1          4            0      7.6kb          7.6kb\n",
      "green  open   .opendistro_security               _QeSqO4CQN2IU8VpE9hnPw   1   0         10            0     75.6kb         75.6kb\n",
      "yellow open   semantic-impact-theory             5khyvtPQRASCMmhZiQTcVw   3   1      33164            0    331.5mb        331.5mb\n",
      "yellow open   kw-538-testrun                     Wam6NsdMR7K5lE8N8ZBTRQ   3   1        284            0    351.4kb        351.4kb\n",
      "yellow open   .plugins-ml-config                 IEeXrm-DRiOMm2qzo7PbqA   1   1          1            0      3.9kb          3.9kb\n",
      "green  open   .opensearch-observability          nN299E0QS9OvsRh_UcbJVQ   1   0          0            0       208b           208b\n",
      "yellow open   security-auditlog-2023.10.09       I0hbU5STRB-qWh_rlnS7Kg   1   1         39            0     91.4kb         91.4kb\n",
      "yellow open   semantic-impact-theory-gte         HOfyQXRmQLaBYooeLgTcMg   3   1      42863            0      799mb          799mb\n",
      "yellow open   semantic-impact-theory-gte-doc-ids PFdAajMqTM2MB7M2dZcWSg   3   1      17849            0    350.5mb        350.5mb\n",
      "yellow open   security-auditlog-2023.09.14       bWmLtF8OS2CqnQDeR79UJA   1   1       1704            0      3.4mb          3.4mb\n",
      "yellow open   security-auditlog-2023.09.15       0pea11jyTr6f_26knTzndg   1   1       1704            0      3.4mb          3.4mb\n",
      "yellow open   security-auditlog-2023.09.16       uFK7MMx7QBikXU4nbkM7SQ   1   1        852            0      1.6mb          1.6mb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "osclient = OpenSearchClient()\n",
    "osclient.show_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797dffa-c046-4292-b27e-095022607cd9",
   "metadata": {},
   "source": [
    "### BM25 Retriever Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e6f7190-0bf0-4c84-86b3-b123da1f1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vectorizor(model_name_or_path='./models/gte-base/').model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29fbf860-119e-4d73-9611-bf158ce65b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'paul-graham3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c78e748-edd1-4fc7-8097-e5fa2bcb3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57a6ca76-5731-493e-9a99-8efef33a6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET https://localhost:9200/paul-graham3 [status:404 request:0.038s]\n",
      "PUT https://localhost:9200/paul-graham3 [status:200 request:0.174s]\n",
      "POST https://localhost:9200/paul-graham3/_refresh [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "client = OpensearchVectorClient(\"http://localhost:9200\", index, 1536, \n",
    "                                 embedding_field=embedding_field, text_field=text_field,\n",
    "                                 http_auth=('admin', 'admin'),\n",
    "                                 use_ssl = True,\n",
    "                                 verify_certs = False,\n",
    "                                 ssl_assert_hostname = False,\n",
    "                                 ssl_show_warn = False,\n",
    "                                 timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33010100-ae5a-46c8-8d19-f8b82741e347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET https://localhost:9200/paul*/_alias [status:200 request:0.004s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'paul-graham3': {'aliases': {}}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osclient.indices.get_alias('paul*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36fe9ed-fb1e-483b-8870-c016f8cc832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().handlers = []\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.retrievers import BM25Retriever\n",
    "from llama_index.indices.vector_store.retrievers.retriever import VectorIndexRetriever\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8227494e-3087-4604-b434-699316b354c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n",
    "service_context = ServiceContext.from_defaults(chunk_size=1024, llm=llm)\n",
    "nodes = service_context.node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a82b153-0a57-41e0-bcb4-44d474b4d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "# initialize vector store\n",
    "storage_context = StorageContext.from_defaults(vector_store=OpensearchVectorStore(client))\n",
    "# initialize an index using our sample data and the client we just created\n",
    "# new_index = VectorStoreIndex.from_documents(documents=documents, storage_context=storage_context, show_progress=True)\n",
    "storage_context.docstore.add_documents(nodes=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1413cb47-edb8-4e97-8d96-0f9e5145578e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET https://localhost:9200/paul-graham3 [status:200 request:0.002s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.115s]\n",
      "POST https://localhost:9200/paul-graham3/_refresh [status:200 request:0.015s]\n"
     ]
    }
   ],
   "source": [
    "new_index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f1527a0-1f50-4b65-abb8-b164c9cdc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = BM25Retriever.from_defaults(new_index, similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d5494ab-5060-42ea-9c93-18bde90fc102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 23755319-8812-4cf1-a60e-98fa57137179<br>**Similarity:** 0.0<br>**Text:** What I Worked On\n",
       "\n",
       "February 2021\n",
       "\n",
       "Before college the two main things I worked on, outside of schoo...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 4b6c25f5-dbb2-4a39-b849-ea65e2311140<br>**Similarity:** 0.0<br>**Text:** All you had to do was teach SHRDLU more words.\n",
       "\n",
       "There weren't any classes in AI at Cornell then, ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 070362e4-471d-4b48-8abf-fb9b0b76e8f7<br>**Similarity:** 0.0<br>**Text:** I was briefly tempted, but they were so slow by present standards; what was the point? No one els...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 591aaad2-89d0-4c1b-876b-041e2ab51275<br>**Similarity:** 0.0<br>**Text:** Now all I had to do was learn Italian.\n",
       "\n",
       "Only stranieri (foreigners) had to take this entrance exa...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** fcc3ae0a-56d4-4198-895f-c940c087ddd7<br>**Similarity:** 0.0<br>**Text:** I wanted to go back to RISD, but I was now broke and RISD was very expensive, so I decided to get...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_source_node\n",
    "\n",
    "# will retrieve all context from the author's life\n",
    "results = retriever.retrieve(\n",
    "    \"Roy\"\n",
    ")\n",
    "for node in results:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26d6248f-3a98-4f21-af1e-817bbd61ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import RetrieverTool\n",
    "\n",
    "vector_retriever = VectorIndexRetriever(new_index, similarity_top_k=5)\n",
    "\n",
    "retriever_tools = [\n",
    "    RetrieverTool.from_defaults(\n",
    "        retriever=vector_retriever,\n",
    "        description=\"Useful in most cases\",\n",
    "    ),\n",
    "    RetrieverTool.from_defaults(\n",
    "        retriever=retriever,\n",
    "        description=\"Useful if searching about specific information\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf5f7462-0c08-4e60-a5c5-83b23239a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import RouterRetriever\n",
    "\n",
    "retriever = RouterRetriever.from_defaults(\n",
    "    retriever_tools=retriever_tools,\n",
    "    service_context=service_context,\n",
    "    select_multi=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "02075861-32ed-4368-b2e5-9df9998d2faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 1: Searching for specific information.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** bf06330b-85ef-4b86-a710-6e93ee00d398<br>**Similarity:** 8.000460324747431<br>**Text:** That's not always why artists have a signature style, but it's usually why buyers pay a lot for s...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** fcc3ae0a-56d4-4198-895f-c940c087ddd7<br>**Similarity:** 7.60773078902128<br>**Text:** I wanted to go back to RISD, but I was now broke and RISD was very expensive, so I decided to get...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b42e9877-0dbc-4292-9d84-f60fd8635a3a<br>**Similarity:** 7.083600149727588<br>**Text:** (I still talk to alumni and to new startups working on things I'm interested in, but that only ta...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 070362e4-471d-4b48-8abf-fb9b0b76e8f7<br>**Similarity:** 6.885972725074988<br>**Text:** I was briefly tempted, but they were so slow by present standards; what was the point? No one els...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** eb8a0408-7664-4acb-b99a-f9f009d8a322<br>**Similarity:** 6.686594148227136<br>**Text:** So in the summer of 1995, after I submitted the camera-ready copy of ANSI Common Lisp to the publ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = retriever.retrieve(\n",
    "    \"How much did Roy pay for the painting on his wall?\"\n",
    ")\n",
    "for node in results:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef75c038-97dd-4203-98bf-e1665a32e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET https://localhost:9200/climate-report [status:404 request:0.039s]\n",
      "PUT https://localhost:9200/climate-report [status:200 request:0.218s]\n",
      "POST https://localhost:9200/climate-report/_refresh [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/IPCC_AR6_WGII_Chapter03.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "# initialize service context (set chunk size)\n",
    "# -- here, we set a smaller chunk size, to allow for more effective re-ranking\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(chunk_size=256, llm=llm)\n",
    "nodes = service_context.node_parser.get_nodes_from_documents(documents)\n",
    "client = OpensearchVectorClient(\"http://localhost:9200\", 'climate-report', 1536, \n",
    "                                 embedding_field=embedding_field, text_field=text_field,\n",
    "                                 http_auth=('admin', 'admin'),\n",
    "                                 use_ssl = True,\n",
    "                                 verify_certs = False,\n",
    "                                 ssl_assert_hostname = False,\n",
    "                                 ssl_show_warn = False,\n",
    "                                 timeout=30)\n",
    "storage_context = StorageContext.from_defaults(vector_store=OpensearchVectorStore(client))\n",
    "storage_context.docstore.add_documents(nodes=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c1f2f027-7f28-41f6-a66a-69b6527aaed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET https://localhost:9200/climate-report [status:200 request:0.003s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.121s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.055s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.047s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.051s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.051s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.051s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.053s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.048s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.062s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.048s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.046s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.053s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.051s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.054s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.055s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.053s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.054s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.056s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.056s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.055s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.051s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.048s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.052s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.051s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.048s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.048s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.059s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.049s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.048s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.055s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.050s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.051s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.046s]\n",
      "POST https://localhost:9200/_bulk [status:200 request:0.033s]\n",
      "POST https://localhost:9200/climate-report/_refresh [status:200 request:1.057s]\n"
     ]
    }
   ],
   "source": [
    "climate_index = VectorStoreIndex(nodes, storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6b4b8e32-c4c9-4a75-b725-a08e6ae1a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retireve the top 10 most similar nodes using embeddings\n",
    "vector_retriever = climate_index.as_retriever(similarity_top_k=10)\n",
    "\n",
    "# retireve the top 10 most similar nodes using bm25\n",
    "bm25_retriever = BM25Retriever.from_defaults(climate_index, similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "02b177ae-dc39-4512-9c35-bce233dccee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import BaseRetriever\n",
    "\n",
    "\n",
    "class HybridRetriever(BaseRetriever):\n",
    "    def __init__(self, vector_retriever, bm25_retriever):\n",
    "        self.vector_retriever = vector_retriever\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "\n",
    "    def _retrieve(self, query, **kwargs):\n",
    "        bm25_nodes = self.bm25_retriever.retrieve(query, **kwargs)\n",
    "        vector_nodes = self.vector_retriever.retrieve(query, **kwargs)\n",
    "\n",
    "        # combine the two lists of nodes\n",
    "        all_nodes = []\n",
    "        node_ids = set()\n",
    "        for n in bm25_nodes + vector_nodes:\n",
    "            if n.node.node_id not in node_ids:\n",
    "                all_nodes.append(n)\n",
    "                node_ids.add(n.node.node_id)\n",
    "        return all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e0ef3344-f77a-4c98-b9ea-683822b071a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "hybrid_retriever = HybridRetriever(vector_retriever, bm25_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9fba3a41-3bdd-4169-9b47-95e5c36ff977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST https://localhost:9200/climate-report/_search [status:200 request:0.009s]\n"
     ]
    }
   ],
   "source": [
    "res = hybrid_retriever.retrieve(\"What is the impact of climate change on the ocean?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b999da48-6ac6-411a-9335-3963ed4dfc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ‘observed impact’ indicates the total effect of all climate-induced drivers on a specific ecosystem service, using expert judgement based on summary statements \\nthroughout Section\\xa03.5.  Tick marks represent the presence of co-occurring drivers non-climate drivers that affect the service. No assessment indicates that not enough evidence is \\navailable to assess the direction of impact.\\nThis section builds on the SROCC assessment of the portfolio \\nof available solutions, their applicability and their effectiveness \\nin reducing climate-change-induced risks to ocean and coastal \\necosystems. Section\\xa0 3.6.2 assesses the set of planned adaptation \\nmeasures. Section\\xa0 3.6.3 assesses implementation of adaptation \\nsolutions and the enablers, barriers and limitations that affect their \\nfeasibility.'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xda\\x11\\x1f\\xf8>RtrM\\'J\\xa7\\x1a\\xa6\\xbadqB \\xa0\\xf7\\x0b\\t\\x19\\x8b\\xa1[\\xeb\\xb9\\x98\\xe9\\xd8\\x053\\x04\\x10R#\\x8f\\xad\\xcd,\\x1e\\xefk\\xf1\\x9e\"=\\xab\\xa4\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00']\n",
      "Bad pipe message: %s [b\"9\\xf2\\xc3\\xc3\\x16Y\\xd7r'jP\\xd7ww\\x90\\xf02\\xa4 \\xe8\\xf5\\x8f]\\x9e\\xfekF\\xd44\\x9a\\xa6\\x9eJ\\x17b]3/\\x8a\\x07\\xcd&\\xa9\\x1c\\xfd=h\\x10\\xc9!*\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\", b'\\x01\\x02']\n",
      "Bad pipe message: %s [b\"\\x9a\\xc9\\xd1\\xd7}\\x7f'\\x9c\\x1b\\x89\\xc4[b\\x00\\x0b\\xb7\\xa5#\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t1\", b'.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04', b'\\x03\\x06', b'\\x07\\x08']\n",
      "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
      "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b\"\\x9e\\xa7\\xe8\\xb9i\\xc4/)f6 &\\xda\\x9b\\xaaS\\x1d-\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\"]\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x0c\\x00\\x00\\t127.0.0.1']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\x00D?I\\xbed\\xa1#f^\\x8e\\x7f_\\x12<\\xea\\x0e\\x82\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c']\n",
      "Bad pipe message: %s [b'd~\\xa0\\xbf\\xaadlG\\x04E\\xb4\\xe3\\xbabxY\\xe0i\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08']\n",
      "Bad pipe message: %s [b'\\x94\\x1cQ\\xe4\\xbf\\x8e\\xf2\\x1da\\xd9\\x86\\xbd \\xfeR|\\x94R\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00']\n",
      "Bad pipe message: %s [b'\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08']\n",
      "Bad pipe message: %s [b'\\x8e\\xde)\\xe4\\xdd+\\xd4\\xfbg\\x9da\\x85a\\xd7]\\x82\\xcf\\xed\\x00\\x00']\n",
      "Bad pipe message: %s [b\"0\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\"]\n",
      "Bad pipe message: %s [b')2\\xb9*\\xb1\\xd0\\xf5\\xf1e\\x94\\xcf{\\x8d\\x9f\\xba\\x1c\\xfa\"\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0\\'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0', b'\\x15\\xc0\\x0b\\xc0\\x01']\n",
      "Bad pipe message: %s [b'W\\x16\\x0f!\\xa1\\xf9\\x97zZ;wu\\xa3\\x8e\\x0c4\\xad) %d/ct\\x0c\\x05g\\xe8\\xd9\\xa2O.']\n",
      "Bad pipe message: %s [b'\\xd4\\x1b\\xa3\\xf1\\xa5\\xc4c\\x1a\\x13\\x1bv\\x95N3T\\x01\\x0f\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 5\\x0cB\\xa3\\xd0\\x1e\\xb3\\x95\\xf6E?G\\xb9\\xed\\xcf\\xbc\\xae\\xb3O\\xa7\\xd5\\xdbh:>\\xd3i']\n",
      "Bad pipe message: %s [b'\\x96\\xe0\\x1aX,\\xe1!\\xef\\xf3t\\xc2\\xd0t\\x85\\xf5\\xf0\\xa6P\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$']\n",
      "Bad pipe message: %s [b\"\\xf8\\xf3\\xac\\x04TGtes\\xda\\xea\\xa2>UqW\\xe4\\x95\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\"]\n",
      "Bad pipe message: %s [b'\\xd8l1\\\\\\x07\\xe2\\xd3W\\x89wnlT\\xa4\\r\\xca*o\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0']\n",
      "Bad pipe message: %s [b'\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00']\n",
      "Bad pipe message: %s [b'\\xc8WJ\\x852\\xdb\\xe9.\\x9a\\x1d\\xd0v\\x87\\xe1lt\\xfeF\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b\"\\xc3\\x1a\\xb2w&\\xdb\\xb3c\\xa5\\x0c\\xc9\\xcbh%\\x83/\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\"]\n",
      "Bad pipe message: %s [b\"s\\xbdQ\\xd4\\xd8\\xc0'\\x1cz\\xee\\x11/B0\\x9b8\\xd9\\x9c\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\", b'\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06']\n"
     ]
    }
   ],
   "source": [
    "res[1].node.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acff84-3d69-4e40-be9d-1f94ec46c9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
