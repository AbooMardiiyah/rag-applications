{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9299e2fb-9f95-4690-b172-0d6e9b4952cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from opensearch_interface import OpenSearchClient\n",
    "from typing import List, Union\n",
    "import numpy as np\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e934fe6-53e2-4720-8583-ba93018393b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReRanker:\n",
    "    '''\n",
    "    Cross-Encoder models achieve higher performance than Bi-Encoders, \n",
    "    however, they do not scale well to large datasets. The lack of scalability\n",
    "    is due to the underlying cross-attention mechanism, which is computationally\n",
    "    expensive.  Thus a Bi-Encoder is best used for 1st-stage document retrieval and \n",
    "    a Cross-Encoder is used to re-rank the retrieved documents. \n",
    "\n",
    "    https://www.sbert.net/examples/applications/cross-encoder/README.html\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name: str='cross-encoder/ms-marco-MiniLM-L-6-v2', local_files: bool=False):\n",
    "        self.model_name = model_name\n",
    "        self.model = CrossEncoder(self.model_name, automodel_args={'local_files_only':local_files})\n",
    "        self.score_field = 'cross_score'\n",
    "\n",
    "    def _cross_encoder_score(self, \n",
    "                             results: List[dict], \n",
    "                             query: str, \n",
    "                             cross_score_key: str='cross-score',\n",
    "                             return_scores: bool=False\n",
    "                             ) -> Union[np.array, None]:\n",
    "        '''\n",
    "        Given a list of hits from a Retriever:\n",
    "            1. Scores hits by passing query and results through CrossEncoder model. \n",
    "            2. Adds cross-score key to hits dictionary. \n",
    "            3. If desired returns np.array of Cross Encoder scores.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        results: List[dict]\n",
    "            List of search results from OpenSearch client.\n",
    "        query: str\n",
    "            User query.\n",
    "        cross_score_key: str='cross-score'\n",
    "            Name of key/field that the new calculated cross encoder score will be associated with.\n",
    "        return_scores: bool=False\n",
    "            If True, returns a np.array of cross encoder scores. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Either returns a np.array of cross encoder scores if \"return_scores\" is True, otherwise\n",
    "        nothing is returned.  The primary purpose of this function is to update the \"results\" dict. \n",
    "        '''\n",
    "        \n",
    "        #build query/content list \n",
    "        #create a list of lists that contains the query and the content field of each result from \"results\"\n",
    "        #important the cross_input variable must be a list of lists\n",
    "        cross_input = None\n",
    "        \n",
    "        #get scores\n",
    "        #call self.model to get predicted scores on the cross_input\n",
    "        cross_scores = None\n",
    "\n",
    "        #enumerate through the results and update each dict with the cross_score_key arg as key and value as the new score:\n",
    "        #Example:\n",
    "             # {'cross-score' : 5.12345}\n",
    "        for i, result in enumerate(results):\n",
    "            None\n",
    "\n",
    "        if return_scores:\n",
    "            return cross_scores\n",
    "\n",
    "    def rerank(self, results: List[dict], query: str, top_k: int=10, threshold: float=None) -> List[dict]:\n",
    "        '''\n",
    "        Given a list of search results from OpenSearch client, results are scored with a Cross Encoder \n",
    "        and returned in sorted order by the cross_score field.  Threshold allows user to filter out \n",
    "        results that do not meet cross_score threshold value:\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        results: List[dict]\n",
    "            List of search results from OpenSearch client.\n",
    "        query: str\n",
    "            User query.\n",
    "        top_k: int=10\n",
    "            Number of reranked results to return\n",
    "        threshold: float=None\n",
    "            If None, top_k results will be returned.  \n",
    "            If float value is present, only results with a cross_score that meet or exceed the threshold\n",
    "            will be retuned.  If no results meet the threshold then top_k results will be returned. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List of reranked search results. \n",
    "        '''\n",
    "        # call the internal _cross_encoder_score function (it's ok that nothing is returned here)\n",
    "        # the results dictionary is being updated \n",
    "        None\n",
    "\n",
    "        #sort results by the new cross-score field\n",
    "        sorted_hits = None\n",
    "\n",
    "        #if user wants to set a threshold we need to account for that\n",
    "        if threshold or threshold == 0:\n",
    "\n",
    "            #filter sorted_hits by the threshold value\n",
    "            filtered_hits = None\n",
    "            \n",
    "            if not any(filtered_hits):\n",
    "                logger.warning(f'No hits above threshold {threshold}. Returning top {top_k} hits.')\n",
    "                return sorted_hits[:top_k]\n",
    "            return filtered_hits\n",
    "            \n",
    "        #if no threshold was set return top_k sorted_hits\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d905c45-88ce-49a6-8ff7-fb7ae5934fac",
   "metadata": {},
   "source": [
    "### Instantiate the ReRanker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a4bf326-c463-4f82-a7ef-3585d66c23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "952a99df-a089-4fd8-b76d-2294fe70777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index name\n",
    "index_name = 'impact-theory-minilm-196'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7819bf44-faac-437f-8599-a44bb9b40040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set query\n",
    "query = \"how do I change my life for good\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8f05d-1503-4bed-b795-58166745e436",
   "metadata": {},
   "source": [
    "### Test ReRanker class by conducting a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5655ea10-6812-46a5-8461-3ec58b6a31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new OpenSearch client\n",
    "osclient = OpenSearchClient('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "feb7e21c-d171-4096-9b13-4b156f625169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct hybrid search\n",
    "response = osclient.hybrid_search(query, index_name, index_name, kw_size=50, vec_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d26ee0cb-7c6e-4bde-9ade-0a43c18e6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranked the hybrid response\n",
    "ranked = ranker.rerank(response, query, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a025e-9b12-49ec-9e48-d320a29ca270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
