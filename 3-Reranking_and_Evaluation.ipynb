{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9299e2fb-9f95-4690-b172-0d6e9b4952cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from opensearch_interface import OpenSearchClient\n",
    "from typing import List, Union\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from reranker import ReRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e934fe6-53e2-4720-8583-ba93018393b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReRanker:\n",
    "    '''\n",
    "    Cross-Encoder models achieve higher performance than Bi-Encoders, \n",
    "    however, they do not scale well to large datasets. The lack of scalability\n",
    "    is due to the underlying cross-attention mechanism, which is computationally\n",
    "    expensive.  Thus a Bi-Encoder is best used for 1st-stage document retrieval and \n",
    "    a Cross-Encoder is used to re-rank the retrieved documents. \n",
    "\n",
    "    https://www.sbert.net/examples/applications/cross-encoder/README.html\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name: str='cross-encoder/ms-marco-MiniLM-L-6-v2', local_files: bool=False):\n",
    "        self.model_name = model_name\n",
    "        self.model = CrossEncoder(self.model_name, automodel_args={'local_files_only':local_files})\n",
    "        self.score_field = 'cross_score'\n",
    "\n",
    "    def _cross_encoder_score(self, \n",
    "                             results: List[dict], \n",
    "                             query: str, \n",
    "                             cross_score_key: str='cross-score',\n",
    "                             return_scores: bool=False\n",
    "                             ) -> Union[np.array, None]:\n",
    "        '''\n",
    "        Given a list of hits from a Retriever:\n",
    "            1. Scores hits by passing query and results through CrossEncoder model. \n",
    "            2. Adds cross-score key to hits dictionary. \n",
    "            3. If desired returns np.array of Cross Encoder scores.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        results: List[dict]\n",
    "            List of search results from OpenSearch client.\n",
    "        query: str\n",
    "            User query.\n",
    "        cross_score_key: str='cross-score'\n",
    "            Name of key/field that the new calculated cross encoder score will be associated with.\n",
    "        return_scores: bool=False\n",
    "            If True, returns a np.array of cross encoder scores. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Either returns a np.array of cross encoder scores if \"return_scores\" is True, otherwise\n",
    "        nothing is returned.  The primary purpose of this function is to update the \"results\" dict. \n",
    "        '''\n",
    "        \n",
    "        #build query/content list \n",
    "        #create a list of lists that contains the query and the content field of each result from \"results\"\n",
    "        #important the cross_input variable must be a list of lists\n",
    "        cross_input = None\n",
    "        \n",
    "        #get scores\n",
    "        # Call the self.model's predict method to get predicted scores on the cross_input\n",
    "        # Output at this step will be a numpy matrix of cross-encoder scores\n",
    "        ######################################################################\n",
    "        # Example: \n",
    "        # array([ 1.3296969 ,  0.8297793 ,  1.2054391 ,  2.9448447 ,  2.7284985 ,\n",
    "        #         4.231843  , -1.6208533 ,  2.4096487 , -1.2081863 ,  2.9743905 ,\n",
    "        #         3.2194595 , -0.27501446,  1.5256095 ,  2.8193645 ,  1.5568736 ,\n",
    "        #         2.5138354 ,  1.9419916 ,  2.6341028 , -1.6115644 , -0.49818742,\n",
    "        #         3.695484  ,  2.93317   ,  3.1728778 , -0.5114989 , -4.076729  ], dtype=float32)\n",
    "\n",
    "        cross_scores = None\n",
    "\n",
    "        #enumerate through the results and update each dict with the cross_score_key arg as key and value as the new score:\n",
    "        #Example:\n",
    "             # {'cross-score' : 5.12345}\n",
    "        for i, result in enumerate(results):\n",
    "            None\n",
    "\n",
    "        if return_scores:\n",
    "            return cross_scores\n",
    "\n",
    "    def rerank(self, results: List[dict], query: str, top_k: int=10, threshold: float=None) -> List[dict]:\n",
    "        '''\n",
    "        Given a list of search results from OpenSearch client, results are scored with a Cross Encoder \n",
    "        and returned in sorted order by the cross_score field.  Threshold allows user to filter out \n",
    "        results that do not meet cross_score threshold value:\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        results: List[dict]\n",
    "            List of search results from OpenSearch client.\n",
    "        query: str\n",
    "            User query.\n",
    "        top_k: int=10\n",
    "            Number of reranked results to return\n",
    "        threshold: float=None\n",
    "            If None, top_k results will be returned.  \n",
    "            If float value is present, only results with a cross_score that meet or exceed the threshold\n",
    "            will be retuned.  This arg is present to prevent very low scoring document from being returned. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List of reranked search results. \n",
    "        '''\n",
    "        # call the internal _cross_encoder_score function (it's ok that nothing is returned here)\n",
    "        # the results dictionary is being updated \n",
    "        None\n",
    "\n",
    "        #sort results by the new cross-score field\n",
    "        sorted_hits = None\n",
    "\n",
    "        #if user wants to set a threshold we need to account for that\n",
    "        if threshold or threshold == 0:\n",
    "\n",
    "            #filter sorted_hits by the threshold value\n",
    "            filtered_hits = None\n",
    "            \n",
    "            if not any(filtered_hits):\n",
    "                logger.warning(f'No hits above threshold {threshold}. Returning top {top_k} hits.')\n",
    "                return sorted_hits[:top_k]\n",
    "            return filtered_hits\n",
    "            \n",
    "        #if no threshold was set return top_k sorted_hits\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d905c45-88ce-49a6-8ff7-fb7ae5934fac",
   "metadata": {},
   "source": [
    "### Instantiate the ReRanker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a4bf326-c463-4f82-a7ef-3585d66c23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d46d8fc-5bc8-42d2-8dae-ebe8c69cad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3296969 ,  0.8297793 ,  1.2054391 ,  2.9448447 ,  2.7284985 ,\n",
       "        4.231843  , -1.6208533 ,  2.4096487 , -1.2081863 ,  2.9743905 ,\n",
       "        3.2194595 , -0.27501446,  1.5256095 ,  2.8193645 ,  1.5568736 ,\n",
       "        2.5138354 ,  1.9419916 ,  2.6341028 , -1.6115644 , -0.49818742,\n",
       "        3.695484  ,  2.93317   ,  3.1728778 , -0.5114989 , -4.076729  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker._cross_encoder_score(response, query=query, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952a99df-a089-4fd8-b76d-2294fe70777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index name\n",
    "index_name = 'impact-theory-minilm-196'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7819bf44-faac-437f-8599-a44bb9b40040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set query\n",
    "query = \"how do I change my life for good\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8f05d-1503-4bed-b795-58166745e436",
   "metadata": {},
   "source": [
    "### Test ReRanker class by conducting a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5655ea10-6812-46a5-8461-3ec58b6a31fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index                              uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
      "yellow open   kw-impact-theory                   2MjMun4bQYOoeUpv5UsJxg   3   1      33164            0     29.4mb         29.4mb\n",
      "yellow open   semantic-impact-theory-196         SY2nXyvmQ9i5LAS4hmn82g   3   1      37007            0    694.6mb        694.6mb\n",
      "yellow open   kw-impact-theory-196               vsuHausxRb6EjysQriOX5w   3   1      37007            0     30.5mb         30.5mb\n",
      "yellow open   security-auditlog-2023.10.21       Vj43Da3dTQm0mwBFNWHjCg   1   1          9            0    151.3kb        151.3kb\n",
      "yellow open   security-auditlog-2023.10.22       YXYp6DkYT-aLgGxRZNGsUA   1   1       1704            0      1.6mb          1.6mb\n",
      "yellow open   paul-graham3                       -74ZPvxoSMmtCPSzAI9o1A   1   1         18            0    768.2kb        768.2kb\n",
      "yellow open   security-auditlog-2023.10.25       1Cn9t6VhT227XHl2KJJ-WQ   1   1        852            0      1.7mb          1.7mb\n",
      "yellow open   security-auditlog-2023.10.26       6NJTWglXQIKkhSeY5iJGiQ   1   1       1704            0      3.4mb          3.4mb\n",
      "yellow open   semantic-impact-theory-128         FJKOre3yT9aFxlF-_TvcTA   3   1      60380            0        1gb            1gb\n",
      "yellow open   security-auditlog-2023.10.23       5P9e5W_TSsqMRF-rI2V6rw   1   1       1704            0      3.3mb          3.3mb\n",
      "yellow open   security-auditlog-2023.10.24       khZ54O5uT6mJ_rpfeWk9kw   1   1       1704            0      3.5mb          3.5mb\n",
      "green  open   .opendistro_security               _QeSqO4CQN2IU8VpE9hnPw   1   0         10            0     75.6kb         75.6kb\n",
      "yellow open   security-auditlog-2023.10.27       qXbsIveDTBKNEKLLYgaWuA   1   1       1704            0      1.7mb          1.7mb\n",
      "yellow open   semantic-impact-theory             5khyvtPQRASCMmhZiQTcVw   3   1      33164            0    331.5mb        331.5mb\n",
      "yellow open   security-auditlog-2023.10.28       _KqVenzeS0WcX-DbtGTazw   1   1        854            0      1.7mb          1.7mb\n",
      "yellow open   semantic-impact-theory-evalution   OKatncGsSQipgrq3cRIU0g   1   1      17849            0    348.9mb        348.9mb\n",
      "yellow open   .plugins-ml-config                 IEeXrm-DRiOMm2qzo7PbqA   1   1          1            0      3.9kb          3.9kb\n",
      "green  open   .opensearch-observability          nN299E0QS9OvsRh_UcbJVQ   1   0          0            0       208b           208b\n",
      "yellow open   semantic-impact-theory-gte         HOfyQXRmQLaBYooeLgTcMg   3   1      42863            0      799mb          799mb\n",
      "yellow open   semantic-impact-theory-gte-doc-ids PFdAajMqTM2MB7M2dZcWSg   3   1      17849            0    350.5mb        350.5mb\n",
      "yellow open   kw-impact-theory-evalution         l-vdyoRQSbK4OcnK7ni7cg   1   1      17849            0     29.2mb         29.2mb\n",
      "yellow open   kw-impact-theory-128               a7g5VTfxRBSsQi9hcuJ1NQ   3   1      60380            0     32.7mb         32.7mb\n",
      "yellow open   impact-theory-minilm-196           FzbaKMvCT32zi-YVMdaWUw   3   1      37007            0    367.7mb        367.7mb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create new OpenSearch client\n",
    "osclient = OpenSearchClient('sentence-transformers/all-MiniLM-L6-v2')\n",
    "osclient.show_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feb7e21c-d171-4096-9b13-4b156f625169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct hybrid search\n",
    "response = osclient.hybrid_search(query, index_name, index_name, kw_size=25, vec_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d26ee0cb-7c6e-4bde-9ade-0a43c18e6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranked the hybrid response\n",
    "ranker.rerank(response, query, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "669a025e-9b12-49ec-9e48-d320a29ca270",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker._cross_encoder_score(response, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e7187e1-dc92-4649-a33a-5598aec3b4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.827699, -11.387819], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.model.predict([['dead man walking', 'prisoner on death row with no chance to live'], ['what is a dead man walking', 'sean penn with susan sarandon']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd408c1-ab39-4e24-8161-286a3ba65882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
