{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate quickstart guide (as a notebook!)\n",
    "\n",
    "This notebook will guide you through the basics of Weaviate. You can find the full documentation [on our site here](https://weaviate.io/developers/weaviate/quickstart).\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/weaviate-tutorials/quickstart/blob/main/quickstart_end_to_end.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need the Weaviate Python client. If you don't yet have it installed - you can do so with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weaviate instance\n",
    "\n",
    "For this, you will need a working instance of Weaviate somewhere. We recommend either:\n",
    "- Creating a free sandbox instance on Weaviate Cloud Services (https://console.weaviate.cloud/), or\n",
    "- Using [Embedded Weaviate](https://weaviate.io/developers/weaviate/installation/embedded).\n",
    "\n",
    "Instantiate the client using **one** of the following code examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For using WCS\n",
    "\n",
    "NOTE: Before you do this, you need to create the instance in WCS and get the credentials. Please refer to the [WCS Quickstart guide](https://weaviate.io/developers/wcs/quickstart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For using WCS\n",
    "import json\n",
    "import os\n",
    "import weaviate\n",
    "from weaviate import Client\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "auth_config = weaviate.AuthApiKey(api_key=os.environ['WEAVIATE_API_KEY'])\n",
    "\n",
    "client = weaviate.Client(\n",
    "  url=\"https://test-cluster-nov8-jvhnpt7n.weaviate.network\",\n",
    "  auth_client_secret=auth_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.is_live(), client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For using Embedded Weaviate\n",
    "\n",
    "This will spin up a Weaviate instance in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For using embedded\n",
    "# import weaviate\n",
    "# from weaviate.embedded import EmbeddedOptions\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# client = weaviate.Client(\n",
    "#     embedded_options=EmbeddedOptions(),\n",
    "#     additional_headers = {\n",
    "#         \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]  # Replace with your inference API key\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from preprocessing import FileIO\n",
    "from typing import Union, List\n",
    "# data = pd.read_csv('jeopardy_questions.csv', nrows=50000)\n",
    "# with open('vector_search_applications/data/impact_theory_updated_Nov1.json') as f:\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (37007, 17)\n",
      "Memory Usage: 4.55+ MB\n"
     ]
    }
   ],
   "source": [
    "data = FileIO().load_parquet('./practice_data/impact_theory_minilm_196.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['author', 'title', 'video_id', 'playlist_id', 'channel_id', 'description', 'keywords', 'length', 'publish_date', 'thumbnail_url', 'views', 'age_restricted', 'episode_num', 'content', 'content_embedding', 'doc_id', 'episode_url'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# questions = data['question'].values.tolist()\n",
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = model.encode(questions, show_progress_bar=True, device='cuda:0', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['vectors'] = pd.Series(vectors.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.014312311075627804,\n",
       " -0.023840470239520073,\n",
       " 0.03354779630899429,\n",
       " -0.014589335769414902,\n",
       " 0.06778962910175323,\n",
       " -0.04618564620614052,\n",
       " -0.029401959851384163,\n",
       " 0.008369481191039085,\n",
       " -0.09274967759847641,\n",
       " -0.021655932068824768,\n",
       " 0.04514612630009651,\n",
       " 0.07262410968542099,\n",
       " 0.010997667908668518,\n",
       " 0.03870929032564163,\n",
       " -0.012866034172475338,\n",
       " -0.03947143629193306,\n",
       " -0.09030212461948395,\n",
       " 0.0016469808761030436,\n",
       " -0.04250699281692505,\n",
       " 0.04687390848994255,\n",
       " 0.009863625280559063,\n",
       " 0.027880573645234108,\n",
       " -0.0014345893869176507,\n",
       " 0.01776115968823433,\n",
       " 0.0377359576523304,\n",
       " 0.02495153434574604,\n",
       " 0.03829507157206535,\n",
       " -0.06030397117137909,\n",
       " 0.01684751734137535,\n",
       " 0.05068695545196533,\n",
       " 0.04673828184604645,\n",
       " -0.030108792707324028,\n",
       " 0.004148408304899931,\n",
       " -0.0534181147813797,\n",
       " -0.0599793903529644,\n",
       " 0.03245760127902031,\n",
       " 0.028064200654625893,\n",
       " -0.02351801097393036,\n",
       " 0.026382220908999443,\n",
       " -0.027201006188988686,\n",
       " 0.0028127955738455057,\n",
       " -0.08360270410776138,\n",
       " 0.061894841492176056,\n",
       " 0.041555169969797134,\n",
       " 0.011427956633269787,\n",
       " 0.04286211356520653,\n",
       " 0.023667585104703903,\n",
       " -0.10138757526874542,\n",
       " 0.050216544419527054,\n",
       " -0.04283791035413742,\n",
       " -0.08908845484256744,\n",
       " -0.009682083502411842,\n",
       " 0.010554631240665913,\n",
       " -0.030971448868513107,\n",
       " 0.02207605354487896,\n",
       " -0.01053954754024744,\n",
       " 0.03800603747367859,\n",
       " 0.0369117297232151,\n",
       " 0.016595497727394104,\n",
       " -0.10686098039150238,\n",
       " 0.054593201726675034,\n",
       " -0.005219861399382353,\n",
       " -0.022058604285120964,\n",
       " 0.027940329164266586,\n",
       " 0.02139701507985592,\n",
       " 0.06339392066001892,\n",
       " -0.003917367663234472,\n",
       " -0.07742541283369064,\n",
       " 0.08452184498310089,\n",
       " 0.15617050230503082,\n",
       " 0.039741840213537216,\n",
       " 0.026780927553772926,\n",
       " -0.0767899602651596,\n",
       " 0.0030088082421571016,\n",
       " 0.04373268410563469,\n",
       " 0.05629010125994682,\n",
       " -0.026217494159936905,\n",
       " 0.052515119314193726,\n",
       " 0.04835071042180061,\n",
       " 5.596363916993141e-05,\n",
       " 0.07778391987085342,\n",
       " -0.048398371785879135,\n",
       " -0.0761079490184784,\n",
       " 0.037485431879758835,\n",
       " -0.0521564744412899,\n",
       " -0.04086025059223175,\n",
       " -0.09004352986812592,\n",
       " -0.06808313727378845,\n",
       " -0.015291801653802395,\n",
       " 0.039474379271268845,\n",
       " 0.08786264806985855,\n",
       " -0.027518173679709435,\n",
       " 0.024444572627544403,\n",
       " -0.05007004737854004,\n",
       " -0.02639842964708805,\n",
       " 0.03217489272356033,\n",
       " -0.0768626481294632,\n",
       " 0.02946389652788639,\n",
       " -0.04602200537919998,\n",
       " 0.01368965394794941,\n",
       " -0.07277800142765045,\n",
       " -0.010568669997155666,\n",
       " -0.08137749135494232,\n",
       " 0.06991934776306152,\n",
       " 0.017130061984062195,\n",
       " 0.0036773402243852615,\n",
       " 0.05211655795574188,\n",
       " -0.04645276069641113,\n",
       " -0.0433119460940361,\n",
       " 0.0344943031668663,\n",
       " -0.03421895205974579,\n",
       " -0.039566028863191605,\n",
       " 0.024311961606144905,\n",
       " -0.015788082033395767,\n",
       " 0.03781687840819359,\n",
       " 0.03705330938100815,\n",
       " -0.013842158950865269,\n",
       " 0.043725576251745224,\n",
       " -0.0355011448264122,\n",
       " 0.05552832782268524,\n",
       " 0.03447923809289932,\n",
       " 0.05419287458062172,\n",
       " 0.06368719041347504,\n",
       " 0.000726869679056108,\n",
       " 0.038933102041482925,\n",
       " 0.034045543521642685,\n",
       " -0.03642178326845169,\n",
       " -4.490231197771716e-33,\n",
       " 0.06792107969522476,\n",
       " -0.013317850418388844,\n",
       " -0.014470078982412815,\n",
       " 0.05346901714801788,\n",
       " -0.005798309110105038,\n",
       " 0.05189994350075722,\n",
       " -0.08209241181612015,\n",
       " 0.0320955254137516,\n",
       " 0.16482163965702057,\n",
       " -0.02966484986245632,\n",
       " 0.07537426799535751,\n",
       " 0.008709169924259186,\n",
       " 0.04449065402150154,\n",
       " -0.02881643921136856,\n",
       " -0.031787365674972534,\n",
       " 0.09777364134788513,\n",
       " 0.06033448502421379,\n",
       " 0.003774900222197175,\n",
       " -0.018759293481707573,\n",
       " -0.03967436030507088,\n",
       " 0.05706019699573517,\n",
       " -0.06336711347103119,\n",
       " -0.024412430822849274,\n",
       " 0.05794935300946236,\n",
       " 0.00954599492251873,\n",
       " 0.0167671088129282,\n",
       " -0.002331745345145464,\n",
       " 0.09713095426559448,\n",
       " -0.03635378181934357,\n",
       " -0.018019497394561768,\n",
       " -0.060651134699583054,\n",
       " 0.11499286442995071,\n",
       " -0.1207408457994461,\n",
       " 0.04343552514910698,\n",
       " -0.009789422154426575,\n",
       " -0.02891247346997261,\n",
       " 0.02954130619764328,\n",
       " -0.01934349164366722,\n",
       " 0.046971045434474945,\n",
       " 0.006654698401689529,\n",
       " 0.03112557902932167,\n",
       " 0.05516083166003227,\n",
       " 0.11360924690961838,\n",
       " -0.07206044346094131,\n",
       " 0.052845072001218796,\n",
       " -0.07196343690156937,\n",
       " -0.0038226149044930935,\n",
       " -0.06232317537069321,\n",
       " 0.04233284667134285,\n",
       " 0.02650853618979454,\n",
       " 0.013807304203510284,\n",
       " -0.040697820484638214,\n",
       " -0.0929768905043602,\n",
       " -0.08846833556890488,\n",
       " -0.011839903891086578,\n",
       " 0.05023226886987686,\n",
       " -0.010198032483458519,\n",
       " 0.03977079316973686,\n",
       " 0.003959740046411753,\n",
       " 0.028241286054253578,\n",
       " 0.04814181476831436,\n",
       " 0.05141204595565796,\n",
       " 0.03454701974987984,\n",
       " -0.012215057387948036,\n",
       " -0.017407573759555817,\n",
       " -0.013989266939461231,\n",
       " -0.06880151480436325,\n",
       " -0.03489731624722481,\n",
       " -0.0809057205915451,\n",
       " 0.021000664681196213,\n",
       " 0.04288381710648537,\n",
       " -0.0023358564358204603,\n",
       " -0.1048600971698761,\n",
       " -0.03235859051346779,\n",
       " -0.014409028925001621,\n",
       " -0.049600716680288315,\n",
       " -0.04374702274799347,\n",
       " -0.049019705504179,\n",
       " -0.09573885798454285,\n",
       " -0.03048654831945896,\n",
       " 0.030591871589422226,\n",
       " -0.0547805093228817,\n",
       " 0.08837682008743286,\n",
       " -0.021940074861049652,\n",
       " 0.050347618758678436,\n",
       " 0.02628035470843315,\n",
       " -0.016349386423826218,\n",
       " 0.04850447177886963,\n",
       " 0.029092049226164818,\n",
       " -0.015379535965621471,\n",
       " -0.006591147277504206,\n",
       " -0.04286349192261696,\n",
       " 0.02407563291490078,\n",
       " -0.0361056886613369,\n",
       " -0.048458147794008255,\n",
       " 1.579144049873291e-33,\n",
       " -0.09123137593269348,\n",
       " 0.011466099880635738,\n",
       " -0.01623021438717842,\n",
       " 0.0058518145233392715,\n",
       " 0.06128985807299614,\n",
       " -0.049398716539144516,\n",
       " -0.15633617341518402,\n",
       " 0.03426184877753258,\n",
       " 0.05332222580909729,\n",
       " -0.053302306681871414,\n",
       " -0.0072256033308804035,\n",
       " 0.06779370456933975,\n",
       " 0.09113695472478867,\n",
       " -0.020651765167713165,\n",
       " -0.03031943179666996,\n",
       " -0.02474924363195896,\n",
       " -0.08483867347240448,\n",
       " -0.09155887365341187,\n",
       " -0.015897393226623535,\n",
       " 0.025486314669251442,\n",
       " 0.04080885648727417,\n",
       " -0.010699331760406494,\n",
       " -0.019468553364276886,\n",
       " -0.06379193812608719,\n",
       " -0.011120567098259926,\n",
       " -0.03718187287449837,\n",
       " -0.023379353806376457,\n",
       " 0.06791061908006668,\n",
       " 0.04862276837229729,\n",
       " 0.0740286335349083,\n",
       " -0.04531371593475342,\n",
       " -0.06090221181511879,\n",
       " -0.027048245072364807,\n",
       " 0.03280587121844292,\n",
       " 0.008346621878445148,\n",
       " -0.04290231317281723,\n",
       " -0.008884520269930363,\n",
       " 0.029287340119481087,\n",
       " 0.0068364329636096954,\n",
       " -0.03387007862329483,\n",
       " -0.020668618381023407,\n",
       " 0.05058235675096512,\n",
       " 0.03015000745654106,\n",
       " -0.14436383545398712,\n",
       " 0.03853871673345566,\n",
       " 0.005175375379621983,\n",
       " -0.013704614713788033,\n",
       " 0.08173896372318268,\n",
       " 0.0005209662485867739,\n",
       " -0.00020777128520421684,\n",
       " 0.012256493791937828,\n",
       " 0.030817480757832527,\n",
       " -0.02432120405137539,\n",
       " 0.009684975259006023,\n",
       " -0.04456843063235283,\n",
       " 0.04597926512360573,\n",
       " 0.06514377892017365,\n",
       " 0.037519220262765884,\n",
       " 0.057271987199783325,\n",
       " 0.06109197810292244,\n",
       " 0.029907217249274254,\n",
       " 0.005248321685940027,\n",
       " 0.009646735154092312,\n",
       " 0.05365312844514847,\n",
       " -0.10142706334590912,\n",
       " 0.07519573718309402,\n",
       " -0.10695887356996536,\n",
       " 0.06873847544193268,\n",
       " -0.02492220513522625,\n",
       " -0.023295799270272255,\n",
       " 0.0555884949862957,\n",
       " -0.06707856804132462,\n",
       " -0.045598387718200684,\n",
       " 0.07730527222156525,\n",
       " 0.036756597459316254,\n",
       " 0.07928300648927689,\n",
       " -0.02187824808061123,\n",
       " 0.017893092706799507,\n",
       " 0.09681686013936996,\n",
       " -0.09215805679559708,\n",
       " -0.04736151173710823,\n",
       " -0.06499221175909042,\n",
       " -0.007018715608865023,\n",
       " -0.03950360044836998,\n",
       " -0.025772271677851677,\n",
       " -0.14360947906970978,\n",
       " -0.015045829117298126,\n",
       " -0.0463847815990448,\n",
       " 0.015606089495122433,\n",
       " -0.04949277266860008,\n",
       " -0.023273080587387085,\n",
       " -0.062452107667922974,\n",
       " 0.0027959265280514956,\n",
       " 0.037933941930532455,\n",
       " 0.02407219260931015,\n",
       " -2.2953900113975578e-08,\n",
       " 0.060654111206531525,\n",
       " 0.015566390939056873,\n",
       " 0.0709591954946518,\n",
       " 0.06256479769945145,\n",
       " 0.10835547745227814,\n",
       " 0.014667325653135777,\n",
       " 0.024712886661291122,\n",
       " -0.10077221691608429,\n",
       " 0.022653920575976372,\n",
       " 0.007782123051583767,\n",
       " -0.08850032091140747,\n",
       " 0.030539460480213165,\n",
       " 0.02436772920191288,\n",
       " -0.007907023653388023,\n",
       " -0.023327255621552467,\n",
       " -0.011841757223010063,\n",
       " 0.06581588834524155,\n",
       " -0.022439097985625267,\n",
       " -0.06971624493598938,\n",
       " 0.06607933342456818,\n",
       " 0.09872362017631531,\n",
       " -0.02137770876288414,\n",
       " 0.008049963042140007,\n",
       " -0.023788439109921455,\n",
       " 0.0716782659292221,\n",
       " -0.018778005614876747,\n",
       " -0.008908925577998161,\n",
       " 0.06913608312606812,\n",
       " -0.05867813527584076,\n",
       " 0.03999132290482521,\n",
       " -0.04475349932909012,\n",
       " -0.021464280784130096,\n",
       " -0.0027805096469819546,\n",
       " -0.03131899610161781,\n",
       " -0.03336000442504883,\n",
       " 0.03735249117016792,\n",
       " 0.02532026916742325,\n",
       " 0.05211983248591423,\n",
       " 0.03714088350534439,\n",
       " 0.019047684967517853,\n",
       " -0.05500524491071701,\n",
       " -0.04484894871711731,\n",
       " -0.08035704493522644,\n",
       " 0.003937059547752142,\n",
       " 0.06211615353822708,\n",
       " -0.02287592738866806,\n",
       " -0.010751488618552685,\n",
       " -0.054090067744255066,\n",
       " -0.017495110630989075,\n",
       " 0.10013391077518463,\n",
       " 0.05367133021354675,\n",
       " 0.06268484890460968,\n",
       " 0.07076307386159897,\n",
       " -0.03760509565472603,\n",
       " 0.03130176663398743,\n",
       " -0.0285105649381876,\n",
       " 0.03884821757674217,\n",
       " 0.024381281808018684,\n",
       " -0.11699977517127991,\n",
       " -0.011718809604644775,\n",
       " 0.015068480744957924,\n",
       " -0.009263750165700912,\n",
       " -0.004904627334326506,\n",
       " 0.00040028526564128697]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['question'][0]\n",
    "data_dict['vectors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {k:v for k,v in data_dict.items() if k in ['question', 'answer', 'vectors', 'category']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['category', 'question', 'answer', 'vectors'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.schema.exists(\"ImpactTheory\"):\n",
    "    client.schema.delete_class(\"ImpactTheory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_obj = {\n",
    "    \"class\": \"ImpactTheory\",\n",
    "    \"vectorizer\": \"none\",  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also. # Ensure the `generative-openai` module is used for generative queries\n",
    "}\n",
    "\n",
    "client.schema.create_class(class_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self,\n",
    "                 hosts: Union[str, List[dict]]=[{\"host\": \"localhost\", \"port\": 9200}],\n",
    "                 http_auth: Tuple[str, str]=('admin', 'admin'),\n",
    "                 model_name_or_path: str='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                 use_ssl: bool = True,\n",
    "                 verify_certs = False,\n",
    "                 ssl_assert_hostname = False,\n",
    "                 ssl_show_warn = False,\n",
    "                 timeout: int=30):\n",
    "        super().__init__(hosts=hosts,\n",
    "                         http_auth=http_auth,\n",
    "                         use_ssl=use_ssl,\n",
    "                         verify_certs = verify_certs,\n",
    "                         ssl_assert_hostname = ssl_assert_hostname,\n",
    "                         ssl_show_warn = ssl_show_warn,\n",
    "                         timeout=timeout)\n",
    "\n",
    "Client(\n",
    "  url=\"https://test-cluster-nov8-jvhnpt7n.weaviate.network\",\n",
    "  auth_client_secret=auth_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weaviate(Client):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 api_key: str=os.environ['WEAVIATE_API_KEY'],\n",
    "                 endpoint: str=os.environ['WEAVIATE_ENDPOINT']\n",
    "                ):\n",
    "        auth_config = weaviate.AuthApiKey(api_key=api_key)\n",
    "        super().__init__(auth_client_secret=auth_config,\n",
    "                         url=endpoint)    \n",
    "        self.fields = [\"title\", \"content\", \"docid\"]\n",
    "        \n",
    "    def show_classes(self):\n",
    "        return [d['class'] for d in self.cluster.get_nodes_status()[0]['shards']]\n",
    "\n",
    "    def show_class_info(self):\n",
    "        return [d for d in self.cluster.get_nodes_status()[0]['shards']]\n",
    "\n",
    "    def _format_response(self, \n",
    "                         response: dict,\n",
    "                         class_: str\n",
    "                         ) -> List[dict]:\n",
    "        results = []\n",
    "        hits = response['data']['Get'][class_]\n",
    "        for d in hits:\n",
    "            temp = {k:v for k,v in d.items() if k != '_additional'}\n",
    "            if d.get('_additional'):\n",
    "                for key in d['_additional']:\n",
    "                    temp[key] = d['_additional'][key]\n",
    "            results.append(temp)\n",
    "        return results\n",
    "        \n",
    "    def keyword_search(self,\n",
    "                       query: str,\n",
    "                       class_: str,\n",
    "                       properties: List[str]=['content'],\n",
    "                       limit: int=10,\n",
    "                       return_raw: bool=False) -> Union[dict, List[dict]]:\n",
    "        '''\n",
    "        Executes Keyword (BM25) search. \n",
    "        '''\n",
    "        response = (self.query\n",
    "                    .get(class_,self.fields)\n",
    "                    .with_bm25(query=query, properties=properties)\n",
    "                    .with_additional(['score', \"id\"])\n",
    "                    .with_limit(limit)\n",
    "                    .do()\n",
    "                    )\n",
    "        if return_raw:\n",
    "            return response\n",
    "        else: \n",
    "            return self._format_response(response, class_)\n",
    "\n",
    "    def hybrid_search(self,\n",
    "                      query: str,\n",
    "                      class_: str,\n",
    "                      properties: List[str]=['content'],\n",
    "                      limit: int=10,\n",
    "                      return_raw: bool=False\n",
    "                     ) -> Union[dict, List[dict]]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add objects\n",
    "\n",
    "We'll add objects to our Weaviate instance using a batch import process.\n",
    "\n",
    "We shows you two options, where you can either:\n",
    "- Have Weaviate create vectors, or\n",
    "- Specify custom vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have Weaviate create vectors (with `text2vec-openai`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing question: 1\n",
      "importing question: 2\n",
      "importing question: 3\n",
      "importing question: 4\n",
      "importing question: 5\n",
      "importing question: 6\n",
      "importing question: 7\n",
      "importing question: 8\n",
      "importing question: 9\n",
      "importing question: 10\n"
     ]
    }
   ],
   "source": [
    "# # Load data\n",
    "# import requests\n",
    "# url = 'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json'\n",
    "# resp = requests.get(url)\n",
    "# data = json.loads(resp.text)\n",
    "\n",
    "# # Configure a batch process\n",
    "# with client.batch(\n",
    "#     batch_size=100\n",
    "# ) as batch:\n",
    "#     # Batch import all Questions\n",
    "#     for i, d in enumerate(data):\n",
    "#         if i % 2500:\n",
    "#             print(f\"importing question: {i+1}\")\n",
    "\n",
    "#         properties = {\n",
    "#             \"answer\": d[\"Answer\"],\n",
    "#             \"question\": d[\"Question\"],\n",
    "#             \"category\": d[\"Category\"],\n",
    "#         }\n",
    "\n",
    "#         client.batch.add_data_object(\n",
    "#             properties,\n",
    "#             \"Question\",\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify \"custom\" vectors (i.e. generated outside of Weaviate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/raydata/lib/python3.9/site-packages/weaviate/warnings.py:130: DeprecationWarning: Dep006: You are using the `client.batch()` method, which will be removed in the next major release.\n",
      "            Please instead use the `client.batch.configure()` method to configure your batch and `client.batch` to enter the context manager.\n",
      "            See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230f03f049ad41c8871b4991fa7d5bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 1.07 s, total: 20.2 s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # Load data\n",
    "# import requests\n",
    "# fname = \"jeopardy_tiny_with_vectors_all-OpenAI-ada-002.json\"  # This file includes pre-generated vectors\n",
    "# url = f'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/{fname}'\n",
    "# resp = requests.get(url)\n",
    "# data = json.loads(resp.text)\n",
    "\n",
    "# Configure a batch process\n",
    "with client.batch(batch_size=250) as batch:\n",
    "    # Batch import all Questions\n",
    "    for i in tqdm(range(len(data_dict['question']))):\n",
    "\n",
    "        properties = {\n",
    "            \"answer\": data_dict[\"answer\"][i],\n",
    "            \"question\": data_dict[\"question\"][i],\n",
    "            \"category\": data_dict[\"category\"][i],\n",
    "        }\n",
    "\n",
    "        custom_vector = data_dict[\"vectors\"][i]\n",
    "        batch.add_data_object(\n",
    "            properties,\n",
    "            \"Question\",\n",
    "            vector=custom_vector  # Add custom vector\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527e7074be6743f6916c72f2a99af7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 870 ms, total: 15.2 s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # Load data\n",
    "# import requests\n",
    "# fname = \"jeopardy_tiny_with_vectors_all-OpenAI-ada-002.json\"  # This file includes pre-generated vectors\n",
    "# url = f'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/{fname}'\n",
    "# resp = requests.get(url)\n",
    "# data = json.loads(resp.text)\n",
    "\n",
    "# Configure a batch process\n",
    "with client.batch(batch_size=250) as batch:\n",
    "    # Batch import all Questions\n",
    "    for i, d in enumerate(tqdm(data)):\n",
    "\n",
    "        properties = {\n",
    "            \"title\": d['title'],\n",
    "            \"content\": d['content'],\n",
    "            \"docid\": d['doc_id'],\n",
    "        }\n",
    "\n",
    "        custom_vector = d['content_embedding']\n",
    "        batch.add_data_object(\n",
    "            properties,\n",
    "            \"ImpactTheory\",\n",
    "            vector=custom_vector  # Add custom vector\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Fanny Hill',\n",
       "  'category': 'IMPRISONED AUTHORS',\n",
       "  'question': 'To escape debtor\\'s prison, John Cleland wrote this bawdy book about \"A Woman of Pleasure\" in 1748'},\n",
       " {'answer': 'Key West',\n",
       "  'category': 'FLORIDA',\n",
       "  'question': 'Harry Truman chose this Florida island locale for his \"Little White House\" in 1946'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.query.get(\n",
    "    \"Question\",\n",
    "    [\"question\", \"answer\", 'category']\n",
    ").with_limit(2).do()\n",
    "\n",
    "# print(json.dumps(response['data']['Get']['Question']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25 Search\n",
    "\n",
    "Let's try a similarity search. We'll use nearText search to look for quiz objects most similar to biology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how do i quit social media\"\n",
    "client.cluster.get_nodes_status()\n",
    "index = 'Impact_theory_minilm_256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['content']\n",
    "response = (\n",
    "    client.query\n",
    "    .get(index,[\"title\", \"content\", \"doc_id\", 'thumbnail_url'])\n",
    "    .with_bm25(query=query, properties=properties)\n",
    "    .with_additional(['score', \"id\"])\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'Impact_theory_minilm_256': [{'_additional': {'id': '92b37c1a-6018-4f9e-b1c9-b6aa420a9eba',\n",
       "      'score': '6.62025'},\n",
       "     'content': \"in electrical engineering and computer science from MIT. He's the author of six books. His work has been published in more than 20 languages. And he's written 60 peer-reviewed papers that have been cited more than 3,500 times. He's a provost, distinguished professor of computer science at Georgetown University. But, ironically, he's most famous for his views on digital minimalism. His TED Talk on why you should quit social media has been viewed over 5 million times. And his work on this topic and related topics such as doing deep work and avoiding a life of distraction have been read by millions of people around the world. His insights and expertise have made him one of the most sought-after minds on the subject. And he's been featured in most major publications, including The New York Times, The Wall Street Journal, The New Yorker, The Washington Post, and The Economist, to name but a few. So, please, help me in welcoming the man who, true to his core philosophy, has never had a social media account, the bestselling author of So Good They Can't Ignore You and Digital Minimalism, Cal Newport. What's up, man? How you doing?\",\n",
       "     'doc_id': 'ROKQHRfh2mA_1',\n",
       "     'thumbnail_url': 'https://i.ytimg.com/vi/ROKQHRfh2mA/hq720.jpg',\n",
       "     'title': 'How to Quit Social Media and Master Your Focus | Cal Newport on Impact Theory'},\n",
       "    {'_additional': {'id': '1e090f35-ab85-4ec0-bc43-30a081af705f',\n",
       "      'score': '6.221853'},\n",
       "     'content': \"It's all about me, me, me, me, me. It's the other way. It's like I care for the things that I care about. I just don't care for your opinions about me, especially if they don't come from a place of love. If they come from a place of love, I do care what you think about me. I do give a fuck. But I don't give a fuck if you just are presenting an opinion because you saw a post on Instagram and you have a problem with that. So how do you help people get out from under family pressure, societal pressure? You talk a lot about social comparison. How do you help people deal with that? And then how do you help them find the clarity of what they really want for themselves? So finding clarity is a very internal process. And most of the time what has happened in our world today, and it happens more and more people get on social media and more time they spend on social media, is that we, and this is actually scientifically researched, they develop something that is called social comparison.\",\n",
       "     'doc_id': 'p0XjlRb1Y_s_13',\n",
       "     'thumbnail_url': 'https://i.ytimg.com/vi/p0XjlRb1Y_s/hq720.jpg',\n",
       "     'title': 'Are You Chasing The WRONG Things? Watch This | Ajit Nawalkha on Impact Theory'},\n",
       "    {'_additional': {'id': 'b10f495b-3a5c-4c36-a90f-16b6b4bb4b3f',\n",
       "      'score': '6.1202855'},\n",
       "     'content': \"So You might that might be like times 50 for humans so I don't know but it's hard, you know, it's hard to like make that exact analogy that's I don't like making those analogies Do you have any sense of like, um What we should expect from the unintentional social social isolation experiment that we're running now So we're recording this. We're what month five. Yeah of uh, covid lockdown. So is there You know, do you have a guess on where our breaking point is or yeah, that's a really good question. I I have no idea I think there's another big thing that you know Is a factor especially with humans two things that are a factor with with humans one is that um The notion of kind of Social media and skype and zoom and all these ways that we are staying connected so To what degree does that actually help to mitigate those feelings of loneliness? It's hard to say, you know Teenagers have been using the new generation of teenagers have been using social media for years and years and yet They report feeling more lonely than ever So is that how people are feeling in general right now with social media or is it actually helping to mitigate?\",\n",
       "     'doc_id': 'ZrkxvEJhxwQ_170',\n",
       "     'thumbnail_url': 'https://i.ytimg.com/vi/ZrkxvEJhxwQ/hq720.jpg',\n",
       "     'title': 'CONTROL And LEVERAGE Dopamine To Never Lack MOTIVATION Again! | Andrew Huberman'}]}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "res  = client.keyword_search(query, index)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearVector = {\"vector\": model.encode(query)}\n",
    "properties = ['content']\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"ImpactTheory\",[\"title\", \"content\", \"docid\"])\n",
    "    .with_near_vector(nearVector)\n",
    "    .with_additional('score')\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"Get\": {\n",
      "            \"ImpactTheory\": [\n",
      "                {\n",
      "                    \"_additional\": {\n",
      "                        \"score\": \"0\"\n",
      "                    },\n",
      "                    \"content\": \"Like if it's not working, if I don't like the way this is working, I should be able to just send everyone an email saying, sorry, you know, you guys broke this place. I don't like the conversation. This is over, right? That's actually something I told Jack Dorsey when he was still running Twitter, that he should just delete it and he'd win the Nobel Peace Prize and he would deserve it. So I think you should be able to, you should be free to delete your social media account if you in fact own it. And you should be free to decide, okay, these are the standards of conduct in this space. Like it's, you know, this is true if you open a restaurant or if you open a movie theater, if you open any public space, it doesn't change if it's merely digital. You should be able to set the terms of service.\",\n",
      "                    \"docid\": \"6KJhM7Pg5EA_47\",\n",
      "                    \"title\": \"Understanding Power, Corruption, Politics, AI, Religion, Tribalism & Free Speech | Sam Harris\"\n",
      "                },\n",
      "                {\n",
      "                    \"_additional\": {\n",
      "                        \"score\": \"0\"\n",
      "                    },\n",
      "                    \"content\": \"There's no easy solution. There's no like, now I love myself. It's a process. It's a journey. It's going to be hard as all things are. Well, so now let's really make it complicated. So when you mess up, yup, you're going to have an internal critic. It's always brutal. But in today's age with social media, and you're like an extreme example of somebody that has to deal with this, but every kid now has to deal with like the one-off tweet about them being fat, ugly, stupid, whatever. How do you encounter something like that and not let it become part of your internal narrative? Yeah. I think with social media, we really need to understand why people use it the way they use it.\",\n",
      "                    \"docid\": \"iHcnt-xubTI_60\",\n",
      "                    \"title\": \"How to Turn Depression Into Millions | Lilly Singh on Impact Theory\"\n",
      "                },\n",
      "                {\n",
      "                    \"_additional\": {\n",
      "                        \"score\": \"0\"\n",
      "                    },\n",
      "                    \"content\": \"It's completely real, and it's completely influencing a lot of our decisions. Social media ends up creating situations where problems that aren't our problems, we take ownership over because we feel the pressure to talk about something or acknowledge something, as well as we want to be rewarded and validated by other people. We create this life for display purposes only. Again, creating a life for display purposes only existed before social media. We were posing for pictures before all of this happened, as well. I think the best thing to do after you acknowledge it is understand that the rewards aren't real. If anything, it's just a momentary dopamine kick, or for a lot of my public figure friends, it's maintaining a level of relevance or maintaining a level of attention, but it's not sustainable.\",\n",
      "                    \"docid\": \"33W8vQlOiPQ_22\",\n",
      "                    \"title\": \"How to Stop Being Controlled by Fear and Failure | Impact Theory Special Guests Q&A\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response includes a list of top 2 (due to the limit set) objects whose vectors are most similar to the word biology.\n",
    "\n",
    "Notice that even though the word biology does not appear anywhere, Weaviate returns biology-related entries.\n",
    "\n",
    "This example shows why vector searches are powerful. Vectorized data objects allow for searches based on degrees of similarity, as shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic search with a filter\n",
    "You can add a Boolean filter to your example. For example, let's run the same search, but only look in objects that have a \"category\" value of \"ANIMALS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"Get\": {\n",
      "            \"Question\": null\n",
      "        }\n",
      "    },\n",
      "    \"errors\": [\n",
      "        {\n",
      "            \"locations\": [\n",
      "                {\n",
      "                    \"column\": 6,\n",
      "                    \"line\": 1\n",
      "                }\n",
      "            ],\n",
      "            \"message\": \"VectorFromParams was called without any known params present\",\n",
      "            \"path\": [\n",
      "                \"Get\",\n",
      "                \"Question\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "nearText = {\"concepts\": [\"biology\"]}\n",
    "ask = {\n",
    "  \"question\": \"What is an erythrocite\",\n",
    "  \"properties\": [\"question\", \"answer\"]\n",
    "}\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Question\", [\"question\", \"answer\", \"category\", \"_additional {answer {hasAnswer property result} }\"])\n",
    "    .with_ask(ask)\n",
    "    # .with_where({\n",
    "    #     \"path\": [\"category\"],\n",
    "    #     \"operator\": \"Equal\",\n",
    "    #     \"valueText\": \"ANIMALS\"\n",
    "    # })\n",
    "    .with_limit(2)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response includes a list of top 2 (due to the limit set) objects whose vectors are most similar to the word biology - but only from the \"ANIMALS\" category.\n",
    "\n",
    "Using a Boolean filter allows you to combine the flexibility of vector search with the precision of where filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative search (single prompt)\n",
    "\n",
    "Next, let's try a generative search, where search results are processed with a large language model (LLM).\n",
    "\n",
    "Here, we use a `single prompt` query, and the model to explain each answer in plain terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"Get\": {\n",
      "            \"Question\": [\n",
      "                {\n",
      "                    \"_additional\": {\n",
      "                        \"generate\": {\n",
      "                            \"error\": null,\n",
      "                            \"singleResult\": \"DNA is like a special code that tells our bodies how to grow and work. It's like a recipe book that has all the instructions for making you who you are. Just like a recipe book has different recipes for different foods, DNA has different instructions for making different parts of your body, like your eyes, hair, and even your personality! It's really amazing because it's what makes you unique and special.\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"answer\": \"DNA\",\n",
      "                    \"category\": \"SCIENCE\",\n",
      "                    \"question\": \"In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance\"\n",
      "                },\n",
      "                {\n",
      "                    \"_additional\": {\n",
      "                        \"generate\": {\n",
      "                            \"error\": null,\n",
      "                            \"singleResult\": \"Well, a species is a group of living things that are similar to each other in many ways. They have the same kind of body parts, like legs or wings, and they can have babies with other members of their species. For example, dogs are a species, and so are cats. They look different and act differently, but all dogs can have puppies with other dogs, and all cats can have kittens with other cats. So, a species is like a big family of animals or plants that are all related to each other in a special way.\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"answer\": \"species\",\n",
      "                    \"category\": \"SCIENCE\",\n",
      "                    \"question\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "nearText = {\"concepts\": [\"biology\"]}\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
    "    .with_near_text(nearText)\n",
    "    .with_generate(single_prompt=\"Explain {answer} as you might to a five-year-old.\")\n",
    "    .with_limit(2)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Weaviate has retrieved the same results as before. But now it includes an additional, generated text with a plain-language explanation of each answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative search (grouped task)\n",
    "\n",
    "In the next example, we will use a grouped task prompt instead to combine all search results and send them to the LLM with a prompt. We ask the LLM to write a tweet about all of these search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧬 Did you know? In 1953, Watson & Crick 🧪 built a model of the molecular structure of DNA, the gene-carrying substance! 🧬 #ScienceFacts\n",
      "\n",
      "🐦🌿 Exciting news! In 2000, a new species 🆕 of sage grouse, the Gunnison sage grouse, was discovered. It's not just another northern sage grouse, but a unique classification! 🦆🌿 #ScienceDiscoveries\n"
     ]
    }
   ],
   "source": [
    "response = (\n",
    "    client.query\n",
    "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
    "    .with_near_text({\"concepts\": [\"biology\"]})\n",
    "    .with_generate(grouped_task=\"Write a tweet with emojis about these facts.\")\n",
    "    .with_limit(2)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(response[\"data\"][\"Get\"][\"Question\"][0][\"_additional\"][\"generate\"][\"groupedResult\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative search sends retrieved data from Weaviate to a large language model, or LLM. This allows you to go beyond simple data retrieval, but transform the data into a more useful form, without ever leaving Weaviate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! In just a few short minutes, you have:\n",
    "\n",
    "- Created your own cloud-based vector database with Weaviate,\n",
    "- Populated it with data objects,\n",
    "    - Using an inference API, or\n",
    "    - Using custom vectors,\n",
    "- Performed searches, including:\n",
    "    - Semantic search,\n",
    "    - Sementic search with a filter and\n",
    "    - Generative search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
