{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88728355-dd6c-4c08-8ad8-ac7f85e6af68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68f03b28-68e1-45c5-9ec0-99d9a32d0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#external files\n",
    "from preprocessing import FileIO\n",
    "from openai_interface import GPT_Turbo\n",
    "from weaviate_interface import WeaviateClient\n",
    "from retrieval_evaluation import (execute_evaluation, calc_hit_rate_scores, calc_mrr_scores)\n",
    "from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
    "from reranker import ReRanker\n",
    "\n",
    "#standard library imports\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from math import ceil\n",
    "from datetime import datetime\n",
    "from typing import List, Any, Dict, Tuple, Union\n",
    "\n",
    "#misc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "env = load_dotenv('./.env', override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bb049-ca24-42ef-9458-72fb687fe27d",
   "metadata": {},
   "source": [
    "### Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e61a946-f5b2-4a7e-80b6-1dc5bdaa4cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (26448, 12)\n",
      "Memory Usage: 2.42+ MB\n"
     ]
    }
   ],
   "source": [
    "data_path = '../impact_theory_minilm_256.parquet'\n",
    "data = FileIO().load_parquet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30095d52-6b57-4632-8a77-08efbec12c80",
   "metadata": {},
   "source": [
    "### Instantiate Weaviate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a440bd3e-1223-41c4-ad1a-0120273d9b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = WeaviateClient(os.environ['WEAVIATE_API_KEY'], os.environ['WEAVIATE_ENDPOINT'])\n",
    "\n",
    "#check if WCS instance is live and ready\n",
    "client.is_live(), client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9759ad5f-6e4b-4c33-bcbf-11949dc53158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Impact_theory_minilm_256', 'ImpactTest4', 'ImpactTest']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.show_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd43eef-e71d-4713-8664-6ebd14f076f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'Impact_theory_minilm_256'\n",
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"./data/training_dataset.json\")\n",
    "# val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "255bdabd-770e-4b12-8bd8-54e5cdc64f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_evaluation( dataset: Dict[str, List[str]], \n",
    "                        class_name: str, \n",
    "                        retriever: WeaviateClient,\n",
    "                        reranker: ReRanker=None,\n",
    "                        alpha: float=0.5,\n",
    "                        retrieve_limit: int=5,\n",
    "                        results_top_k: int=5,\n",
    "                        rerank_top_k: int=5,\n",
    "                        chunk_size: int=256,\n",
    "                        display_properties: List[str]=['doc_id', 'content']\n",
    "                        ) -> Tuple[int, int, int]:\n",
    "\n",
    "    if results_top_k > retrieve_limit:  # we don't want to retrieve less results than the top_k that we want to see returned\n",
    "        retrieve_limit = results_top_k\n",
    "        \n",
    "    reranker_name = reranker.model_name if reranker else \"None\"\n",
    "    \n",
    "    results_dict = {'n':retrieve_limit, \n",
    "                    'top_k': results_top_k,\n",
    "                    'alpha': alpha,\n",
    "                    'Retriever': retriever.model_name_or_path, \n",
    "                    'Ranker': reranker_name,\n",
    "                    'chunk_size': chunk_size,\n",
    "                    'kw_hit_rate': 0,\n",
    "                    'kw_mrr': 0,\n",
    "                    'vector_hit_rate': 0,\n",
    "                    'vector_mrr': 0,\n",
    "                    'hybrid_hit_rate':0,\n",
    "                    'hybrid_mrr': 0,\n",
    "                    'total_misses': 0,\n",
    "                    'total_questions':0\n",
    "                    }\n",
    "    if reranker:\n",
    "        results_dict['rerank_top_k'] = rerank_top_k  # have to build the results_dict before we can add this information\n",
    "    \n",
    "    for query_id, q in tqdm(dataset.queries.items(), 'Queries'):\n",
    "        results_dict['total_questions'] += 1\n",
    "        \n",
    "        #make Keyword, Vector, and Hybrid calls to Weaviate host\n",
    "        try:\n",
    "            kw_response = retriever.keyword_search(request=q, class_name=class_name, limit=retrieve_limit, display_properties=display_properties)\n",
    "            vector_response = retriever.vector_search(request=q, class_name=class_name, limit=retrieve_limit, display_properties=display_properties)\n",
    "            hybrid_response = retriever._hybrid_search(request=q, class_name=class_name, alpha=alpha, limit=retrieve_limit, display_properties=display_properties)           \n",
    "    \n",
    "            #rerank returned responses if reranker is provided\n",
    "            if reranker:\n",
    "                kw_response = reranker.rerank(kw_response, q, top_k=rerank_top_k)\n",
    "                vector_response = reranker.rerank(vector_response, q, top_k=rerank_top_k)\n",
    "                hybrid_response = reranker.rerank(hybrid_response, q, top_k=rerank_top_k)\n",
    "            \n",
    "            #collect doc_ids to check for document matches (include only results_top_k)\n",
    "            kw_doc_ids = {result['doc_id']:i for i, result in enumerate(kw_response[:results_top_k], 1)}\n",
    "            vector_doc_ids = {result['doc_id']:i for i, result in enumerate(vector_response[:results_top_k], 1)}\n",
    "            hybrid_doc_ids = {result['doc_id']:i for i, result in enumerate(hybrid_response[:results_top_k], 1)}\n",
    "            \n",
    "            #extract doc_id for scoring purposes\n",
    "            doc_id = dataset.relevant_docs[query_id][0]\n",
    "\n",
    "            #increment hit_rate counters and mrr scores\n",
    "            if doc_id in kw_doc_ids:\n",
    "                results_dict['kw_hit_rate'] += 1\n",
    "                results_dict['kw_mrr'] += 1/kw_doc_ids[doc_id]\n",
    "            if doc_id in vector_doc_ids:\n",
    "                results_dict['vector_hit_rate'] += 1\n",
    "                results_dict['vector_mrr'] += 1/vector_doc_ids[doc_id]\n",
    "            if doc_id in hybrid_doc_ids:\n",
    "                results_dict['hybrid_hit_rate'] += 1\n",
    "                results_dict['hybrid_mrr'] += 1/hybrid_doc_ids[doc_id]\n",
    "\n",
    "            # if no hits, let's capture that\n",
    "            else:\n",
    "                results_dict['total_misses'] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    #use raw counts to calculate final scores\n",
    "    calc_hit_rate_scores(results_dict)\n",
    "    calc_mrr_scores(results_dict)\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f9279571-40a0-4dfe-ba85-e76306eb96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(train_dataset.queries.items())[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa6c2a69-2f17-4b06-b046-4504ea953032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Queries: 100%|█████████████████████████████████████████████████████████████████| 250/250 [01:38<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.42 s, sys: 196 ms, total: 6.62 s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n': 5,\n",
       " 'top_k': 5,\n",
       " 'alpha': 0.3,\n",
       " 'Retriever': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       " 'Ranker': 'None',\n",
       " 'chunk_size': 256,\n",
       " 'kw_hit_rate': 0.68,\n",
       " 'kw_mrr': 0.55,\n",
       " 'vector_hit_rate': 0.39,\n",
       " 'vector_mrr': 0.29,\n",
       " 'hybrid_hit_rate': 0.71,\n",
       " 'hybrid_mrr': 0.56,\n",
       " 'total_misses': 73,\n",
       " 'total_questions': 250}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xb0\\x0c\\xc5(^/<Pc\\x8c\\xd8w\\xb1\\xba)j\\xf19 \"oZ[\\xb2\\xfe\\x0c\\xca\\x14_s\\x9505\\xc9XlG\\x1a\\x03\\x0bi\\x82\\x97\\xb5\\x9e\\xde(F\\x1f\\x12\\xd3\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00', b'\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00']\n",
      "Bad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01']\n",
      "Bad pipe message: %s [b'\\xe7\\n>\\t\\x17s`\\xcaL\\x8b\\xeea\\xa9\\xfce\\xba\\x9aN \\xa6^\\x04@u@\\xae/\\x84\\xf6fS\\xf2?\\xd7\\x8c\\x96\\xbfR\\xeb\\x85\\x91\\xc3\\x1c\\xc3UM\\x89nF\\xb5\\x86\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.']\n",
      "Bad pipe message: %s [b'\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08']\n",
      "Bad pipe message: %s [b'\\x08\\x08\\t\\x08\\n\\x08']\n",
      "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 F#\\x8a\\xebp9\\xecj\\xa6\\x9f\\x99%Y\\xbb\\x7f\\xfa\\x9e\\xe6\\x90\\xe5\\xd0^']\n",
      "Bad pipe message: %s [b\"n\\xf1!\\x9a\\x8a\\x8b3\\x9bz\\xd5jI\\x17\\x85\\x04\\xf6B\\xc0\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\", b'\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01']\n",
      "Bad pipe message: %s [b\"\\xbb\\xc4X\\t7\\xdf\\xc1?(\\xb2\\xbd_\\x99\\xf27\\xa8\\xe4|\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\"]\n",
      "Bad pipe message: %s [b'\\x06\\x01\\x03\\x03', b'\\x03', b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'r\\xef:G\\xf0%\\xd8-\\x80\\x02\\nO6\\xbe\\x15\\xbfe!\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00', b'\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00']\n",
      "Bad pipe message: %s [b'|Z\\xb2\\xd9\\xe9w\\x1f\\xba\\xf7\\x15\\xb6E\\xc4#\\xdf\\x14oy\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002']\n",
      "Bad pipe message: %s [b'\\xd57Q\\x80\\xcf\\xfd\\xdc;3\\xbaFSh\\xac\\x86\\xd92V\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x00']\n",
      "Bad pipe message: %s [b'2\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0']\n",
      "Bad pipe message: %s [b'\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16']\n",
      "Bad pipe message: %s [b\"\\xa2;\\x91q\\x88\\xa3\\x08\\xa39D\\xce\\x8c\\x8bD\\xa6\\xca\\xb73\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\", b'\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x00']\n",
      "Bad pipe message: %s [b'2\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b\"\\xaf\\x15u\\x93\\xfa\\xdfW\\x19\\xe0P\\xba\\xa0\\xb2a+\\xa2YB\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0\", b'\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00']\n",
      "Bad pipe message: %s [b'E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00;\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b']\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "execute_evaluation(train_dataset, class_name, client, alpha=0.3, retrieve_limit=5, results_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a528131-cd73-4fa4-95a5-6dd0b2b71ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Questions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:19<00:00,  2.78s/it]\n",
      "Questions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:18<00:00,  2.76s/it]\n",
      "Questions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:18<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 16s, sys: 3.32 s, total: 4min 20s\n",
      "Wall time: 6min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "for alpha in np.linspace(0,0.5,num=3):\n",
    "    result = execute_evaluation(dataset, client, reranker, index, alpha=alpha, limit=100, rerank_all_responses=True)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7c087ef-6572-4fda-8239-550ca3e4322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca368ee7-681e-44b6-bc74-d5c3777d663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'kw_hit_rate': 150, 'vector_hit_rate': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cdb20b6-78ba-4fc0-bc9e-09291073c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['kw', 'vector']:\n",
    "    results[f'{prefix}_hit_rate'] = round(results[f'{prefix}_hit_rate']/200,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b23da3ca-efed-4884-8c16-37fe73e5ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kw_hit_rate': 0.75, 'vector_hit_rate': 0.5}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394ea01-bcbc-420b-8b84-44d420ca2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n': 5,\n",
    " 'rerank_top_k': 5,\n",
    " 'alpha': 0,\n",
    " 'Retriever': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    " 'Ranker': 'None',\n",
    " 'chunk_size': 256,\n",
    " 'kw_hit_rate': 0.68,\n",
    " 'kw_mrr': 0.55,\n",
    " 'vector_hit_rate': 0.39,\n",
    " 'vector_mrr': 0.29,\n",
    " 'hybrid_hit_rate': 0.68,\n",
    " 'hybrid_mrr': 0.55,\n",
    " 'total_questions': 250}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
