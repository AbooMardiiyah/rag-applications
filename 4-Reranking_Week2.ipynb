{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9299e2fb-9f95-4690-b172-0d6e9b4952cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from opensearch_interface import OpenSearchClient\n",
    "from typing import List, Union\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from reranker import ReRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e934fe6-53e2-4720-8583-ba93018393b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReRanker:\n",
    "    '''\n",
    "    Cross-Encoder models achieve higher performance than Bi-Encoders, \n",
    "    however, they do not scale well to large datasets. The lack of scalability\n",
    "    is due to the underlying cross-attention mechanism, which is computationally\n",
    "    expensive.  Thus a Bi-Encoder is best used for 1st-stage document retrieval and \n",
    "    a Cross-Encoder is used to re-rank the retrieved documents. \n",
    "\n",
    "    https://www.sbert.net/examples/applications/cross-encoder/README.html\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name: str='cross-encoder/ms-marco-MiniLM-L-6-v2', local_files: bool=False):\n",
    "        self.model_name = model_name\n",
    "        self.model = CrossEncoder(self.model_name, automodel_args={'local_files_only':local_files})\n",
    "        self.score_field = 'cross_score'\n",
    "\n",
    "    def _cross_encoder_score(self, \n",
    "                             results: List[dict], \n",
    "                             query: str, \n",
    "                             cross_score_key: str='cross-score',\n",
    "                             return_scores: bool=False\n",
    "                             ) -> Union[np.array, None]:\n",
    "        '''\n",
    "        Given a list of hits from a Retriever:\n",
    "            1. Scores hits by passing query and results through CrossEncoder model. \n",
    "            2. Adds cross-score key to hits dictionary. \n",
    "            3. If desired returns np.array of Cross Encoder scores.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        results: List[dict]\n",
    "            List of search results from OpenSearch client.\n",
    "        query: str\n",
    "            User query.\n",
    "        cross_score_key: str='cross-score'\n",
    "            Name of key/field that the new calculated cross encoder score will be associated with.\n",
    "        return_scores: bool=False\n",
    "            If True, returns a np.array of cross encoder scores. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Either returns a np.array of cross encoder scores if \"return_scores\" is True, otherwise\n",
    "        nothing is returned.  The primary purpose of this function is to update the \"results\" dict. \n",
    "        '''\n",
    "        \n",
    "        #build query/content list \n",
    "        #create a list of lists that contains the query and the content field of each result from \"results\"\n",
    "        #important the cross_input variable must be a list of lists\n",
    "        cross_input = None\n",
    "        \n",
    "        #get scores\n",
    "        # Call the self.model's predict method to get predicted scores on the cross_input\n",
    "        # Output at this step will be a numpy matrix of cross-encoder scores\n",
    "        ######################################################################\n",
    "        # Example: \n",
    "        # array([ 1.3296969 ,  0.8297793 ,  1.2054391 ,  2.9448447 ,  2.7284985 ,\n",
    "        #         4.231843  , -1.6208533 ,  2.4096487 , -1.2081863 ,  2.9743905 ,\n",
    "        #         3.2194595 , -0.27501446,  1.5256095 ,  2.8193645 ,  1.5568736 ,\n",
    "        #         2.5138354 ,  1.9419916 ,  2.6341028 , -1.6115644 , -0.49818742,\n",
    "        #         3.695484  ,  2.93317   ,  3.1728778 , -0.5114989 , -4.076729  ], dtype=float32)\n",
    "\n",
    "        cross_scores = None\n",
    "\n",
    "        #enumerate through the results and update each dict with the cross_score_key arg as key and value as the new score:\n",
    "        #Example:\n",
    "             # {'cross-score' : 5.12345}\n",
    "        for i, result in enumerate(results):\n",
    "            None\n",
    "\n",
    "        if return_scores:\n",
    "            return cross_scores\n",
    "\n",
    "    def rerank(self, results: List[dict], query: str, top_k: int=10, threshold: float=None) -> List[dict]:\n",
    "        '''\n",
    "        Given a list of search results from OpenSearch client, results are scored with a Cross Encoder \n",
    "        and returned in sorted order by the cross_score field.  Threshold allows user to filter out \n",
    "        results that do not meet cross_score threshold value:\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        results: List[dict]\n",
    "            List of search results from OpenSearch client.\n",
    "        query: str\n",
    "            User query.\n",
    "        top_k: int=10\n",
    "            Number of reranked results to return\n",
    "        threshold: float=None\n",
    "            If None, top_k results will be returned.  \n",
    "            If float value is present, only results with a cross_score that meet or exceed the threshold\n",
    "            will be retuned.  This arg is present to prevent very low scoring document from being returned. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List of reranked search results. \n",
    "        '''\n",
    "        # call the internal _cross_encoder_score function (it's ok that nothing is returned here)\n",
    "        # the results dictionary is being updated \n",
    "        None\n",
    "\n",
    "        #sort results by the new cross-score field\n",
    "        sorted_hits = None\n",
    "\n",
    "        #if user wants to set a threshold we need to account for that\n",
    "        if threshold or threshold == 0:\n",
    "\n",
    "            #filter sorted_hits by the threshold value\n",
    "            filtered_hits = None\n",
    "            \n",
    "            if not any(filtered_hits):\n",
    "                logger.warning(f'No hits above threshold {threshold}. Returning top {top_k} hits.')\n",
    "                return sorted_hits[:top_k]\n",
    "            return filtered_hits\n",
    "            \n",
    "        #if no threshold was set return top_k sorted_hits\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d905c45-88ce-49a6-8ff7-fb7ae5934fac",
   "metadata": {},
   "source": [
    "### Instantiate the ReRanker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a4bf326-c463-4f82-a7ef-3585d66c23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d46d8fc-5bc8-42d2-8dae-ebe8c69cad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3296969 ,  0.8297793 ,  1.2054391 ,  2.9448447 ,  2.7284985 ,\n",
       "        4.231843  , -1.6208533 ,  2.4096487 , -1.2081863 ,  2.9743905 ,\n",
       "        3.2194595 , -0.27501446,  1.5256095 ,  2.8193645 ,  1.5568736 ,\n",
       "        2.5138354 ,  1.9419916 ,  2.6341028 , -1.6115644 , -0.49818742,\n",
       "        3.695484  ,  2.93317   ,  3.1728778 , -0.5114989 , -4.076729  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker._cross_encoder_score(response, query=query, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952a99df-a089-4fd8-b76d-2294fe70777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index name\n",
    "index_name = 'impact-theory-minilm-196'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7819bf44-faac-437f-8599-a44bb9b40040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set query\n",
    "query = \"how do I change my life for good\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8f05d-1503-4bed-b795-58166745e436",
   "metadata": {},
   "source": [
    "### Test ReRanker class by conducting a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd408c1-ab39-4e24-8161-286a3ba65882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
