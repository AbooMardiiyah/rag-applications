{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddf3f52-c9f4-4c33-99b7-90c968e36b37",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/vectorsearch-applications/1-Preprocess_Data_Week1.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bhumble-barnacle-q7j5xj47pv6346j4/workspaces/vectorsearch-applications/1-Preprocess_Data_Week1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bhumble-barnacle-q7j5xj47pv6346j4/workspaces/vectorsearch-applications/1-Preprocess_Data_Week1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bhumble-barnacle-q7j5xj47pv6346j4/workspaces/vectorsearch-applications/1-Preprocess_Data_Week1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdotenv\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bhumble-barnacle-q7j5xj47pv6346j4/workspaces/vectorsearch-applications/1-Preprocess_Data_Week1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# load_dotenv('./.env', override=True)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bhumble-barnacle-q7j5xj47pv6346j4/workspaces/vectorsearch-applications/1-Preprocess_Data_Week1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# load_dotenv('./.env', override=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from preprocessing import FileIO, Splitters, Vectorizor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.text_splitter import SentenceSplitter\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fc919-6968-48bd-a755-e0e470ab6639",
   "metadata": {},
   "source": [
    "## Step - 1: Import Podcast Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ccc38ee-5d39-495f-9722-c81e00f9dcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/impact_theory_metadata.json'\n",
    "with open(data_path) as f:\n",
    "    data =  json.load(f)\n",
    "    data = [d for d in data if d.get('content')]\n",
    "with open(data_path, 'w') as f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b51374-a217-4273-8414-6f276751f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e38b43-e4cd-483b-b221-97d932d391c4",
   "metadata": {},
   "source": [
    "### 2a.) Split Text into Sentences - LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a0505d-e45c-4920-a4d9-5de9ba380070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Dig into why text_splitter is using NLTK tokenizer under the hood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31cf5376-2e4b-4d18-b106-1d6d93761f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "196-128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6947c023-46b9-4d9a-b60d-d96c5d1fcca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=128, chunk_overlap=20)\n",
    "splitter = Splitters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2024ab7e-78e5-47dc-903f-897fde38cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Docs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [00:23<00:00, 16.68it/s]\n"
     ]
    }
   ],
   "source": [
    "split_dict = splitter.split_corpus(data, text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e058c81-3070-4e3c-a495-dc6082b41d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60380"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(split_dict[key]) for key in split_dict]\n",
    "sum(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4bb15-7493-446a-8963-f975c43a8c1f",
   "metadata": {},
   "source": [
    "### 2b.) Split Text into Sentences - SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5e060b8-3eaf-44f4-9d6a-6f5ece2f143b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n",
      "385\n",
      "CPU times: user 5.09 s, sys: 35.2 ms, total: 5.13 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "utils = Utilities()\n",
    "transcripts = [d.get('content', '') for d in data]\n",
    "print(len(transcripts))\n",
    "transcripts = [text for text in transcripts if text]\n",
    "print(len(transcripts))\n",
    "split_sentences = [utils.sentence_splitter(text) for text in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10169dc9-9429-4428-87ca-9b8f8f0a25ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>857.015584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>642.827887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5342.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count   385.000000\n",
       "mean    857.015584\n",
       "std     642.827887\n",
       "min       1.000000\n",
       "25%     469.000000\n",
       "50%     668.000000\n",
       "75%    1056.000000\n",
       "max    5342.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([len(corpus) for corpus in split_sentences]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fae97-f211-41b3-ad9c-05c6f66c7a24",
   "metadata": {},
   "source": [
    "### 3. Encode Chunks as Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89720b-8b68-44a8-8ee9-4c6c59f7b121",
   "metadata": {},
   "source": [
    "### 3a.) SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e26b5d8-f716-4712-ac11-ed047dc8bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbert = SentenceTransformer('all-MiniLM-L6-v2'). ##  35 seconds to encode all ImpactTheory \n",
    "\n",
    "# model = SentenceTransformer(model_path, device='cuda:0') ## 136 seconds to encode all ImpactTheory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cda8b5b-6523-402e-bdfa-207c8b379bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/elastic/notebooks/vector_search_applications/models/gte-base/' \n",
    "vectorizer = Vectorizor(model_name_or_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04a987d2-8fe1-4339-886d-c208d7d3eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Docs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [02:23<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 881 ms, total: 2min 41s\n",
      "Wall time: 2min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merged_dict = vectorizer.encode_from_dict(split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a5214304-bdeb-4c03-b369-866333915e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./gte_vectors.npy', gte_vectors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9555d7f7-31c0-4180-bb40-53fedd641577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60380"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectorizer.join_metadata(corpus=data, merged_dict=merged_dict, create_doc_id=True)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8b7563e-6a75-4583-a307-c49dc559aa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [d for d in docs if d['video_id'] == 'mrND5lSPEQU']\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb9ff354-5a00-449a-914e-8b1b44d6d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-12 20:19:15.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing\u001b[0m:\u001b[36msave_as_parquet\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mDataFrame saved as parquet file here: /home/elastic/notebooks/vector_search_applications/data/impact_theory_gte_128.parquet\u001b[0m\n",
      "Bad pipe message: %s [b\"q(\\xeaMV\\xab\\xc0\\x03\\xd3\\xaf\\x94<\\xc1\\xbe\\xd8\\x1a\\x8az\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\"]\n",
      "Bad pipe message: %s [b'B\\xa4\\x83\\x950y9\\xd2\\xbf\\x87\\x1b\\xfc\\x83\\x9e\\xd1\\x8bx\\x86\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001']\n",
      "Bad pipe message: %s [b'\\xac\\x143\\xff\\\\\\xfe\\xa7\\x7f\\xf5\\xf3M\\xabz\\x11=\\r\\x1a\\xb0\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00']\n",
      "Bad pipe message: %s [b'\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00']\n",
      "Bad pipe message: %s [b'\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01']\n",
      "Bad pipe message: %s [b\"|`\\xb7\\xe3^\\x98\\xf4\\x99wd\\x04\\xecc\\xa4-\\x19\\xbbr\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\", b' \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05']\n",
      "Bad pipe message: %s [b'\\x03', b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\n",
      "Bad pipe message: %s [b'\\x91\\xff+\\xa7\\x17\\xf2:\\x86\\xde\\xdb\\x1e\\xea\\xb4K\\xe7\\xd9\\xf8\\xef\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00']\n",
      "Bad pipe message: %s [b\"\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\"]\n",
      "Bad pipe message: %s [b'\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03']\n"
     ]
    }
   ],
   "source": [
    "io = FileIO()\n",
    "io.save_as_parquet(file_path='/home/elastic/notebooks/vector_search_applications/data/impact_theory_gte_128.parquet', data=docs, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd9599-57cd-4e58-9522-fab80917e256",
   "metadata": {},
   "source": [
    "### 3b.) OpenAI Ada Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73176902-10a2-48d9-a656-cecae55353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "model = \"text-embedding-ada-002\"\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "#get cost first\n",
    "tokenizer = Tokenizer(model_type=\"cl100k_base\", price=0.001)\n",
    "\n",
    "# cost = tokenizer.get_cost(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ac557e9-d176-47be-91cb-522978e64213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2b06f-fa71-424b-a142-46934ec03a0f",
   "metadata": {},
   "source": [
    "#### Working around OpenAI rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec0d7eb4-c13c-4733-8b56-13ffba68e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 890642\tCost: 0.891\n",
      "Total Tokens: 889149\tCost: 0.889\n",
      "Total Tokens: 892516\tCost: 0.893\n",
      "Total Tokens: 887084\tCost: 0.887\n",
      "Total Tokens: 892144\tCost: 0.892\n",
      "Total Tokens: 887583\tCost: 0.888\n",
      "Total Tokens: 876077\tCost: 0.876\n",
      "Total Tokens: 126477\tCost: 0.126\n"
     ]
    }
   ],
   "source": [
    "#split text_chunks into roughly 1 million tokens total per group\n",
    "for num in range(0,43000,6000):\n",
    "    chunks = text_chunks[num:num+6000]\n",
    "    cost = tokenizer.get_cost(chunks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d1931e2-6607-4753-ba62-5f61572d4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.Embedding.create(text_chunks[:2], engine=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec1f3bc3-96c6-4ebd-8900-292569895e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37271dc7-c403-4ba8-8aac-965a7f7f08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# embeddings = []\n",
    "# for num in range(0,43000,6000):\n",
    "#     chunks = text_chunks[num:num+6000]\n",
    "#     results = openai.Embedding.create(input=chunks, engine=model)\n",
    "#     embeddings.append(results)\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee740130-1532-4698-905b-d8f467f678c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = results['data']\n",
    "vectors = [vec['embedding'] for vec in vectors]\n",
    "len(vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
