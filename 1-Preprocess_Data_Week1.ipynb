{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddf3f52-c9f4-4c33-99b7-90c968e36b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# load_dotenv('./.env', override=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from preprocessing import FileIO, Vectorizor, Splitters\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.text_splitter import SentenceSplitter\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fc919-6968-48bd-a755-e0e470ab6639",
   "metadata": {},
   "source": [
    "## Step 1 -->  Import Podcast Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccc38ee-5d39-495f-9722-c81e00f9dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/impact_theory_metadata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b51374-a217-4273-8414-6f276751f79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#should see 385 unique podcast entries \n",
    "with open(data_path) as f:\n",
    "    data =  json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9700bbde-d02b-49b4-bed4-f3b4772aa00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12884.654545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7741.439730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1819.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9899.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16860.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48502.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lengths\n",
       "count    385.000000\n",
       "mean   12884.654545\n",
       "std     7741.439730\n",
       "min     1819.000000\n",
       "25%     7891.000000\n",
       "50%     9899.000000\n",
       "75%    16860.000000\n",
       "max    48502.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's get some rough statistics on the content lengths of each podcast\n",
    "lens = [len(d['content'].split()) for d in data]\n",
    "df = pd.DataFrame(lens, columns=['Lengths'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df07acc-5aea-4d76-9574-4457c61f4723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Tom Bilyeu',\n",
       " 'title': '\"Real Life SEX ROBOTS Are Coming...\" - The Dangers Of Seductive AI | Mo Gawdat',\n",
       " 'video_id': 'IK9lN__kBXs',\n",
       " 'playlist_id': 'PL8qcvQ7Byc3OJ02hbWJbHWePh4XEg3cvo',\n",
       " 'channel_id': 'UCnYMOamNKLGVlJgRUbamveA',\n",
       " 'description': 'No description provided',\n",
       " 'keywords': [],\n",
       " 'length': 684,\n",
       " 'publish_date': '07-08-2023',\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/IK9lN__kBXs/hq720.jpg',\n",
       " 'views': 61134,\n",
       " 'age_restricted': False,\n",
       " 'content': \"what are the near-term disruptions? The one that freaks me out, and every time I talk to a parent with a teenage boy, I'm like, your kid is like, sex robots are really gonna be a thing for them, like for real, for real. I worry if I grew up five years from now, I would not graduate from high school. I would just find a sex robot and go into oblivion. What are one, what do you think is the reality of that one in particular? And then I'd love to branch out to some others. So the word robot is interesting, but sex alternatives, for sure. I mean, get yourself an Apple Vision Pro or a Quest 3 and see how realistic your desired other gender is, right? It's just incredible. I mean, again, just think about all of the illusions that we're now unable to decipher illusion from truth, right? Sex happens in the brain at the end of the day. I mean, the physical side of it is not that difficult to simulate, okay? But if we can convince you that this sex robot is alive or that sex experience in a virtual reality headset or an augmented reality headset is alive, is real, then there you go. Go a few years further and think of Neuralink and other ways of connecting directly to your nervous system. And why would you need another being in the first place? You know, that's actually quite messy. It's all signals in your brain that you enjoy companionship and sexuality. And if you really want to take the magic out of it, okay, yeah, it can be simulated. Just like we can now simulate very, very easily how to move muscles. And, you know, there are so many ways where you can copy the brain signals that would move your hand in a certain way and just, you know, give it back to your hand and it will move the same way. It's not that complicated. There are, you know, so that whole idea of interacting with a totally new form of being. And once again, there is that huge debate of are they sentient or not? Does it really matter if they're simulating sentientism so well, okay? Does it really matter if the Morgan Freeman talking to you on the screen is actually Morgan Freeman or an AI-generated avatar if you're convinced that it is Morgan Freeman? This is the whole game. The whole game is we get lost in those conversations of, you know, are they alive? Are they sentient? It doesn't matter. If my brain believes they are, they are. And we're getting there. We're getting there so quickly. Companionship in general. I mean, there was a release of ChatGPT on Snapchat, okay? And kids chat with it as a friend. They don't really, I mean, of course they do somewhere deep in their mind distinguish that this is not really a human, but what do they care? The other person on the other side was never a human anyway. It was just a stream of texts and emojis and funny images. Wow. Yeah. So, and again, look, I'm an old man. I used a rotary phone in my young years. I coded mainframes. But when you really think about it, as much as I never imagined and I resisted, you know, should my kids have tablets or not? Should I have a free-to-air satellite television at home or not every time a new technology was coming out? And eventually we all managed to live with this. But let's just say this is a very significant redesign of society. It's a very significant redesign of love and relationships. And because there is money in it, what would prevent the next dating app from giving you avatars to date? There is money in it. A lot of people will try it. There are more than 2 million people on replica. Whoa. Given how many deaths of despair there are, do you think that that will ultimately be for better or worse that AI will be able to provide companionship for anybody that needs it? It's just eerie. I don't know if it's better or worse. I mean, I have a friend that I met for the first time at a concert in the UK, and we just had a wonderful time, and we haven't met since. But we chat all the time on Instagram, or sorry, on WhatsApp or whatever. And it's wonderful. It feels like a wonderful connection. If I didn't know it was a human, but the chat was that same quality, would it improve my human experience? A little bit. But has all of that small screen interaction improved humanity at large? The consensus is it hasn't, that we're more lonely today, even though we have 10x more friends on our friends list, that teen suicide is at an all-time high, that female suicide is at an all-time high. Obviously, the companies that will create those things will position them as the noble approach to help humanity. But at the end of the day, read Freakonomics. This is the noble approach for the company to make more money. That's it, right? Well, we want to sell it as this is good for humanity so that we hire more developers, and we convince the consumers, and we can stand on TED Talk stages and give larger-than-life speeches and so on. But end of the day, it's all about making more money. And I think reality is it's not good for humanity so far, so again, if you extrapolate that chart, it's going to be worse for humanity. Long-term, I don't know. Maybe those robots will be much nicer than a girlfriend. I don't know. So I've heard you use the example a lot of times. In fact, you mentioned it in this interview that you want to give AI the sort of value system of, gosh, it's somewhere in India, where you said people would come to the US, they would get educated to get these incredibly high-paying jobs, wildly intelligent people. You'd ping them to go grab a coffee, and they're like, oh, I've moved back to India. Why? To take care of my parents, just self-evident. So I don't have kids, and one of the things that I've really had to think about is when I'm 80, that ain't going to be cool. I'm not going to have somebody that's coming by to check up on me. And I just thought, oh, by the time I'm 80, assuming that the robots don't kill us, I'll be able to wear whatever the Apple Vision Pro of the moment is. And when the robot walks into my room, it will look exactly like the avatar looks through my glasses, and it will be able to care for me. I'll build a relationship with it over time. It will be tailored to my wants and desires. So it'll become the best of the best friends that I could ever hope for, or I could even program it to be like a child to me. And so it is like my kids coming to visit, whenever I want them to. I won't lie. It is, I definitely don't think it's better than kids. And I think that most people should have kids. I want to be very clear. But at the same time, given that I did not have kids, I am very grateful that the odds of something like that existing border on 100%. What do you think about that? Is that going to be like, does that further crater population problems because people are going to go, oh, Tom's right. I don't need to have kids. I don't need to have AI kids. Can I answer that question with my heart, not my brain? So the soul that you spoke to, it's the blue pill, red pill, right? It's the blue pill, red pill. And I think it's a very interesting philosophical question of should Neo have ever taken the red pill? You know, he had a life, okay? And the issue with humanity at large, Tom, is that we have failed because of how much life has spoiled us to accept what life gives us, okay? And in my other work on happiness, I will tell you openly that happiness is not getting what you want. It's not about getting what you want. It's about loving what you have, okay? And so the more we fall in that trap of make my life easier, make my life easier, make my life easier, make my life easier, there will always be something in that life that is not easier, okay? You know, there was that movie, I don't remember what it was, or I maybe heard of it, where, you know, someone dies, goes to heaven, and then gets like a wish. And basically the wish is, I wanna be a winner in the Vegas casino. So he spends every day, he walks into the casino and makes money and makes money and makes money. And as he makes money, you know, more girls are interested in him and da, da, da, da, da. And then eventually he starts to wake up one day and say, can I not lose money someday? Like, this is really boring, okay? Humans, we are who we are. It's not getting more things. It's not the tech company's approach of let's make things easier all the time that's ever gonna make us happier. You gotta give people the punchline of that episode. It's absolutely phenomenal. Yeah, it is. There is a point at which more progress is hurting us at the community level. It's also hurting us at the individual's ability to stay healthy when life is not what we want. And life is about to become a lot different than what we want, just because we constantly want more and more and more. Life, at the end of the day, I just always want to remind people that there is no other way in my mind. I mean, I want to be proven wrong. Please prove me wrong. That the separation of power and wealth that is about to come in a world with such a superpower is science fiction-like, okay? That the challenge to jobs and income and purpose is science fiction-like. These are very dystopian images of society. What for? Because we want our vision pro to create a reality that is not our reality. If you want to learn more about this topic, check out this interview. We've never created a nuclear weapon that can create nuclear weapons. The artificial intelligences that we're building are capable of creating other artificial intelligences. As a matter of fact, they're encouraged to create other artificial intelligences, even if...\\n\",\n",
       " 'episode_num': 376}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peek at what a data entry looks like (use shortest transcript)\n",
    "data[np.argmin(df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e38b43-e4cd-483b-b221-97d932d391c4",
   "metadata": {},
   "source": [
    "## Step 2 -->  Split Text into Sentences - LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a0505d-e45c-4920-a4d9-5de9ba380070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Dig into why text_splitter is using NLTK tokenizer under the hood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6947c023-46b9-4d9a-b60d-d96c5d1fcca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discussion on chunk size\n",
    "chunk_size = 196\n",
    "splitter = Splitters()\n",
    "text_splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2024ab7e-78e5-47dc-903f-897fde38cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Docs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [00:21<00:00, 18.09it/s]\n"
     ]
    }
   ],
   "source": [
    "split_dict = splitter.split_corpus(data, text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e058c81-3070-4e3c-a495-dc6082b41d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37007"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(split_dict[key]) for key in split_dict]\n",
    "sum(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fae97-f211-41b3-ad9c-05c6f66c7a24",
   "metadata": {},
   "source": [
    "## Step 3 -->  Encode Chunks as Vectors (Transfer to Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89720b-8b68-44a8-8ee9-4c6c59f7b121",
   "metadata": {},
   "source": [
    "### 3a.) SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e26b5d8-f716-4712-ac11-ed047dc8bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbert = SentenceTransformer('all-MiniLM-L6-v2'). ##  35 seconds to encode all ImpactTheory \n",
    "# model = SentenceTransformer(model_path, device='cuda:0') ## 136 seconds to encode all ImpactTheory\n",
    "model = SentenceTransformer('thenlper/gte-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cda8b5b-6523-402e-bdfa-207c8b379bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'thenlper/gte-base'\n",
    "base_model = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "vectorizer = Vectorizor(model_name_or_path=base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de75f273-13f6-40d7-91c1-205e081248c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [00:52<00:00,  5.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# CPU demonstration\n",
    "%%time\n",
    "vectors = []\n",
    "from tqdm import tqdm\n",
    "for sent in tqdm(split_dict[0]):\n",
    "    vectors.append(model.encode(sent, device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f786a6-23ae-4d58-8e1d-518ed60b1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 280)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors), len(split_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04a987d2-8fe1-4339-886d-c208d7d3eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Docs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [14:39<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 7min 59s, sys: 6min 2s, total: 1h 14min 2s\n",
      "Wall time: 14min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## GPU demonstration\n",
    "merged_dict = vectorizer.encode_from_dict(split_dict, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4652663-d071-423b-8fd2-9c1a5a4dffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "385/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a5214304-bdeb-4c03-b369-866333915e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./gte_vectors.npy', gte_vectors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9555d7f7-31c0-4180-bb40-53fedd641577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9055"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectorizer.join_metadata(corpus=data, merged_dict=merged_dict, create_doc_id=True)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8b7563e-6a75-4583-a307-c49dc559aa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [d for d in docs if d['video_id'] == 'mrND5lSPEQU']\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb9ff354-5a00-449a-914e-8b1b44d6d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-12 20:19:15.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing\u001b[0m:\u001b[36msave_as_parquet\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mDataFrame saved as parquet file here: /home/elastic/notebooks/vector_search_applications/data/impact_theory_gte_128.parquet\u001b[0m\n",
      "Bad pipe message: %s [b\"q(\\xeaMV\\xab\\xc0\\x03\\xd3\\xaf\\x94<\\xc1\\xbe\\xd8\\x1a\\x8az\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\"]\n",
      "Bad pipe message: %s [b'B\\xa4\\x83\\x950y9\\xd2\\xbf\\x87\\x1b\\xfc\\x83\\x9e\\xd1\\x8bx\\x86\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001']\n",
      "Bad pipe message: %s [b'\\xac\\x143\\xff\\\\\\xfe\\xa7\\x7f\\xf5\\xf3M\\xabz\\x11=\\r\\x1a\\xb0\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00']\n",
      "Bad pipe message: %s [b'\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00']\n",
      "Bad pipe message: %s [b'\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01']\n",
      "Bad pipe message: %s [b\"|`\\xb7\\xe3^\\x98\\xf4\\x99wd\\x04\\xecc\\xa4-\\x19\\xbbr\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\", b' \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05']\n",
      "Bad pipe message: %s [b'\\x03', b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\n",
      "Bad pipe message: %s [b'\\x91\\xff+\\xa7\\x17\\xf2:\\x86\\xde\\xdb\\x1e\\xea\\xb4K\\xe7\\xd9\\xf8\\xef\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00']\n",
      "Bad pipe message: %s [b\"\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\"]\n",
      "Bad pipe message: %s [b'\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03']\n"
     ]
    }
   ],
   "source": [
    "io = FileIO()\n",
    "io.save_as_parquet(file_path=f'/home/elastic/notebooks/vector_search_applications/data/impact_theory_gte_{chunk_size}.parquet', data=docs, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd9599-57cd-4e58-9522-fab80917e256",
   "metadata": {},
   "source": [
    "## Step - 3.1 --> OPTIONAL: OpenAI Ada Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73176902-10a2-48d9-a656-cecae55353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "model = \"text-embedding-ada-002\"\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "#get cost first\n",
    "tokenizer = Tokenizer(model_type=\"cl100k_base\", price=0.001)\n",
    "\n",
    "# cost = tokenizer.get_cost(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ac557e9-d176-47be-91cb-522978e64213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2b06f-fa71-424b-a142-46934ec03a0f",
   "metadata": {},
   "source": [
    "#### Working around OpenAI rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec0d7eb4-c13c-4733-8b56-13ffba68e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 890642\tCost: 0.891\n",
      "Total Tokens: 889149\tCost: 0.889\n",
      "Total Tokens: 892516\tCost: 0.893\n",
      "Total Tokens: 887084\tCost: 0.887\n",
      "Total Tokens: 892144\tCost: 0.892\n",
      "Total Tokens: 887583\tCost: 0.888\n",
      "Total Tokens: 876077\tCost: 0.876\n",
      "Total Tokens: 126477\tCost: 0.126\n"
     ]
    }
   ],
   "source": [
    "#split text_chunks into roughly 1 million tokens total per group\n",
    "for num in range(0,43000,6000):\n",
    "    chunks = text_chunks[num:num+6000]\n",
    "    cost = tokenizer.get_cost(chunks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d1931e2-6607-4753-ba62-5f61572d4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.Embedding.create(text_chunks[:2], engine=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec1f3bc3-96c6-4ebd-8900-292569895e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37271dc7-c403-4ba8-8aac-965a7f7f08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# embeddings = []\n",
    "# for num in range(0,43000,6000):\n",
    "#     chunks = text_chunks[num:num+6000]\n",
    "#     results = openai.Embedding.create(input=chunks, engine=model)\n",
    "#     embeddings.append(results)\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee740130-1532-4698-905b-d8f467f678c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = results['data']\n",
    "vectors = [vec['embedding'] for vec in vectors]\n",
    "len(vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
