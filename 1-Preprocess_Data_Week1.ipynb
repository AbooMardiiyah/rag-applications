{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddf3f52-c9f4-4c33-99b7-90c968e36b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# load_dotenv('./.env', override=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from preprocessing import FileIO, Vectorizor, Splitters, Utilities\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.text_splitter import SentenceSplitter\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tiktoken impo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fc919-6968-48bd-a755-e0e470ab6639",
   "metadata": {},
   "source": [
    "## Step 1 -->  Import Podcast Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c181bb89-7215-49a9-a2c1-562225385f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/impact_theory_data.json'\n",
    "\n",
    "#should see 385 unique podcast entries \n",
    "with open(data_path) as f:\n",
    "    data =  json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9700bbde-d02b-49b4-bed4-f3b4772aa00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>16860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lengths\n",
       "94    16860"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's get some rough statistics on the content lengths of each podcast\n",
    "lens = [len(d['content'].split()) for d in data]\n",
    "df = pd.DataFrame(lens, columns=['Lengths'])\n",
    "df[df['Lengths'] == 16860]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb59dda-00d9-4cc3-b3db-f6c6ae33f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df07acc-5aea-4d76-9574-4457c61f4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#peek at what a data entry looks like (use shortest transcript)\n",
    "# data[np.argmin(df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e38b43-e4cd-483b-b221-97d932d391c4",
   "metadata": {},
   "source": [
    "## Step 2 -->  Split Text into Sentences - LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187304eb-2b37-470f-9ade-17ff75a519f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import tiktoken # bad ass tokenizer library for use with OpenAI LLMs \n",
    "from llama_index.text_splitter import SentenceSplitter #one of the best on the market\n",
    "\n",
    "#instantiate tokenzier for our embedding model of choice\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "#instantiate tokenizer for use with ChatGPT-3.5-Turbo\n",
    "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "\n",
    "#set chunk size and instantiate three SentenceSplitters \n",
    "chunk_size = 256\n",
    "default_txt_splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "allmini_txt_splitter = SentenceSplitter(chunk_size=chunk_size, tokenizer=tokenizer.encode, chunk_overlap=0)\n",
    "gpt35_txt_splitter   = SentenceSplitter(chunk_size=chunk_size, tokenizer=encoding.encode, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2024ab7e-78e5-47dc-903f-897fde38cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assingnment_1_1(data, gpt35_txt_splitter, content_field='content'):\n",
    "    return [gpt35_txt_splitter.split_text(d[content_field]) for d in tqdm(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f3271b-703b-4992-a85d-dc5330d73851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [00:30<00:00, 12.73it/s]\n"
     ]
    }
   ],
   "source": [
    "splits = assingnment_1_1(data, gpt35_txt_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e058c81-3070-4e3c-a495-dc6082b41d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.215584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.037964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>269.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  385.000000\n",
       "mean    69.215584\n",
       "std     42.037964\n",
       "min     10.000000\n",
       "25%     42.000000\n",
       "50%     53.000000\n",
       "75%     90.000000\n",
       "max    269.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(chunk) for chunk in split_dict]\n",
    "pd.DataFrame(lens).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fae97-f211-41b3-ad9c-05c6f66c7a24",
   "metadata": {},
   "source": [
    "## Step 3 -->  Encode Chunks as Vectors (Transfer to Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89720b-8b68-44a8-8ee9-4c6c59f7b121",
   "metadata": {},
   "source": [
    "### 3a.) SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cda8b5b-6523-402e-bdfa-207c8b379bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'thenlper/gte-base'\n",
    "base_model = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de75f273-13f6-40d7-91c1-205e081248c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [00:52<00:00,  5.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# # CPU demonstration\n",
    "# %%time\n",
    "# vectors = []\n",
    "# from tqdm import tqdm\n",
    "# for sent in tqdm(split_dict[0]):\n",
    "#     vectors.append(model.encode(sent, device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f786a6-23ae-4d58-8e1d-518ed60b1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 280)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(vectors), len(split_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a987d2-8fe1-4339-886d-c208d7d3eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [00:32<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.4 s, sys: 697 ms, total: 47 s\n",
      "Wall time: 32.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## GPU demonstration\n",
    "def assignment_1_2(content_splits: List[List[str]], model: SentenceTransformer):\n",
    "    text_vector_tuples = []\n",
    "    for chunk in tqdm(content_splits):\n",
    "        vectors = model.encode(chunk, show_progress_bar=False, device='cuda:0')\n",
    "        text_vector_tuples.append(list(zip(chunk, vectors)))\n",
    "    return text_vector_tuples\n",
    "\n",
    "tvt = assignment_1_2(splits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9555d7f7-31c0-4180-bb40-53fedd641577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26648"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join(corpus, tuples):\n",
    "    docs = []\n",
    "    for i, d in enumerate(corpus):\n",
    "        for j, episode in enumerate(tuples[i]):\n",
    "            doc = {k:v for k,v in d.items() if k != 'content'}\n",
    "            video_id = doc['video_id']\n",
    "            doc['doc_id'] = f'{video_id}_{j}'\n",
    "            doc['content'] = episode[0]\n",
    "            doc['content_embedding'] = episode[1]\n",
    "            docs.append(doc)\n",
    "    return docs\n",
    "docs = join(data, tvt)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8b7563e-6a75-4583-a307-c49dc559aa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb9ff354-5a00-449a-914e-8b1b44d6d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-11 01:36:15.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing\u001b[0m:\u001b[36msave_as_parquet\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mDataFrame saved as parquet file here: /home/elastic/notebooks/vector_search_applications/practice_data/impact_theory_minilm_256.parquet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "io = FileIO()\n",
    "io.save_as_parquet(file_path=f'/home/elastic/notebooks/vector_search_applications/practice_data/impact_theory_minilm_{chunk_size}.parquet', data=docs, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd9599-57cd-4e58-9522-fab80917e256",
   "metadata": {},
   "source": [
    "## Step - 3.1 --> OPTIONAL: OpenAI Ada Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73176902-10a2-48d9-a656-cecae55353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "model = \"text-embedding-ada-002\"\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "#get cost first\n",
    "tokenizer = Tokenizer(model_type=\"cl100k_base\", price=0.001)\n",
    "\n",
    "# cost = tokenizer.get_cost(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ac557e9-d176-47be-91cb-522978e64213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2b06f-fa71-424b-a142-46934ec03a0f",
   "metadata": {},
   "source": [
    "#### Working around OpenAI rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec0d7eb4-c13c-4733-8b56-13ffba68e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 890642\tCost: 0.891\n",
      "Total Tokens: 889149\tCost: 0.889\n",
      "Total Tokens: 892516\tCost: 0.893\n",
      "Total Tokens: 887084\tCost: 0.887\n",
      "Total Tokens: 892144\tCost: 0.892\n",
      "Total Tokens: 887583\tCost: 0.888\n",
      "Total Tokens: 876077\tCost: 0.876\n",
      "Total Tokens: 126477\tCost: 0.126\n"
     ]
    }
   ],
   "source": [
    "#split text_chunks into roughly 1 million tokens total per group\n",
    "for num in range(0,43000,6000):\n",
    "    chunks = text_chunks[num:num+6000]\n",
    "    cost = tokenizer.get_cost(chunks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d1931e2-6607-4753-ba62-5f61572d4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.Embedding.create(text_chunks[:2], engine=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec1f3bc3-96c6-4ebd-8900-292569895e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37271dc7-c403-4ba8-8aac-965a7f7f08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# embeddings = []\n",
    "# for num in range(0,43000,6000):\n",
    "#     chunks = text_chunks[num:num+6000]\n",
    "#     results = openai.Embedding.create(input=chunks, engine=model)\n",
    "#     embeddings.append(results)\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee740130-1532-4698-905b-d8f467f678c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = '''\n",
    "In the Impact Theory episode featuring Ray Dalio, a renowned billionaire investor and hedge fund manager, a wide range of topics is explored, with a central focus on the global economic landscape and the challenges it currently faces. The conversation between Tom Bilyeu and Ray Dalio delves into various aspects of economics, geopolitics, and the dynamics that shape our world today.\n",
    "\n",
    "One of the primary concerns highlighted in the discussion is the vulnerability of the U.S. dollar. Ray Dalio expresses his unease regarding the ongoing international efforts by the BRICS nations (Brazil, Russia, India, China, and South Africa) to reduce their reliance on the dollar as the world's primary reserve currency. He emphasizes that this shift is not an outright attack on the dollar but rather a reflection of the changing economic landscape.\n",
    "\n",
    "Dalio draws parallels between historical events where other reserve currencies, such as the British pound and the Dutch guilder, lost their dominance due to a combination of factors, including holding excessive amounts of the currency and concerns over potential sanctions. He explains that countries are now looking for alternatives to transact in, driven by a desire to avoid the risks associated with holding large amounts of dollar-denominated debt and the potential for sanctions.\n",
    "\n",
    "The discussion also touches on the importance of financial responsibility for countries, suggesting that being financially strong is crucial in this evolving global environment. The idea of externalizing inflation through currency devaluation is explored, along with the complex interplay between interest rates, money printing, and fiscal responsibility.\n",
    "\n",
    "Throughout the conversation, Ray Dalio emphasizes that understanding the historical context and the cyclical nature of economic events is crucial. He advocates for principles like strong family structures, quality education, and equal opportunities as foundational elements for a thriving middle class and a prosperous society. However, he acknowledges that achieving these principles in today's complex world is challenging, particularly when it comes to addressing issues like education inequality and poverty.\n",
    "\n",
    "In summary, the Impact Theory episode featuring Ray Dalio provides valuable insights into the current state of the global economy and the challenges it faces. Dalio's expertise and historical perspective shed light on the potential vulnerabilities of the U.S. dollar and the importance of financial responsibility for nations. The conversation serves as a reminder of the complex interplay of economic forces, geopolitics, and social factors that shape our world, and it underscores the significance of addressing these challenges to ensure a prosperous future.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc49a9e3-6d89-4388-8cbe-97571530bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(episode.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c774ac-f28f-4742-901f-f79f771a13c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
