{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d8b53d-f1ef-47f1-90cb-174614c39ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9093ed76-8448-4008-9197-61880661f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q trulens-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35eb1a6-3af0-4c83-b271-9b81dca982ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "envs = load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd75b5d-15b0-4a51-aa0a-546326bf64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "university_info = \"\"\"\n",
    "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
    "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
    "As the flagship institution of the six public universities in Washington state,\n",
    "UW encompasses over 500 buildings and 20 million square feet of space,\n",
    "including one of the largest library systems in the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf358ffc-d36c-4684-a7f7-470b17584099",
   "metadata": {},
   "outputs": [],
   "source": [
    "harvard = \"\"\"\n",
    "Harvard University is a private Ivy League research university in Cambridge, Massachusetts. Founded in 1636 as Harvard College and named for its first benefactor, Puritan clergyman John Harvard, it is the oldest institution of higher learning in the United States. Its influence, wealth, and rankings have made it one of the most prestigious universities in the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f22891-764e-4a9b-b0d3-44b683fad762",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba827235-03f1-4d08-b2ad-71c11fc95d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = oai_client.embeddings.create(model='text-embedding-ada-002', input=university_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f45defa-dad9-4cc6-89d7-9edafa2aee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_array = embedding.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbd44172-e75b-42f2-8a66-bb66d9ba2bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trulens_eval.feedback.provider.openai.OpenAI"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_client.chat.completions.create("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bfcd32-8a99-4aee-8ce9-17172f9be410",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddingFunction(api_key=os.environ.get('OPENAI_API_KEY'),\n",
    "                                             model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(name=\"Universities\",\n",
    "                                                      embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb45512-1fe0-44ca-a1ed-db3a4e6e3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\"uni_info\", documents=university_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "688a2a1e-233d-4344-a35c-4ec80ef9998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: harvard\n",
      "Insert of existing embedding ID: harvard\n"
     ]
    }
   ],
   "source": [
    "vector_store.add('harvard', documents=harvard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a10efd7-2fdd-4b5e-9589-21663d068137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package langchain-community is installed but has a version conflict:\n",
      "\t(langchain-community 0.0.13 (/opt/anaconda3/envs/vsa/lib/python3.10/site-packages), Requirement.parse('langchain_community>=0.0.17'))\n",
      "\n",
      "This package is optional for trulens_eval so this may not be a problem but if\n",
      "you need to use the related optional features and find there are errors, you\n",
      "will need to resolve the conflict:\n",
      "\n",
      "    ```bash\n",
      "    pip install 'langchain_community>=0.0.17'\n",
      "    ```\n",
      "\n",
      "If you are running trulens_eval in a notebook, you may need to restart the\n",
      "kernel after resolving the conflict. If your distribution is in a bad place\n",
      "beyond this package, you may need to reinstall trulens_eval so that all of the\n",
      "dependencies get installed and hopefully corrected:\n",
      "    \n",
      "    ```bash\n",
      "    pip uninstall -y trulens_eval\n",
      "    pip install trulens_eval\n",
      "    ```\n",
      "\n",
      "Using legacy llama_index version 0.9.29. Consider upgrading to 0.10.0 or later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15fefef1-5e98-447b-b85f-d6dfedde8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_from_scratch:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "        query_texts=query,\n",
    "        n_results=2\n",
    "    )\n",
    "        return results['documents'][0]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\": \n",
    "            f\"We have provided context information below. \\n\"\n",
    "            f\"---------------------\\n\"\n",
    "            f\"{context_str}\"\n",
    "            f\"\\n---------------------\\n\"\n",
    "            f\"Given this information, please answer the question: {query}\"\n",
    "            }\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4229d777-98f6-45d8-b433-ba3dd9b3a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
      "âœ… In Context Relevance, input context will be set to __record__.app.retrieve.rets.collect() .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback.provider.openai import OpenAI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "provider = OpenAI()\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=provider)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a587446-ba99-4831-8ee6-b57a3fb25949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'RAG v1',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f98cf9ed-10a1-4ee6-802b-960f6a6e1365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40dc437bdba42b19028b940a9b0ddbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_rag as recording:\n",
    "    rag.query(\"When was the University of Washington founded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eaeb367-ecb0-43dc-91db-b92d655840c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Groundedness  Context Relevance  Answer Relevance  latency  total_cost\n",
       "app_id                                                                        \n",
       "RAG v1           0.0                0.9               1.0      1.0    0.000316"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[\"RAG v1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c190a3fd-5c10-4b22-a986-7b4771d779b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e015308b73e4b09b81c03bca4620627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.26:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c3507-1635-4c66-825e-f0bedb0fe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "Groundedness("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsa",
   "language": "python",
   "name": "vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
