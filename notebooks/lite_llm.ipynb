{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0483dc-785e-4286-9870-91567bc1ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa8105b-32f0-4686-8df5-54542797602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 03:00:45.068 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-26 03:00:45.070 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "envs = load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from litellm import batch_completion\n",
    "from src.database.database_utils import get_weaviate_client\n",
    "from src.llm.llm_interface import LLM\n",
    "from src.llm.llm_utils import get_token_count, load_azure_openai\n",
    "from src.llm.prompt_templates import huberman_system_message\n",
    "from src.preprocessor.preprocessing import FileIO\n",
    "from app_features import generate_prompt_series\n",
    "import os\n",
    "import re\n",
    "import tiktoken\n",
    "from tiktoken import Encoding\n",
    "from rich import print\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3103fa2-f5b8-4036-bfef-56994e1e1acb",
   "metadata": {},
   "source": [
    "### Set Constants\n",
    "---\n",
    "\n",
    "### Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e325cb21-c86c-4404-80d8-3b39af8ef9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Huberman_minilm_128'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Huberman_minilm_256'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Huberman_minilm_512'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Huberman_subset_minilm_test'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'Huberman_minilm_128'\u001b[0m, \u001b[32m'Huberman_minilm_256'\u001b[0m, \u001b[32m'Huberman_minilm_512'\u001b[0m, \u001b[32m'Huberman_subset_minilm_test'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get weaviate client\n",
    "\n",
    "weave_client = get_weaviate_client()\n",
    "collections = weave_client.show_all_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2d106-0f96-42fb-a00d-a5a493b3d957",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad60d040-3e93-41e6-b489-86529617fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_model = \"gpt-3.5-turbo-0125\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "azure_model = \"gpt-35-turbo\" #\"gpt-4-32k\"\n",
    "cohere_model = 'command-r-plus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7218f9fa-f07a-4875-b55f-248cb8e28ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = LLM(model_name=claude_model, api_key=os.environ['ANTHROPIC_API_KEY'])\n",
    "turbo = LLM(model_name=turbo_model)\n",
    "azure = load_azure_openai(model_name=azure_model)\n",
    "cohere = LLM(model_name=cohere_model, api_key=os.environ['COHERE_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f4064-5fbf-4e88-adc2-40d9a8696cf8",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118b99e7-ebed-49be-bb16-aa32f6238663",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What does Cal Newport have to say about avoiding distractions'\n",
    "\n",
    "results = weave_client.hybrid_search(request=query,\n",
    "                                     collection_name=collections[2],\n",
    "                                     return_properties=['content', 'title', 'summary','guest'],\n",
    "                                     limit=5\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd3281-c3c9-4c62-a58b-9d6cff687136",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcba9a1b-d11d-4c9a-9b52-558d79f9a92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Rough Total Token Count: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4955</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Rough Total Token Count: \u001b[1;36m4955\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant_message = generate_prompt_series(query, results[:5])\n",
    "max_tokens = 500\n",
    "token_count = get_token_count(assistant_message) + get_token_count(huberman_system_message) + max_tokens\n",
    "print(f'Rough Total Token Count: {token_count}')\n",
    "# print(assistant_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a6d09-7e88-461a-82c3-448f90011d92",
   "metadata": {},
   "source": [
    "### LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44271ee1-99f6-428b-aa22-1059103c9027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 12.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "token_count = 0\n",
    "\n",
    "async def gather_tasks(llm: LLM):\n",
    "    tasks = [llm.achat_completion( system_message=huberman_system_message,\n",
    "                                       user_message=assistant_message,\n",
    "                                       temperature=1.0,\n",
    "                                       max_tokens=max_tokens,\n",
    "                                       raw_response=True\n",
    "                                       ) for x in range(3)]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    return responses\n",
    "\n",
    "# for i in range(1,16):\n",
    "#     completion = await \n",
    "#     tokens = completion.usage.total_tokens\n",
    "#     token_count += tokens\n",
    "#     print(f'{i}.) Running Token Count: {token_count}')\n",
    "#     print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb88bb89-a4b9-43cb-b543-ea0d58151967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7</span> seconds\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1.7\u001b[0m seconds\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "responses = asyncio.run(gather_tasks(azure))\n",
    "end = time.perf_counter() - start\n",
    "print(f'{round(end,2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c47ddc2-16c4-40db-ad55-557fd6c8268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = cohere.chat_completion(huberman_system_message, assistant_message, max_tokens=250, temperature=1.0, raw_response=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5851d913-ba9c-4197-93a8-e9063c9e58c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ModelResponse'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42a218cf-05b9-4004-b19c-ccf97e6bc795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cal\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cal\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Newport\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Newport\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> emphasizes\n",
       "</pre>\n"
      ],
      "text/plain": [
       " emphasizes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> the\n",
       "</pre>\n"
      ],
      "text/plain": [
       " the\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> importance\n",
       "</pre>\n"
      ],
      "text/plain": [
       " importance\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> of\n",
       "</pre>\n"
      ],
      "text/plain": [
       " of\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> eliminating\n",
       "</pre>\n"
      ],
      "text/plain": [
       " eliminating\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> distractions\n",
       "</pre>\n"
      ],
      "text/plain": [
       " distractions\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> such\n",
       "</pre>\n"
      ],
      "text/plain": [
       " such\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> as\n",
       "</pre>\n"
      ],
      "text/plain": [
       " as\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> social\n",
       "</pre>\n"
      ],
      "text/plain": [
       " social\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> media\n",
       "</pre>\n"
      ],
      "text/plain": [
       " media\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> smartphones\n",
       "</pre>\n"
      ],
      "text/plain": [
       " smartphones\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">,\n",
       "</pre>\n"
      ],
      "text/plain": [
       ",\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> and\n",
       "</pre>\n"
      ],
      "text/plain": [
       " and\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> excessive\n",
       "</pre>\n"
      ],
      "text/plain": [
       " excessive\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> emails\n",
       "</pre>\n"
      ],
      "text/plain": [
       " emails\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> to\n",
       "</pre>\n"
      ],
      "text/plain": [
       " to\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> optimize\n",
       "</pre>\n"
      ],
      "text/plain": [
       " optimize\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> cognitive\n",
       "</pre>\n"
      ],
      "text/plain": [
       " cognitive\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> performance\n",
       "</pre>\n"
      ],
      "text/plain": [
       " performance\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.\n",
       "</pre>\n"
      ],
      "text/plain": [
       ".\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for resp in cohere.chat_completion(huberman_system_message, assistant_message, max_tokens=50, stream=True):\n",
    "    content = resp.choices[0].delta.content\n",
    "    if content:\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "afdf4b8a-1e09-440e-a203-8be2f23875c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.8 ms, sys: 4.01 ms, total: 44.9 ms\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "message, cost = azure.chat_completion(huberman_system_prompt, assistant_message, temperature=1.0, return_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "241a73d9-d6a9-44bd-a1ff-e96ed6d6c258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00215"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2800/1000 * 0.0005 + (500/1000*0.0015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "87a6fd95-5285-47c5-b2ca-9e7952e15a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.004451</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0.004451\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cal Newport emphasizes the importance of eliminating distractions, such as social media, smartphones, and excessive\n",
       "emails, in order to optimize cognitive performance. He also suggests creating specific protocols for different \n",
       "types of tasks and using specialized tools, like whiteboards and notebooks, to maximize focus and efficiency. \n",
       "Additionally, Newport cautions against the addictive nature of smartphones and social media, and suggests that \n",
       "individuals reconsider unrestricted internet usage, particularly among young people. Therefore, Cal Newport \n",
       "highlights the significance of avoiding distractions to enhance focus and productivity.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cal Newport emphasizes the importance of eliminating distractions, such as social media, smartphones, and excessive\n",
       "emails, in order to optimize cognitive performance. He also suggests creating specific protocols for different \n",
       "types of tasks and using specialized tools, like whiteboards and notebooks, to maximize focus and efficiency. \n",
       "Additionally, Newport cautions against the addictive nature of smartphones and social media, and suggests that \n",
       "individuals reconsider unrestricted internet usage, particularly among young people. Therefore, Cal Newport \n",
       "highlights the significance of avoiding distractions to enhance focus and productivity.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9af68ab-58ca-462e-9cc3-5ae0fb1748e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_task(message: list[dict]):\n",
    "    response = await acompletion(model=\"gpt-3.5-turbo-1106\", messages=message, temperature=1.0)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaa73ef4-d58d-45d8-bd9f-3802a7b284c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "async def gather(prompts: list[str]):\n",
    "    tasks = []\n",
    "    for p in prompts:\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a highly experienced data annotator.  Your job is to create two questions that can be answered from the provided context.\"},\n",
    "                    {\"role\": \"assistant\", \"content\": prompt.format(context=p)}]\n",
    "        tasks.append(async_task(messages))\n",
    "    asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bb1ff5e-be9f-4dfc-9433-3e95c7e3400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 328 µs, sys: 109 µs, total: 437 µs\n",
      "Wall time: 416 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "responses = asyncio.run(gather(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08509474-ba0b-4c53-bc1e-6ab466a8949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a35e45c-caf0-49cb-911f-922c1c2816c8",
   "metadata": {},
   "source": [
    "### Mulitple LLM calls single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79d6e2f-f609-4dce-9f4b-de69f9044eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What does Cal Newport have to say about avoiding distractions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41afdb55-1aef-47fc-8fce-0223c9b8c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = \"\"\"\n",
    "You are an AI language model assistant. Your task is to generate {n}\n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines.\\n\\nOriginal question: {question}\n",
    "\"\"\".format(n=3, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "337fcb4e-c761-4a73-a052-f697a357b093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. How does Cal Newport discuss strategies for minimizing distractions?\\n2. What are Cal Newport's recommendations for staying focused and avoiding distractions?\\n3. What insights does Cal Newport provide on the topic of mitigating distractions and maintaining concentration?\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "03a99caa-f82b-4368-be43-f82f91f8cafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How does Cal Newport discuss strategies for minimizing distractions?',\n",
       " \"What are Cal Newport's recommendations for staying focused and avoiding distractions?\",\n",
       " 'What insights does Cal Newport provide on the topic of mitigating distractions and maintaining concentration?',\n",
       " 'What does Cal Newport have to say about avoiding distractions']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [\n",
    "                re.sub(r\"^[-\\d]+[\\).\\s]\", \"\", question).strip() for question in response.split('\\n')\n",
    "            ]\n",
    "questions.append(query)\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "31612c5e-734c-4233-b943-cd4b40f9c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = batch_completion(model=f'azure/{azure_model}', messages=messages, temperature=1.0, max_tokens=500,  api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "                      api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "                      api_base=os.environ['AZURE_OPENAI_ENDPOINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "80681a4d-c886-49e1-b80d-8befe9c58480",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievals = [weave_client.hybrid_search(request=query,\n",
    "                                     collection_name=collections[2],\n",
    "                                     return_properties=['content', 'title', 'summary','guest'],\n",
    "                                     limit=3\n",
    "                                    ) for query in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8c4d66f9-fda4-4e50-b85f-d5be67ce8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assist_messages = [generate_prompt_series(q, retrievals[i]) for i, q in enumerate(questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "43ad16e6-a21f-46d9-b3b7-165b0944366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [ [{'role':'system','content':huberman_system_prompt},\n",
    "               {'role':'assistant', 'content': mess}] for mess in assist_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c045f4c1-0a34-4cf5-9b4e-15a8305b1a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cal Newport discusses strategies for minimizing distractions by emphasizing the importance of eliminating \n",
       "distractions such as social media, smartphones, and excessive emails in order to optimize cognitive performance. He\n",
       "also suggests creating specific protocols for different types of tasks and using specialized tools like whiteboards\n",
       "and notebooks to maximize focus and efficiency. Additionally, Newport cautions against the addictive nature of \n",
       "smartphones and social media, and suggests that individuals reconsider unrestricted internet usage, particularly \n",
       "among young people. By prioritizing deep work and minimizing distractions, Newport asserts that individuals can \n",
       "improve their cognitive performance and achieve their best possible work.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cal Newport discusses strategies for minimizing distractions by emphasizing the importance of eliminating \n",
       "distractions such as social media, smartphones, and excessive emails in order to optimize cognitive performance. He\n",
       "also suggests creating specific protocols for different types of tasks and using specialized tools like whiteboards\n",
       "and notebooks to maximize focus and efficiency. Additionally, Newport cautions against the addictive nature of \n",
       "smartphones and social media, and suggests that individuals reconsider unrestricted internet usage, particularly \n",
       "among young people. By prioritizing deep work and minimizing distractions, Newport asserts that individuals can \n",
       "improve their cognitive performance and achieve their best possible work.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cal Newport recommends several strategies for staying focused and avoiding distractions. Some of his \n",
       "recommendations include: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Eliminating distractions such as social media, smartphones, and excessive emails to optimize cognitive \n",
       "performance.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Creating specific protocols for different types of tasks and using specialized tools like whiteboards and \n",
       "notebooks to maximize focus and efficiency.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Emphasizing the concept of active recall, which involves replicating and recalling information to improve \n",
       "learning.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Prioritizing deep work and minimizing distractions to improve cognitive performance.\n",
       "\n",
       "These recommendations are based on the principles outlined in Newport's book <span style=\"color: #008000; text-decoration-color: #008000\">\"Deep Work: Rules for Focus Success in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a Distracted World\"</span> and align with his expertise in productivity and focus.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cal Newport recommends several strategies for staying focused and avoiding distractions. Some of his \n",
       "recommendations include: \n",
       "\u001b[1;36m1\u001b[0m. Eliminating distractions such as social media, smartphones, and excessive emails to optimize cognitive \n",
       "performance.\n",
       "\u001b[1;36m2\u001b[0m. Creating specific protocols for different types of tasks and using specialized tools like whiteboards and \n",
       "notebooks to maximize focus and efficiency.\n",
       "\u001b[1;36m3\u001b[0m. Emphasizing the concept of active recall, which involves replicating and recalling information to improve \n",
       "learning.\n",
       "\u001b[1;36m4\u001b[0m. Prioritizing deep work and minimizing distractions to improve cognitive performance.\n",
       "\n",
       "These recommendations are based on the principles outlined in Newport's book \u001b[32m\"Deep Work: Rules for Focus Success in\u001b[0m\n",
       "\u001b[32ma Distracted World\"\u001b[0m and align with his expertise in productivity and focus.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cal Newport provides insights on the importance of eliminating distractions, such as social media, smartphones, and\n",
       "excessive emails, in order to optimize cognitive performance. He suggests creating specific protocols for different\n",
       "types of tasks and using specialized tools, like whiteboards and notebooks, to maximize focus and efficiency. \n",
       "Newport also cautions against the addictive nature of smartphones and social media, and suggests that individuals \n",
       "reconsider unrestricted internet usage, particularly among young people. By prioritizing deep work and minimizing \n",
       "distractions, Newport asserts that individuals can improve their cognitive performance and achieve their best \n",
       "possible work. This shows that Newport emphasizes the significance of mitigating distractions and maintaining \n",
       "concentration for optimal cognitive performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cal Newport provides insights on the importance of eliminating distractions, such as social media, smartphones, and\n",
       "excessive emails, in order to optimize cognitive performance. He suggests creating specific protocols for different\n",
       "types of tasks and using specialized tools, like whiteboards and notebooks, to maximize focus and efficiency. \n",
       "Newport also cautions against the addictive nature of smartphones and social media, and suggests that individuals \n",
       "reconsider unrestricted internet usage, particularly among young people. By prioritizing deep work and minimizing \n",
       "distractions, Newport asserts that individuals can improve their cognitive performance and achieve their best \n",
       "possible work. This shows that Newport emphasizes the significance of mitigating distractions and maintaining \n",
       "concentration for optimal cognitive performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cal Newport emphasizes the importance of avoiding distractions such as social media, smartphones, and excessive \n",
       "emails in order to optimize cognitive performance. He suggests creating specific protocols for different types of \n",
       "tasks and using specialized tools like whiteboards and notebooks to maximize focus and efficiency. Newport also \n",
       "highlights the concept of active recall, which involves replicating and recalling information to improve learning. \n",
       "Additionally, Newport is structured and disciplined in his avoidance of cell phone use, as mentioned by Andrew \n",
       "Huberman in the podcast transcript. Therefore, Cal Newport advocates for minimizing distractions and maintaining a \n",
       "structured approach to enhance focus and productivity.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cal Newport emphasizes the importance of avoiding distractions such as social media, smartphones, and excessive \n",
       "emails in order to optimize cognitive performance. He suggests creating specific protocols for different types of \n",
       "tasks and using specialized tools like whiteboards and notebooks to maximize focus and efficiency. Newport also \n",
       "highlights the concept of active recall, which involves replicating and recalling information to improve learning. \n",
       "Additionally, Newport is structured and disciplined in his avoidance of cell phone use, as mentioned by Andrew \n",
       "Huberman in the podcast transcript. Therefore, Cal Newport advocates for minimizing distractions and maintaining a \n",
       "structured approach to enhance focus and productivity.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for response in responses:\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34810d27-e423-426d-90a1-b2970eed8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_messages = [{'role':'system','content':huberman_system_prompt},\n",
    "                   {'role':'assistant', 'content': assistant_message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "720859bf-06ee-4b46-9ae5-cf636cf0ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere = LLM(model_name='command-r-plus', api_key=os.environ['COHERE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cf1ed69-55dd-4d23-9564-11a325776eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 03:06:15.695 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-21 03:06:15.696 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Of course! I'm happy to answer any questions you may have about the Huberman Lab podcast. Please go ahead with your queries, and I will provide responses based on the information given.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohere.chat_completion(system_message=huberman_system_prompt,\n",
    "                       assistant_message=assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71dfc6-3294-4a5e-a63d-83005e312c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
