{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "208b6f8b-09bb-4e2c-bf8b-a5410ceffebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#load from local .env file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "#standard libraries\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import List\n",
    "from math import ceil\n",
    "\n",
    "#external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich import print\n",
    "from torch import cuda\n",
    "from tqdm.notebook import tqdm\n",
    "import tiktoken # bad ass tokenizer library for use with OpenAI LLMs \n",
    "from llama_index.text_splitter import SentenceSplitter #one of the best on the market\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#external files\n",
    "from src.preprocessor.preprocessing import FileIO\n",
    "from src.database.weaviate_v4 import WeaviateWCS, WeaviateIndexer\n",
    "from src.database.huberman_properties import properties_template\n",
    "from src.pipelines.pipeline import (chunk_data, create_vectors, join_docs, \n",
    "                                    create_dataset, groupby_episode, create_parent_chunks,\n",
    "                                    convert_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2707da2-956c-4400-b055-cacd674eed00",
   "metadata": {},
   "source": [
    "### Set Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95de892-f23c-4100-9e14-554eef5921cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 256\n",
    "\n",
    "#tokenizer\n",
    "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo-0613')\n",
    "#text_splitter\n",
    "splitter = SentenceSplitter(chunk_overlap=0, chunk_size=chunk_size, tokenizer=encoding.encode)\n",
    "#model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cpu')\n",
    "#corpus\n",
    "raw = FileIO().load_json('../data/hubermanlabs.json')\n",
    "data = convert_raw_data(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274457c0-b4a6-49e0-8743-ef02da5264ee",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4bb1e48-ad59-4a96-b520-963715ae2692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating dataset using chunk_size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating dataset using chunk_size: \u001b[1;36m256\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b62094704054294852b021e691f39d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CHUNKING:   0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c956455fb75496fa35cfe200f5e7e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VECTORS:   0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-27 11:06:49.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.preprocessor.preprocessing\u001b[0m:\u001b[36msave_as_parquet\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mDataFrame saved as parquet file here: ../data/huberman_minilm_256-256.parquet\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total Time to process dataset of chunk_size <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.88</span> minutes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total Time to process dataset of chunk_size \u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m14.88\u001b[0m minutes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 51min 16s, sys: 4min 36s, total: 1h 55min 52s\n",
      "Wall time: 14min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outpath = '../data/huberman_minilm_256'\n",
    "docs = create_dataset(data, model, splitter, file_outpath_prefix=outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8644d-7926-4b5d-b896-74700dc1037f",
   "metadata": {},
   "source": [
    "### Create Expanded Content property "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad02199b-a429-4292-9b90-bdc7bab37608",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = groupby_episode(docs, key_field='videoId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df66730-8eba-4334-9d17-2a1db2c9edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pchunks = create_parent_chunks(grouped, window_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ad54a55-e1a4-409a-9de9-ce4fa990734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(pchunks):\n",
    "    doc_id = list(chunk.keys())[0]\n",
    "    assert doc_id == docs[i]['doc_id'], f'failed at line {i}\\t{k}'\n",
    "    docs[i]['expanded_content'] = chunk[doc_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86d450-7261-4b57-8814-14258f8d5a7f",
   "metadata": {},
   "source": [
    "### Create Weaviate Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d7c7618-f810-49b2-a00a-aa5573723a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;92mTrue\u001b[0m \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read env vars from local .env file\n",
    "api_key = os.environ['WEAVIATE_API_KEY']\n",
    "url = os.environ['WEAVIATE_ENDPOINT']\n",
    "\n",
    "#instantiate client\n",
    "client = WeaviateWCS(url, api_key=api_key)\n",
    "\n",
    "#check if WCS instance is live and ready\n",
    "print(client._client.is_live(), client._client.is_ready())\n",
    "\n",
    "indexer = WeaviateIndexer(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd11a1c4-d186-43e7-b80c-130fda609dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9ac06-1d2c-45dc-9c92-ba35e43eee32",
   "metadata": {},
   "source": [
    "### Load data from disk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e53f9cd8-e1d0-4e91-a179-ada6f812ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = FileIO().load_parquet('../data/huberman_subset_minilm-256.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26ceb8-fabb-4007-85cc-967a763ab18f",
   "metadata": {},
   "source": [
    "### Create Schema and Index Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d117190-7352-4834-a191-fcbcc51998f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection \"Huberman_minilm_256\" created\n"
     ]
    }
   ],
   "source": [
    "indexer.create_collection(collection_name, properties_template, description='Full index of 189 Huberman Labs episodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "457cde2c-7a42-4cf1-8643-6e6dbac8162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection \"Way_too_big\" not found on host, creating Collection first...\n",
      "Collection \"Way_too_big\" created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23450/23450 [01:21<00:00, 288.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch job completed in 1.99 minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_errors': 0, 'failed_objects': [], 'failed_references': []}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.batch_index_data(docs, collection_name='Way_too_big', properties=properties_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4b99-259e-428e-ae09-f90bb1cf5d37",
   "metadata": {},
   "source": [
    "## Small-to-Big Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eaee65d-0a33-42f3-b6f2-5c02945fa0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (26448, 12)\n",
      "Memory Usage: 2.42+ MB\n"
     ]
    }
   ],
   "source": [
    "data = FileIO().load_parquet('../impact-theory-new-ft-model-256.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d3555-d370-44b6-808b-9c91aba9bf7a",
   "metadata": {},
   "source": [
    "### Remove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b9e46f-cb64-4791-ac97-8abbfe4e0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{k:v for k,v in d.items() if k != 'content_embedding'} for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54425b74-962b-4bea-bdb3-13fbc27abdfa",
   "metadata": {},
   "source": [
    "## Breakout Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7499b400-4875-4854-834e-dc93dafbd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_into_episodes(data: List[dict]) -> List[list]:\n",
    "    '''\n",
    "    Separates entire Impact Theory corpus into individual \n",
    "    lists of discrete episodes.\n",
    "    '''\n",
    "    all_episodes = []\n",
    "    episode = []\n",
    "    cur_video = ''\n",
    "    count = 0\n",
    "    for d in data:\n",
    "        video_id = d['video_id']\n",
    "        if not cur_video:\n",
    "            cur_video = video_id\n",
    "        if cur_video == video_id:\n",
    "            episode.append(d)\n",
    "            count += 1\n",
    "        else:\n",
    "            all_episodes.append(episode)\n",
    "            count = 0\n",
    "            episode = []\n",
    "            episode.append(d)\n",
    "            cur_video = video_id\n",
    "    all_episodes.append(episode)\n",
    "    assert len(all_episodes) == 384\n",
    "    return all_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c614af7-7884-4541-86b7-c7d459a18679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def groupby_episode(data: List[dict], key_field: str='video_id') -> List[List[dict]]:\n",
    "    '''\n",
    "    Separates entire Impact Theory corpus into individual \n",
    "    lists of discrete episodes.\n",
    "    '''\n",
    "    episodes = []\n",
    "    for key, group in groupby(data, lambda x: x[key_field]):\n",
    "        episode = [chunk for chunk in group]\n",
    "        episodes.append(episode)\n",
    "    return episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be96980a-e3e9-4ce2-a999-0f9cdd61c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_episodes = groupby_episode(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf6408-74ef-45f6-a41e-71a73e25ecfe",
   "metadata": {},
   "source": [
    "### Combine episode chunks into Parent Chunks one for each doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "77b07c0f-5ac2-4354-8007-c92c0e38eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_chunks(episode_list: List[list], window_size: int=2) -> List[dict]:\n",
    "    '''\n",
    "    Creates parent chunks from original chunk of text, for use with \n",
    "    small to big retrieval.  Window size sets number of chunks before\n",
    "    and after the original chunk.  For example a window_size of 2 will \n",
    "    return five joined chunks.  2 chunks before original, the original, \n",
    "    and 2 chunks after the original.  Chunks are kept in sequence by \n",
    "    using the doc_id field. \n",
    "    '''\n",
    "    parent_chunks = []\n",
    "    for episode in episode_list:\n",
    "        contents = [d['content'] for d in episode]\n",
    "        for i, d in enumerate(episode):\n",
    "            doc_id = d['doc_id']\n",
    "            start = max(0, i-window_size)\n",
    "            end = i+window_size+1\n",
    "            chunk = ' '.join(contents[start:end])\n",
    "            parent_chunks.append({doc_id:chunk})\n",
    "    return parent_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b80b321f-aa9b-457f-93fd-ba2dca2b29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pchunks = create_parent_chunks(all_episodes, window_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a173eecb-8519-4abd-8750-6cac201fbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_chunk_cache(parent_chunks: List[dict]) -> dict:\n",
    "    '''\n",
    "    Creates a simple in-memory cache for quick parent chunk lookup.\n",
    "    Used for small-to-big retrieval in a RAG system.\n",
    "    '''\n",
    "    content_cache = {}\n",
    "    for chunk in pchunks:\n",
    "        for k,v in chunk.items():\n",
    "            content_cache[k] = v\n",
    "    return content_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5848323-a180-4842-a175-743d6d064c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = create_parent_chunk_cache(pchunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da970c57-1e4a-4403-b7fc-edd7bb21b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltext = ' '.join(list(cache.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01bc60d7-732f-4d68-bbc1-374e8146e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1658bec-be47-41a8-98b7-359619f3b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model('gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fae36f03-c194-47aa-8cdb-1efee54a9307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40777582"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(alltext))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe07f1ec-f469-463b-b323-ec883c10c4e6",
   "metadata": {},
   "source": [
    "# ------------------- BREAK ---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ade2eb-f853-4fe6-a273-a21a29bf01fd",
   "metadata": {},
   "source": [
    "# Small to Big Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69a8bc3b-5760-4688-afbc-96cbf741487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of original data: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26448</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of original data: \u001b[1;36m26448\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Size of cached content: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26448</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Size of cached content: \u001b[1;36m26448\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Size of original data: {len(data)}')\n",
    "print(f'Size of cached content: {len(content_cache)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd34d184-fd63-4aa0-851b-9e01e751d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name =  'Fine_tuned_on_300'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd773b-742d-4f04-8d10-90f3e92ff271",
   "metadata": {},
   "source": [
    "### Hybrid Search call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "592260e6-6583-4d9d-9e88-d6b91016b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.hybrid_search('does this show discuss the use of generative ai', class_name, properties=['content', 'summary', 'guest'], alpha=0.45)\n",
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb136c-ed06-475e-9af0-dd16c4f4a27c",
   "metadata": {},
   "source": [
    "### View larger context from response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "25d6608f-81cb-48cc-8af2-fccb8a1c6970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So your chief AI officer is scanning the horizon, understanding it, and then advising members of your team. So every part of your team, right? There's going to be AI supporting sales, and marketing, and engineering, and HR. We're all going to have, in the near term, an AI co-pilot, right? This is an AI that helps you do your job better, because we are so limited as carbon life forms. But ultimately is going to be able to operate and do a number of the things repetitively, because we do a lot of repetitive tasks, and AIs are much better at that. I think if you've got, we've got, say, a 30 person company, every single person needs to be trained in AI, and using these chatbot auto GPT tools, and absolutely augment themselves 10, 20, 100x. I have said to my company, okay, everybody here needs to figure out in your department, what are the tools that exist in AI? And how can you immediately implement them? But even that's pretty vague. Like I'm just sort of dumping it on them. Where do people start? What is the thing you actually do? Easy and super specific. If you have an email newsletter that goes out, use chat GPT, just say, how would I increase the engagement rate with this email? We did that. We got a 25% increase. Can you feed it the email? You feed it the email. Yeah. And just say, how do I make this better? Yeah. Come up with a better headline. Or put in social sharing links throughout it. Or say, listen, I'm in HR, go to chat GPT, open it up right now. Hopefully you have the GPT-4 version of it. And say, I'm in HR. How should I be using generative AI in my business? It'll feed you. Give me five examples or 10 examples. Pick the one that sounds good. Give me step-by-step instructions on how to use this. It's recursive in that fashion. And so you're going to use AI to help you learn what you want to know. It comes back a lot to mindset, Tom. And you need the mindset of a kid here. Curiosity, absolute play. It's like one of the things I'm going to be doing in my team, my PhD Ventures that runs Abundance360 and a few others, we're setting aside three days. And no homework coming out of these three days. We're going to go in with a series of objectives. And we're going to actually crank for three days and generate all the content, all the plans. And you can. But it takes time for all of us to switch from our old habits of how we do things to new ways. So the first time it's going to take 150% of your time. The next time we'll take 50%, then 25%. You talk about mindset. The thing I see, and I'm sure you guys have encountered this, is a lot of people, they just have so much anxiety about this is going to replace me. I think about that a lot. So Lisa and I have put our fortune back at risk to build this company. And you've said this a lot. I've said this a lot. Skate to where the puck is going to be, not where the puck is.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_cache['zm0QVutAkYg_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e10b2-8ba7-409d-8857-ff049876ce32",
   "metadata": {},
   "source": [
    "### Extract top-n results from response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f10e7070-6154-47c4-8f7f-b7fdaa0dad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 3\n",
    "\n",
    "def get_top_n(response: List[dict], top_n: int=3):\n",
    "    top_docs = [d['doc_id'] for d in response[:top_n]]\n",
    "    cache_responses = [content_cache[doc_id] for doc_id in top_docs]\n",
    "    return cache_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c0aac4d-e5b4-4770-b460-38cdc733d39a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"So your chief AI officer is scanning the horizon, understanding it, and then advising members of your team. So every part of your team, right? There's going to be AI supporting sales, and marketing, and engineering, and HR. We're all going to have, in the near term, an AI co-pilot, right? This is an AI that helps you do your job better, because we are so limited as carbon life forms. But ultimately is going to be able to operate and do a number of the things repetitively, because we do a lot of repetitive tasks, and AIs are much better at that. I think if you've got, we've got, say, a 30 person company, every single person needs to be trained in AI, and using these chatbot auto GPT tools, and absolutely augment themselves 10, 20, 100x. I have said to my company, okay, everybody here needs to figure out in your department, what are the tools that exist in AI? And how can you immediately implement them? But even that's pretty vague. Like I'm just sort of dumping it on them. Where do people start? What is the thing you actually do? Easy and super specific. If you have an email newsletter that goes out, use chat GPT, just say, how would I increase the engagement rate with this email? We did that. We got a 25% increase. Can you feed it the email? You feed it the email. Yeah. And just say, how do I make this better? Yeah. Come up with a better headline. Or put in social sharing links throughout it. Or say, listen, I'm in HR, go to chat GPT, open it up right now. Hopefully you have the GPT-4 version of it. And say, I'm in HR. How should I be using generative AI in my business? It'll feed you. Give me five examples or 10 examples. Pick the one that sounds good. Give me step-by-step instructions on how to use this. It's recursive in that fashion. And so you're going to use AI to help you learn what you want to know. It comes back a lot to mindset, Tom. And you need the mindset of a kid here. Curiosity, absolute play. It's like one of the things I'm going to be doing in my team, my PhD Ventures that runs Abundance360 and a few others, we're setting aside three days. And no homework coming out of these three days. We're going to go in with a series of objectives. And we're going to actually crank for three days and generate all the content, all the plans. And you can. But it takes time for all of us to switch from our old habits of how we do things to new ways. So the first time it's going to take 150% of your time. The next time we'll take 50%, then 25%. You talk about mindset. The thing I see, and I'm sure you guys have encountered this, is a lot of people, they just have so much anxiety about this is going to replace me. I think about that a lot. So Lisa and I have put our fortune back at risk to build this company. And you've said this a lot. I've said this a lot. Skate to where the puck is going to be, not where the puck is.\",\n",
       " \"We showed this prototype of something called BuilderBot, which is basically a helper for people creating worlds in Horizon. And the idea is instead of, and we have this whole scripting language where you can be in VR and you can kind of drag things around and lay out the world the way you want, which is pretty wild and fun. It's like the first creation tool where you're in the thing that you're creating as you're building it, right? So you're not writing a script and compiling it and seeing what it looks like or drawing something on a screen in Photoshop. You're like in it and building it. But now with AI, we also have the tools so you can just say, okay, put a tree over there. Actually, I want a tree. Can you maybe make that tree have more branches? All right. Maybe it's false. So make the tree, maybe the branches should be, the leaves should be turning red and yellow instead of green. It's like, okay, put a waterfall there, whatever, however you want to design this thing. Being able to script it or kind of put it together with your hands is one thing, but also being able to use AI to just describe the world that you want to create and have an AI help build it. Do you have to load the assets or can the AI actually construct the trees, the clouds, the whatever? I mean, I think over time it'll get even more generative, but I mean, there's a whole roadmap here as well. Right now we're mostly focused on, okay, it knows a certain number of things and we want you to be able to express those. But I mean, in one of the demos that I did, it was like, all right, here, put some clouds in the sky. It's like actually make them cumulonimbus clouds. And it like knew, you know, we were able to make it so that it kind of had a sense of what that was and it made clouds that were accurate to that. So over time, I mean, obviously it's going to need to know what the concepts are, but being able to be generative, even for things that it doesn't have texture for or something like that, I do think is where we want to go with that. But there's a long roadmap on that too. How do you think about ownership and all of this? So even as you were describing that scenario where the AI, if the AI isn't procedurally generating it, can people create items that they contribute to that, but they put a price tag on it? Like, how do you think about that? That seems to be in web three, people that are hardcore web three, they love themselves some decentralization and they definitely love ownership. Where do you come down on those two really big ideas? Yeah. I mean, one of the things that we're working on for Horizon is basically the ability to just import anything that you make outside and have an asset store around this that people can exchange or buy things.\",\n",
       " \"So for people that don't understand how the art is created, it looks at a field of noise. Here are all the possible things that these could be in any of these pixels. And from that field of possibilities, it pulls forth the most likely placement of pixels and colors based on what you type. That's insane. So that level of pattern recognition, as evidenced by the art that it can generate, is truly mind blowing. So this guy's saying, OK, hey, at least ideas will be the last bastion and you'll never be able to get rid of me, the artist, because I'm the one with taste. I'm the one with good ideas. Not realizing, no, no, no, what AI is, is a pattern recognition machine. It will recognize the greatest ideas that have ever been had, what they have in common, and will be able to predict the next great idea along that thing. It doesn't even have to just regurgitate what it's already seen. It can like figure out what that sequence is and what that next part of the sequence could be. And on top of that, it's doing that with humans. So AI will get, AI is already extraordinarily good. This is why people think their phone's recording them when it serves an ad. Oftentimes, Target, using their AI, knows that you're pregnant before you do if you're a woman, because they know what to pick up on. So AI is going to get extremely good at understanding us at an individual level, serving us up exactly what we want right in that moment. And that gets dystopian really fast. Really fast. I mean, again, when you combine it with the social credit score, as you've seen in kind of China and other things, you gamify life and you have a system of complete social control, a panopticon, as it were. The pattern recognition was the missing bit whereby you had a level of pattern recognition. So for taste, what do you have? TikTok, Shine, hundred billion dollar companies based on old school algorithms before we even got to generative AI, which as you said, it can take images out of noise. Stable diffusion, you know, the model that we collaborated on now that we lead, we took a hundred thousand gigabytes of images and the output was a two gigabyte file that acts as a filter. Words go in, images come out. Because why is that discrepancy in size meaningful? Fifty thousand to one compression is not WinZip. If you remember Silicon Valley on HBO, it's way beyond that they managed there in terms of compression. It's unheard of compression. Is it compression or is it something completely different? It's intelligence. It's learning the principles. How much information do you see? And then you learn the principles and then spot the tiger in the bush. You learn what's next. Literally GPT and these language models. They predict the next word. That's all they do. They pay attention. They predict the next word. And that was the missing part to intelligence that now is there. We've had the first studies now come out that show that the language models score higher in creativity than people. Woof. And again, think about TikTok. Think about Shine.\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18cbe2-fae6-4d3c-8e03-0ae740f62acb",
   "metadata": {},
   "source": [
    "### Compare with original response content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "242f3e70-7818-434e-963c-316386f39190",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_content = [d['content'] for d in response[:top_n]]\n",
    "response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e191918-03c7-4dee-9b20-8593d9a920fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7607226a-81e9-4eec-bc1b-79c44be8770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.encoding_for_model('gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "67244738-2d72-40ef-9e45-05c4a5a057c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/elastic/notebooks/datasets/acled_reports/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7798ba20-1474-43f6-8a47-64c921cf1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted([os.path.join(data_path, file) for file in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, file))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "71054e5c-38dc-4a66-84d5-072bea91c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = []\n",
    "\n",
    "for path in paths:\n",
    "    with open(path) as f:\n",
    "        string = f.read()\n",
    "        strings.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a1bf6a0-3865-458c-a40a-8358ceb7c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(map(len, encoder.encode_batch(strings))), columns=['lens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e50c3d7-b380-40da-9d81-7879b777e2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lens    21279\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef0efc-f151-4000-9502-91564b212560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsa",
   "language": "python",
   "name": "vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
