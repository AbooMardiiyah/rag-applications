{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ddf3f52-c9f4-4c33-99b7-90c968e36b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env', override=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from preprocessing import FileIO, Splitters, Vectorizor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.text_splitter import SentenceSplitter\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbb92ac-641d-4820-93d2-bef63d94c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_hub.file.pymu_pdf.base import PyMuPDFReader\n",
    "# loader = PyMuPDFReader()\n",
    "# docs = loader.load('./data/llama2.pdf')\n",
    "# len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fc919-6968-48bd-a755-e0e470ab6639",
   "metadata": {},
   "source": [
    "### 1.) Import Podcast Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf555b03-b3d9-42df-b9c2-71c658123d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/elastic/notebooks/vector_search_applications/data/impact_theory_metadata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ccc38ee-5d39-495f-9722-c81e00f9dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.6 ms, sys: 43.6 ms, total: 74.3 ms\n",
      "Wall time: 73.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with open(data_path) as f:\n",
    "    data =  json.load(f)\n",
    "    data = [d for d in data if d.get('content')]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b51374-a217-4273-8414-6f276751f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[384]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e38b43-e4cd-483b-b221-97d932d391c4",
   "metadata": {},
   "source": [
    "### 2a.) Split Text into Sentences - LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a0505d-e45c-4920-a4d9-5de9ba380070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Dig into why text_splitter is using NLTK tokenizer under the hood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6947c023-46b9-4d9a-b60d-d96c5d1fcca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=172, chunk_overlap=20)\n",
    "splitter = Splitters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2024ab7e-78e5-47dc-903f-897fde38cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Docs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [00:21<00:00, 17.61it/s]\n"
     ]
    }
   ],
   "source": [
    "split_dict = splitter.split_corpus(data, text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e058c81-3070-4e3c-a495-dc6082b41d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42863"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(split_dict[key]) for key in split_dict]\n",
    "sum(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4bb15-7493-446a-8963-f975c43a8c1f",
   "metadata": {},
   "source": [
    "### 2b.) Split Text into Sentences - SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5e060b8-3eaf-44f4-9d6a-6f5ece2f143b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n",
      "385\n",
      "CPU times: user 5.09 s, sys: 35.2 ms, total: 5.13 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "utils = Utilities()\n",
    "transcripts = [d.get('content', '') for d in data]\n",
    "print(len(transcripts))\n",
    "transcripts = [text for text in transcripts if text]\n",
    "print(len(transcripts))\n",
    "split_sentences = [utils.sentence_splitter(text) for text in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10169dc9-9429-4428-87ca-9b8f8f0a25ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>857.015584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>642.827887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5342.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count   385.000000\n",
       "mean    857.015584\n",
       "std     642.827887\n",
       "min       1.000000\n",
       "25%     469.000000\n",
       "50%     668.000000\n",
       "75%    1056.000000\n",
       "max    5342.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([len(corpus) for corpus in split_sentences]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fae97-f211-41b3-ad9c-05c6f66c7a24",
   "metadata": {},
   "source": [
    "### 3. Encode Chunks as Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89720b-8b68-44a8-8ee9-4c6c59f7b121",
   "metadata": {},
   "source": [
    "### 3a.) SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e26b5d8-f716-4712-ac11-ed047dc8bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbert = SentenceTransformer('all-MiniLM-L6-v2'). ##  35 seconds to encode all ImpactTheory \n",
    "\n",
    "# model = SentenceTransformer(model_path, device='cuda:0') ## 136 seconds to encode all ImpactTheory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cda8b5b-6523-402e-bdfa-207c8b379bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/elastic/notebooks/vector_search_applications/models/gte-base/' \n",
    "vectorizer = Vectorizor(model_name_or_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04a987d2-8fe1-4339-886d-c208d7d3eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Docs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [02:16<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 31s, sys: 877 ms, total: 2min 32s\n",
      "Wall time: 2min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merged_dict = vectorizer.encode_from_dict(split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a5214304-bdeb-4c03-b369-866333915e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./gte_vectors.npy', gte_vectors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9555d7f7-31c0-4180-bb40-53fedd641577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42863"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectorizer.join_metadata(corpus=data, merged_dict=merged_dict)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb9ff354-5a00-449a-914e-8b1b44d6d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-09 22:00:01.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing\u001b[0m:\u001b[36msave_as_parquet\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mDataFrame saved as parquet file here: /home/elastic/notebooks/vector_search_applications/data/impact_theory_GTE.parquet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "io = FileIO()\n",
    "io.save_as_parquet(file_path='/home/elastic/notebooks/vector_search_applications/data/impact_theory_GTE.parquet', data=docs, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd9599-57cd-4e58-9522-fab80917e256",
   "metadata": {},
   "source": [
    "### 3b.) OpenAI Ada Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73176902-10a2-48d9-a656-cecae55353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "model = \"text-embedding-ada-002\"\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "#get cost first\n",
    "tokenizer = Tokenizer(model_type=\"cl100k_base\", price=0.001)\n",
    "\n",
    "# cost = tokenizer.get_cost(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ac557e9-d176-47be-91cb-522978e64213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2b06f-fa71-424b-a142-46934ec03a0f",
   "metadata": {},
   "source": [
    "#### Working around OpenAI rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec0d7eb4-c13c-4733-8b56-13ffba68e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 890642\tCost: 0.891\n",
      "Total Tokens: 889149\tCost: 0.889\n",
      "Total Tokens: 892516\tCost: 0.893\n",
      "Total Tokens: 887084\tCost: 0.887\n",
      "Total Tokens: 892144\tCost: 0.892\n",
      "Total Tokens: 887583\tCost: 0.888\n",
      "Total Tokens: 876077\tCost: 0.876\n",
      "Total Tokens: 126477\tCost: 0.126\n"
     ]
    }
   ],
   "source": [
    "#split text_chunks into roughly 1 million tokens total per group\n",
    "for num in range(0,43000,6000):\n",
    "    chunks = text_chunks[num:num+6000]\n",
    "    cost = tokenizer.get_cost(chunks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d1931e2-6607-4753-ba62-5f61572d4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.Embedding.create(text_chunks[:2], engine=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec1f3bc3-96c6-4ebd-8900-292569895e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37271dc7-c403-4ba8-8aac-965a7f7f08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# embeddings = []\n",
    "# for num in range(0,43000,6000):\n",
    "#     chunks = text_chunks[num:num+6000]\n",
    "#     results = openai.Embedding.create(input=chunks, engine=model)\n",
    "#     embeddings.append(results)\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee740130-1532-4698-905b-d8f467f678c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = results['data']\n",
    "vectors = [vec['embedding'] for vec in vectors]\n",
    "len(vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
