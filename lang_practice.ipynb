{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f09d8e6-5a05-4daf-aadd-59e583326fc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseSettings' from 'pydantic' (/anaconda/envs/openai/lib/python3.9/site-packages/pydantic/__init__.cpython-39-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT_Turbo\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/chromadb/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtelemetry\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientStartEvent\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtelemetry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Telemetry\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/chromadb/config.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EnforceOverrides\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSettings, validator\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# The thin client will have a flag to control which implementations to use\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseSettings' from 'pydantic' (/anaconda/envs/openai/lib/python3.9/site-packages/pydantic/__init__.cpython-39-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from bs4 import BeautifulSoup\n",
    "from openai_interface import GPT_Turbo\n",
    "import re\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9e64f5-ad6c-4595-ad6f-74ba239a14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_new_lines(content: str):\n",
    "    return re.sub('\\n+', '\\n', content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96d013cd-dd7f-4da2-884f-093e48e87b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage(url: str, return_content_only: bool=False, return_as_loader: bool=False):\n",
    "    if return_as_loader:\n",
    "        return WebBaseLoader(url)\n",
    "    data = WebBaseLoader(url).load()\n",
    "    if return_content_only:\n",
    "        content = data[0].page_content.strip()\n",
    "        return sub_new_lines(content)\n",
    "    else: return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a535a4e9-0f15-4873-96e6-285e71bf3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "langurl = \"https://python.langchain.com/docs/use_cases/question_answering/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ce1f5e1-a4b1-4334-a046-c8e51bd1a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.document_loaders.web_base.WebBaseLoader at 0x7fd238839fa0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = get_webpage(langurl)\n",
    "loader = get_webpage(langurl, return_as_loader=True)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fbe1c25b-4aee-4727-9757-ff72755f5d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:81\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/chromadb/__init__.py:4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtelemetry\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientStartEvent\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/chromadb/config.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSettings, validator\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseSettings' from 'pydantic' (/anaconda/envs/openai/lib/python3.9/site-packages/pydantic/__init__.cpython-39-x86_64-linux-gnu.so)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorstoreIndexCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/langchain/indexes/vectorstore.py:82\u001b[0m, in \u001b[0;36mVectorstoreIndexCreator.from_loaders\u001b[0;34m(self, loaders)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loader \u001b[38;5;129;01min\u001b[39;00m loaders:\n\u001b[1;32m     81\u001b[0m     docs\u001b[38;5;241m.\u001b[39mextend(loader\u001b[38;5;241m.\u001b[39mload())\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/langchain/indexes/vectorstore.py:87\u001b[0m, in \u001b[0;36mVectorstoreIndexCreator.from_documents\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a vectorstore index from documents.\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m sub_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n\u001b[0;32m---> 87\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore_kwargs\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m VectorStoreIndexWrapper(vectorstore\u001b[38;5;241m=\u001b[39mvectorstore)\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:613\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    612\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:568\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    548\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:84\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m client_settings\n",
      "\u001b[0;31mValueError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92d37cd2-8ede-46b4-8902-b597567ebc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT_Turbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fe5a6e7-f10f-452a-863b-aef637357321",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = '''\n",
    "EXECUTIVE SUMMARY\n",
    "\n",
    "Former US Navy SEAL and hands-on leader with an eclectic background that combines real-world military operational excellence with six years of corporate sales, strategy, and Data Science experience. Big thinker with proven ability to translate data insights into business decisions; years of experience improving operational processes. \n",
    "\n",
    "PROFESSIONAL EXPERIENCE\n",
    "Microsoft – Senior Data Scientist \tApr 2021 – Present\n",
    "•  Recently assigned as the Lead Product data scientist for the Azure Planetary Computer product team. \n",
    "•  Technical Lead for 5-person team charged with creating a search and discovery experience for enterprise data   \n",
    "   within Classified networks, consisting of keyword/semantic/image/video search, and question answering.\n",
    "•  Lead Delivery data scientist for a strategic military account; responsible for scoping and implementing a year-\n",
    "   long contractual engagement that resulted in two spin-off product applications. \n",
    "\n",
    "Elite Meet – Head of Analytics \t Oct 2020 – June 2021\n",
    "•  Built an analytics platform for the CEO to enable decision support in the areas of membership growth,  \n",
    "    marketing campaigns, and resource allocation by geographic location.   \n",
    "\n",
    "Gartner – Federal Account Executive\t      2019 – Oct 2020\n",
    "•  Achieved over 200% of new business quota in nine months by direct engagement with CXO decision makers.\n",
    "\n",
    "US Navy: Naval Special Warfare Command\n",
    "Product Manager\t             \t\t    \t     \t   \t\t\t\t\t\t    2017\n",
    "•  Led the design, development, implementation and user experience of flagship, classified software platform.\n",
    "•  Grew the daily user base by 400% and increased adoption rate from three organizations to 17 over 7 months.\n",
    "\n",
    "Chief of Staff\t\t\t\t                                           \t\t\t\t        2016-2017\n",
    "•  High impact role leading a staff of 13 departments in support of the Logistics requirements of the West Coast   \n",
    "   SEAL Teams and seven other supporting commands.\n",
    "•  Planned and executed an extensive 6-months long Manpower Requirements project involving a detailed \n",
    "   analysis of all organizational commitments which was used to justify organizational manpower requirements \n",
    "   into 2020.\n",
    "\n",
    "Director of Operations\t\t\t\t\t\t\t                                            2015-2016\n",
    "•  Managed the training, equipping, and deployment of over 450 combat support personnel, including six \n",
    "   specialized Combat Support Teams, across 4 continents, in support of SEAL Team combat operations. \n",
    "\n",
    "Senior Program Manager\t       \t\t\t\t\t\t\t\t        2010-2015\n",
    "•  Spearheaded the relocation of headquarters building from Virginia to Florida. Over a period of 2 years, I worked with \n",
    "   finance, manpower, operations and logistics to create a framework for project execution, resulting in the transfer of over  \n",
    "   45 personnel and $30M in assets. \n",
    "•  Hand-picked to lead a SEAL Task Unit charged with augmenting the security of the President of the United States \n",
    "   during a 2-week period while he conducted a high-level diplomatic visit to South Africa. \n",
    "\n",
    "EDUCATION\n",
    "UNIVERSITY OF CALIFORNIA, BERKELEY | Masters, Data Science\t\t\t\t    \t        Aug 2019\n",
    "UNIVERSITY OF UTAH | BS, Political Science (Honors), Magna Cum Laude\t\t\t\t        May 2007\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a890fa3-631a-4eed-a271-e26e187919fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "# Using the enclosed context in triple backticks answer the following question:\n",
    "# Question: Which method or Class should I use to parse text content from a web page and return in string format, using the python library langchain?  Provide a step by step solution on how I would do that using python.\n",
    "# Context: \n",
    "# ```\n",
    "# {page}\n",
    "# ```\n",
    "# Answer: \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "033064a6-9533-43b3-ab8b-12903276a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "What is the total number of people that Chris Sanchez has led or managed over the entire course of his career. \\\n",
    "Provide a rough estimate, and reason through the following context to answer the question.\n",
    "Context: {resume}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b7d9971-08f7-493f-b160-a128dba469b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gpt.get_completion_from_messages(prompt, show_response=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "39404ffc-2047-48d4-a7f2-ab6cfd26cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it is difficult to determine the exact number of people that Chris Sanchez has led or managed over the entire course of his career. However, we can make a rough estimate based on the information provided.\n",
      "\n",
      "From the context, we can identify the following roles where Chris Sanchez had leadership or management responsibilities:\n",
      "\n",
      "1. Lead Product data scientist at Microsoft: Although the number of people directly managed is not mentioned, it can be assumed that Chris Sanchez is leading a team of data scientists, which could range from a few individuals to a larger team.\n",
      "\n",
      "2. Head of Analytics at Elite Meet: The context does not provide information about the size of the team or the number of people managed in this role.\n",
      "\n",
      "3. Federal Account Executive at Gartner: The context does not mention any direct management responsibilities in this role.\n",
      "\n",
      "4. Product Manager at US Navy: Naval Special Warfare Command: The context does not provide information about the size of the team or the number of people managed in this role.\n",
      "\n",
      "5. Chief of Staff at US Navy: Naval Special Warfare Command: Chris Sanchez led a staff of 13 departments, which could include a significant number of personnel.\n",
      "\n",
      "6. Director of Operations at US Navy: Naval Special Warfare Command: Chris Sanchez managed over 450 combat support personnel, including six specialized Combat Support Teams.\n",
      "\n",
      "7. Senior Program Manager at US Navy: Chris Sanchez led a SEAL Task Unit, which could include a team of personnel.\n",
      "\n",
      "Based on the available information, it can be estimated that Chris Sanchez has led or managed at least several hundred people over the course of his career. However, without specific details about the team sizes in each role, it is challenging to provide a more precise estimate.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bb07728-6f12-4e43-bf1d-dd1c1becf718",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70664cb8-d98d-46aa-9fb5-0dfdfd0d4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splitter.split_documents(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ea255-bb92-41ec-9982-64b760cf92e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
