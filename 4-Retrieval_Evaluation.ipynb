{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88728355-dd6c-4c08-8ad8-ac7f85e6af68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f03b28-68e1-45c5-9ec0-99d9a32d0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#external files\n",
    "from preprocessing import FileIO\n",
    "from openai_interface import GPT_Turbo\n",
    "from opensearch_interface import OpenSearchClient\n",
    "from reranker import ReRanker\n",
    "\n",
    "#standard library imports\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from math import ceil\n",
    "from datetime import datetime\n",
    "from typing import List, Any, Dict, Tuple, Union\n",
    "\n",
    "#misc\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "env = load_dotenv('./.env', override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bb049-ca24-42ef-9458-72fb687fe27d",
   "metadata": {},
   "source": [
    "### Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e61a946-f5b2-4a7e-80b6-1dc5bdaa4cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (37007, 16)\n",
      "Memory Usage: 4.27+ MB\n"
     ]
    }
   ],
   "source": [
    "data_path = './practice_data/impact_theory_minilm_196.parquet'\n",
    "data = FileIO().load_parquet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a130cd-03de-4390-9882-3189c2ca9384",
   "metadata": {},
   "source": [
    "### Randomly select 100 chunks for Q/A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c379516f-ee58-4445-8d2e-0ec8241bb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b33379-f58b-45d9-9c72-d31f0537149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data: List[dict], sample_size: int):\n",
    "    sample = random.sample(data, sample_size)\n",
    "    contents = [(d['doc_id'], d['content']) for d in sample]\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8dc7bf0-8f53-4603-ba22-d05a7a6dd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(sample: List[dict], key: str=\"doc_id\") -> List[Any]:\n",
    "    return [d[key] for d in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89f27c6-87ca-4481-a74d-b11044a1ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(doc_id: str, corpus: List[dict], full_dict: bool=False):\n",
    "    result = [d for d in corpus if d['doc_id'] == doc_id][0]\n",
    "    if full_dict: return result\n",
    "    else: return result['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71526d96-b5d4-4ce0-8e18-5b5c64eea9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"that would be nice if we all thought that way But of course, there's this primitive mind that we talked about which is this part of your brain that is not wired for truth it's wired for survival in 50,000 BC and what that often meant was agreeing with The sacred beliefs of your tribe and believing them and the people who could believe what the tribe believed With full conviction they survived. Well, they were you know, they were on the in-group they fit in and that's what was needed What's up, guys?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample('kE3yryW-FiE_33', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bda73ab-2994-4ce6-83c3-9b6aefcd8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_numbers(query: str):\n",
    "    return query[3:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4919dee7-a38d-4c82-9cc6-ed9a58b9bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_questions(question_tuples: List[tuple]) -> Dict[str, List[str]]:\n",
    "    question_dict = {}\n",
    "    for tup in question_tuples:\n",
    "        doc_id = tup[0]\n",
    "        questions = tup[1].split('\\n')\n",
    "        questions = [strip_numbers(q) for q in questions]\n",
    "        question_dict[doc_id] = questions\n",
    "    return question_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53289eed-4590-4c30-a840-30c329ecb02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(data: List[dict], dir_path: str, num_questions: int=100, batch_size: int=50):\n",
    "    gpt = GPT_Turbo()\n",
    "    if batch_size > 50:\n",
    "        raise ValueError('Due to OpenAI rate limits, batch_size cannot be greater than 50')\n",
    "\n",
    "    time_marker = datetime.now().strftime(\"%Y-%m-%d:%H:%M:%S\")\n",
    "    filepath = os.path.join(dir_path, f\"{num_questions}_questions_{time_marker}.json\")\n",
    "    \n",
    "    sample = sample_data(data, num_questions)\n",
    "    batches = ceil(num_questions/batch_size)\n",
    "    all_questions = []\n",
    "    for n in range(batches):\n",
    "        batch = sample[n*batch_size:(n+1)*batch_size]\n",
    "        questions = gpt.batch_generate_question_context_pairs(batch)\n",
    "        all_questions.append(questions)\n",
    "        if n < batches - 1:\n",
    "            print('Pausing for 60 seconds due to OpenAI rate limits...')\n",
    "            time.sleep(60)\n",
    "    all_questions = [tup for batch in all_questions for tup in batch]\n",
    "    processed_questions = process_questions(all_questions)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(processed_questions, f, indent=4)\n",
    "    return processed_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b797f1-2642-4285-86d1-cb197a9811c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.59Generated Questions/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing for 60 seconds due to OpenAI rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.79Generated Questions/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = generate_dataset(data=data, dir_path='./practice_data/', num_questions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a440bd3e-1223-41c4-ad1a-0120273d9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gteclient = OpenSearchClient(model_name_or_path='/home/elastic/notebooks/vector_search_applications/models/gte-base/')\n",
    "osclient = OpenSearchClient()\n",
    "reranker = ReRanker()\n",
    "intfloat = ReRanker(model_name='intfloat/simlm-msmarco-reranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd43eef-e71d-4713-8664-6ebd14f076f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How did the United States respond to the Soviet Union's advancements in space?\"\n",
    "kw_index = 'impact-theory-minilm-196'\n",
    "vec_index = 'impact-theory-minilm-196'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "255bdabd-770e-4b12-8bd8-54e5cdc64f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation( dataset: Dict[str, List[str]], \n",
    "                    retriever: OpenSearchClient,\n",
    "                    reranker: ReRanker,\n",
    "                    kw_index_name: str, \n",
    "                    vector_index_name: str,\n",
    "                    response_size: int=10,\n",
    "                    top_k: int=5,\n",
    "                    chunk_size: int=196,\n",
    "                    rerank_all_responses: bool=False,\n",
    "                    ) -> Tuple[int, int, int, int]:\n",
    "\n",
    "    top_k = top_k if top_k else response_size\n",
    "    reranker_name = reranker.model_name if rerank_all_responses else \"None\"\n",
    "    \n",
    "    results_dict = {'n':response_size, \n",
    "                    'top_k': top_k, \n",
    "                    'Retriever': retriever.model_name_or_path, \n",
    "                    'Ranker': reranker_name,\n",
    "                    'chunk_size': chunk_size,\n",
    "                    'kw_recall': 0,\n",
    "                    'vector_recall': 0,\n",
    "                    'hybrid_recall':0,\n",
    "                    'total_questions':0\n",
    "                    }\n",
    "    for doc_id, questions in tqdm(dataset.items(), 'Questions'):\n",
    "        for q in questions:\n",
    "            results_dict['total_questions'] += 1\n",
    "            \n",
    "            #make calls to OpenSearch host of: Keyword, Vector, and Hybrid\n",
    "            kw_response = retriever.keyword_search(query=q, index=kw_index_name, size=response_size)\n",
    "            vector_response = retriever.vector_search(query=q, index=vector_index_name, size=response_size)\n",
    "            hybrid_response = retriever.hybrid_search(q, kw_index_name, vector_index_name, kw_size=response_size, vec_size=response_size)\n",
    "\n",
    "            #rerank returned responses if rerank_all is True\n",
    "            if rerank_all_responses:\n",
    "                kw_response = reranker.rerank(kw_response, q, top_k=top_k)\n",
    "                vector_response = reranker.rerank(vector_response, q, top_k=top_k)\n",
    "                hybrid_response = reranker.rerank(hybrid_response, q, top_k=top_k)\n",
    "                \n",
    "            #collect doc_ids to check for document matches (include only top_k if top_k > 0)\n",
    "            kw_doc_ids = [res['_source']['doc_id'] for res in kw_response][:top_k]\n",
    "            vector_doc_ids = [res['_source']['doc_id'] for res in vector_response][:top_k]\n",
    "            hybrid_doc_ids = [res['_source']['doc_id'] for res in hybrid_response][:top_k]\n",
    "            \n",
    "            #increment recall counters as appropriate\n",
    "            if doc_id in kw_doc_ids:\n",
    "                results_dict['kw_recall'] += 1\n",
    "            if doc_id in vector_doc_ids:\n",
    "                results_dict['vector_recall'] += 1\n",
    "            if doc_id in hybrid_doc_ids:\n",
    "                results_dict['hybrid_recall'] += 1\n",
    "\n",
    "    #use raw counts to calculate final scores\n",
    "    calc_recall_scores(results_dict)\n",
    "    \n",
    "    return results_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a94f824a-1bd6-4e9f-b325-fa4a44e529ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall_scores(results_dict: Dict[str, Union[str, int]]):\n",
    "    for prefix in ['kw', 'vector', 'hybrid']:\n",
    "        results_dict[f'{prefix}_score'] = round(results_dict[f'{prefix}_recall']/results_dict['total_questions'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a96addfe-117c-4599-b5dc-e00a22e664cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(results_dict: Dict[str, Union[str, int]], dir_outpath: str=None) -> None:\n",
    "    #write results to output file\n",
    "    if dir_outpath:\n",
    "        time_marker = datetime.now().strftime(\"%Y-%m-%d:%H:%M:%S\")\n",
    "        path = os.path.join(dir_outpath, f'retrieval_eval_{chunk_size}_{time_marker}.json')\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "864cb7bc-6c60-4f0b-a15a-37c440f3fdca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intfloat/simlm-msmarco-reranker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Questions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:11<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 196\n",
    "all_results = []\n",
    "for x in range(60,61):\n",
    "    results = run_evaluation( dataset=dataset, \n",
    "                              retriever=osclient, \n",
    "                              reranker=intfloat,\n",
    "                              kw_index_name=kw_index, \n",
    "                              vector_index_name=vec_index, \n",
    "                              response_size=x, \n",
    "                              top_k=10,\n",
    "                              rerank_all_responses=True,\n",
    "                            )\n",
    "    all_results.append(results)\n",
    "record_results(all_results, dir_outpath='./practice_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1ae8bd-71a6-42bf-b1cb-ea248f9cc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# query = 'How do I get ahead in life?'\n",
    "# resp = osclient.hybrid_search(query, kw_index, vec_index, kw_size=60, vec_size=60)\n",
    "# intfloat.rerank(resp, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8a761-2056-4239-8c04-91eb4cba040e",
   "metadata": {},
   "source": [
    "### gpt-4-32k Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ce8c9cd-d986-4138-9b26-2f5ce15dec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tiktoken_functions import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31dcd282-339c-4f79-bb5b-15fbb54d6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47f5187-ec83-41da-af94-d5f942d3af78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/impact_theory_data.json'\n",
    "\n",
    "#should see 385 unique podcast entries \n",
    "with open(data_path) as f:\n",
    "    data =  json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0462d92-d85f-431c-8395-1c0ae0730d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "5323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The 3 DAILY HABITS That Destroy Your Health & DECREASE Lifespan! | Bob Hariri'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode = data[94]['content'][:30000]\n",
    "print(len(episode))\n",
    "print(len(episode.split()))\n",
    "title = data[94]['title']\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3635efbf-6f87-4b02-b17f-ec4a547e3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-3.5-turbo-16k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8764963c-bda5-402a-a790-01260c2a82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT_Turbo(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "434d189b-1413-42cc-bafa-d870f14c4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "You are an expert in document summarization.  Your task is to summarize the following podcast episode surrounded in triple backticks.  \\\n",
    "For context, the show is titled {title} and is part of the YouTube series Impact Theory created and hosted by Tom Bilyeu.  \\\n",
    "Impact Theory investigates and analyzes the most useful topics with the world's most sought-after guests.  \\\n",
    "Impact Theory is meant for listeners who are looking to thrive in uncertain times, achieve unprecedented goals, and improve the most meaningful aspects of their lives.\\\n",
    "Summarize the following episode in no more than 250 words. \n",
    "```{episode}```\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b47c17b0-3d4d-45fc-8292-32cc9382566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gpt.get_completion_from_messages(prompt=prompt, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "318d7f87-1e23-4903-9a1e-cb655174bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tik = Tokenizer(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e35bf83-2e1b-48db-adaf-9dc3ca0c6a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 30,670\tCost: $0.09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30670, 0.09201000000000001)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tik.get_cost(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91000d79-e85d-4ed8-946b-8232da6f66bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this episode of Impact Theory, host Tom Bilyeu interviews Dr. Bob Hariri, a pioneer in the medical technology industry. Hariri discusses three daily habits that can negatively impact health and lifespan: inactivity, poor diet, and the misuse of supplements. He emphasizes the importance of physical activity and maintaining muscle mass for overall health. Hariri also discusses the detrimental effects of a poor diet, highlighting the difference between calories from proteins, fats, and carbohydrates. He argues that many people are unknowingly harming their health by consuming readily available, unhealthy food options. Lastly, Hariri warns against the misuse of supplements, stating that while they can be beneficial, they can also have negative effects if not used properly. He also delves into the complex processes of the human body at a cellular level, explaining how cells function and the role of stem cells in restoring function after traumatic injuries.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "396fc6d7-8956-49d9-ba72-9cb0a1d385cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dr. Bob Hariri discusses three daily habits that can shorten lifespan. The first habit is inactivity and a dependence on technology for physical activities. Dr. Hariri emphasizes the importance of being physically active and maintaining muscle mass for overall health. The second habit is a poor diet, which can have a significant impact on health, lifespan, and mental state. He explains that many food choices are not great and can be harmful to the body. He also highlights the importance of consuming proteins and fats for cell and tissue regeneration. Dr. Hariri warns against pro-inflammatory elements in food, such as raw sugars, and emphasizes the need to control inflammation. The third habit is the use of medicines and supplements that may not be beneficial. He cautions against gelatin-encapsulated supplements and advises paying attention to the ingredients in the products consumed. \\n\\nDr. Hariri also discusses the process of DNA replication and the role of stem cells. He explains that stem cells can become any type of cell in the body and discusses their potential in treating traumatic brain injuries. He highlights the importance of controlling brain swelling and inflammation in such injuries. However, he acknowledges that there is still much to learn about stem cells and their full potential. He also mentions the complexity of the placenta and the various factors involved in its function, suggesting that injecting stem cells alone may not be sufficient for radical transformation. Overall, Dr. Hariri emphasizes the importance of physical activity, a healthy diet, and being mindful of the substances consumed for maintaining health and longevity.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xc8\"\\x1aex)\\n\\xf5\\xdf\\x96D\\xa4sp\\xcc\\x9c1\\xfd\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0\\'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96']\n",
      "Bad pipe message: %s [b\"-\\xa5n\\x13\\x1a\\xb2\\xced\\x83\\x9c\\x1d\\xca\\xd1tK\\x01\\xc2\\x9b\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\"]\n",
      "Bad pipe message: %s [b'9\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99']\n",
      "Bad pipe message: %s [b'\\x82\\x11\\x15\\x0f\\xa1\\xaa$4\\xa1\\nZ\\xe6\\x12\"\\x01>\\x02\\xd4\\x00\\x00']\n",
      "Bad pipe message: %s [b'\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff']\n",
      "Bad pipe message: %s [b'X>\\t7Z(3\\xf5r.\\xb3\\xb2\\xe9\\x19\\r\\x1d\\x14\\xba\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00', b'\\x11\\xc0\\x07\\xc0\\x0c\\xc0']\n",
      "Bad pipe message: %s [b'\\x05']\n",
      "Bad pipe message: %s [b',\\xf8\\xf1\\xda\\xea\\xa3`8\\x146\\xc54\\xd7}P\\x05M\\xbf\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/']\n"
     ]
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab245b9-5d6a-40cc-9b51-0447a0a91705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
