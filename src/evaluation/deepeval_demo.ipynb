{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424b4361-f20c-4f54-afff-7ba76578667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "envs = load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dba2cec-e732-4a67-9e59-bfaf14d2e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import FaithfulnessMetric, AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.dataset import EvaluationDataset\n",
    "\n",
    "from src.database.database_utils import get_weaviate_client\n",
    "from src.database.weaviate_interface_v4 import WeaviateWCS\n",
    "from src.llm.llm_interface import LLM\n",
    "from src.llm.llm_utils import get_token_count, load_azure_openai\n",
    "from src.llm.prompt_templates import question_answering_prompt_series, huberman_system_message\n",
    "from app_features import generate_prompt_series\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from litellm import ModelResponse\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f89c8ad-7fb8-4982-accd-dba8436fc84e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7, model='gpt-4', strict_mode=True)\n",
    "# test_case = LLMTestCase(\n",
    "#     input=\"What if these shoes don't fit?\",\n",
    "#     # Replace this with the actual output from your LLM application\n",
    "#     actual_output=\"We offer a 30-day full refund at no extra costs.\",\n",
    "#     retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n",
    "# )\n",
    "# evaluate([test_case], [answer_relevancy_metric], run_async=False, ignore_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d4ebecf-5553-4707-8ee8-1e35fc1fc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Give a brief explanation of how brain neuroplasticity works\",\n",
    "             \"What is the role of dopamine in the body\",\n",
    "             \"What is a catecholimine\",\n",
    "             \"What does Jocko Willink have to say about leadership\",\n",
    "             \"What does Lex Fridman think about the evolution of AI\", \n",
    "             \"How can I support the Huberman Lab podcst\",\n",
    "             \"Why do people make self-destructive decisions\",\n",
    "             \"Provide a better sleep protocol in list format\",\n",
    "             \"What are the topcis that Lex Fridman discusses\",\n",
    "             \"Is there a generally positive outlook on the future of AI\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "444bf30f-9a5b-4994-8a77-3c0ef571e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2247250/3431604043.py:1: ResourceWarning: unclosed <ssl.SSLSocket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.18.0.6', 32790), raddr=('34.149.137.116', 443)>\n",
      "  client = get_weaviate_client()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "client = get_weaviate_client()\n",
    "turbo = LLM(model_name='gpt-3.5-turbo-0125')\n",
    "azure = load_azure_openai(model_name='gpt-4')\n",
    "collection_name = 'Huberman_minilm_128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7aca859-f202-48e9-b329-e39ca6505db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_bundle(query: str,\n",
    "                      client: WeaviateWCS,\n",
    "                      collection_name: str,\n",
    "                      answer_llm: LLM,\n",
    "                      ground_truth_llm: LLM=None\n",
    "                     ) -> tuple[str, list[list[str]], str]:\n",
    "    '''\n",
    "    Returns answer, ground truth and associated context from a single query.\n",
    "    '''\n",
    "    def format_llm_response(response: ModelResponse) -> str:\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    #1st-stage retrieval (get contexts)\n",
    "    context = client.hybrid_search(query, collection_name, \n",
    "                                   query_properties=['content', 'title', 'summary'],\n",
    "                                   limit=3, \n",
    "                                   return_properties=['content', 'guest', 'summary'])\n",
    "    #create contexts from content field\n",
    "    contexts = [d['content'] for d in context]\n",
    "    \n",
    "    #generate assistant message prompt\n",
    "    assist_message = generate_prompt_series(query, context)\n",
    "\n",
    "    #generate answers from model being evaluated\n",
    "    answer = format_llm_response(answer_llm.chat_completion(huberman_system_message, assist_message))\n",
    "\n",
    "    #create ground truth answers\n",
    "    if ground_truth_llm:\n",
    "        ground_truth = format_llm_response(ground_truth_llm.chat_completion(huberman_system_message, assist_message))\n",
    "        return query, contexts, answer, ground_truth\n",
    "    return query, contexts, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6a84919-1f2d-43e9-9527-aa3b81ae07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from time import sleep\n",
    "\n",
    "async def create_test_dataset(questions: list[str], \n",
    "                              client: WeaviateWCS,\n",
    "                              collection_name: str,\n",
    "                              answer_llm: LLM,\n",
    "                              ground_truth_llm: LLM=None, \n",
    "                              batch_size: int=5, \n",
    "                              async_mode: bool=True,\n",
    "                              disable_internal_tqdm: bool=False):\n",
    "    total = len(questions)\n",
    "    progress = tqdm('Queries', total=total, disable=disable_internal_tqdm)\n",
    "    data = []\n",
    "    batches = ceil(total/batch_size)\n",
    "    for i in range(batches):\n",
    "        batch = questions[i*batch_size:(i+1)*batch_size]\n",
    "        if async_mode:\n",
    "            results = await asyncio.gather(*[aget_answer_bundle(query, \n",
    "                                                                client, \n",
    "                                                                collection_name, \n",
    "                                                                answer_llm,\n",
    "                                                                ground_truth_llm) for query in batch])\n",
    "            if any(results):\n",
    "                data.extend(results)\n",
    "            else:\n",
    "                raise \"No results returned for initial batch, double-check your inputs.\"\n",
    "        else:\n",
    "            with ThreadPoolExecutor(max_workers=os.cpu_count() * 2) as executor:\n",
    "                futures = [executor.submit(get_answer_bundle, query, client, collection_name, answer_llm, ground_truth_llm) for query in batch]\n",
    "                for future in as_completed(futures):\n",
    "                    progress.update(1)\n",
    "                    data.append(future.result())\n",
    "        print(f\"Finished with batch {i+1}, taking a break...\")\n",
    "    \n",
    "    queries = [d[0] for d in data]\n",
    "    contexts = [d[1] for d in data]\n",
    "    answers = [d[2] for d in data]\n",
    "    dataset = {'queries': queries, 'contexts': contexts, 'answers': answers}\n",
    "    if len(data[0]) == 4:\n",
    "        ground_truths = [d[3] for d in data]\n",
    "        dataset.update(ground_truths=ground_truths)\n",
    "        return dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e48edd30-c6b9-40be-80cd-cf43c25f2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def aget_answer_bundle( query: str,\n",
    "                              client: WeaviateWCS,\n",
    "                              collection_name: str,\n",
    "                              answer_llm: LLM,\n",
    "                              ground_truth_llm: LLM=None\n",
    "                             ) -> tuple[str, list[list[str]], str]:\n",
    "    '''\n",
    "    Returns answer, ground truth and associated context from a single query.\n",
    "    '''\n",
    "    #1st-stage retrieval (get contexts)\n",
    "    context = client.hybrid_search(query, collection_name, \n",
    "                                   query_properties=['content', 'title', 'summary'],\n",
    "                                   limit=3, \n",
    "                                   return_properties=['content', 'guest', 'summary'])\n",
    "    \n",
    "    #create contexts from content field\n",
    "    contexts = [d['content'] for d in context]\n",
    "    \n",
    "    #generate assistant message prompt\n",
    "    assist_message = generate_prompt_series(query, context, 2)\n",
    "\n",
    "    #generate answers from model being evaluated\n",
    "    answer = await answer_llm.achat_completion(huberman_system_message, assist_message)\n",
    "\n",
    "    #create ground truth answers\n",
    "    if ground_truth_llm:\n",
    "        ground_truth = await ground_truth_llm.achat_completion(huberman_system_message, assist_message)\n",
    "        return query, contexts, answer, ground_truth\n",
    "    return query, contexts, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48c7f866-1e79-46b8-9738-2ae9353eb2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/anaconda/envs/vsa/lib/python3.10/site-packages/openai/_legacy_response.py:347: ResourceWarning: unclosed <socket.socket fd=131, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.18.0.6', 56944), raddr=('52.242.46.17', 443)>\n",
      "  async def wrapped(*args: P.args, **kwargs: P.kwargs) -> LegacyAPIResponse[R]:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/anaconda/envs/vsa/lib/python3.10/site-packages/openai/_legacy_response.py:347: ResourceWarning: unclosed <socket.socket fd=136, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.18.0.6', 44686), raddr=('104.18.7.192', 443)>\n",
      "  async def wrapped(*args: P.args, **kwargs: P.kwargs) -> LegacyAPIResponse[R]:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/anaconda/envs/vsa/lib/python3.10/asyncio/selector_events.py:704: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=136 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m1\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m2\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                          | 0/10 [00:37<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data = await create_test_dataset(questions, client, collection_name, turbo, azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd8c68b9-d736-41cc-a5ec-71efc139828d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['Give a brief explanation of how brain neuroplasticity works',\n",
       "  'What is the role of dopamine in the body',\n",
       "  'What is a catecholimine',\n",
       "  'What does Jocko Willink have to say about leadership',\n",
       "  'What does Lex Fridman think about the evolution of AI',\n",
       "  'How can I support the Huberman Lab podcst',\n",
       "  'Why do people make self-destructive decisions',\n",
       "  'Provide a better sleep protocol in list format',\n",
       "  'What are the topcis that Lex Fridman discusses',\n",
       "  'Is there a generally positive outlook on the future of AI'],\n",
       " 'contexts': [[\"And I promise you, I'm not going to just list off a bunch of different brain areas that are active during meditation. That wouldn't be useful to you. In fact, I don't believe in throwing out a lot of nomenclature without also giving some mechanistic explanation as to what different brain areas do. And you could say, well, what good is it knowing what different brain areas do and their names if I can't actually manipulate those brain areas? But the good news is you actually can manipulate those brain areas.\",\n",
       "   'Neuroplasticity is our nervous system, which of course includes the brain, the spinal cord, and all the connections between the brain and spinal cord and the organs and tissues of the body, and then all the neural connections back from the organs and tissues of the body to the brain and spinal cord, so the whole thing in both directions, has the ability to change in response to experience in ways that are adaptive. That is, that allows us to do things that we could not do before.',\n",
       "   \"Neuroplasticity broadly defined is the nervous system's ability to change in response to experience. But at a cellular level, that occurs through a couple of different mechanisms. One of the main mechanisms is something called long-term potentiation. Long-term potentiation involves the strengthening of particular connections between neurons. The connection sites between neurons we call synapses. Actually, technically synapses are the gaps between those connections, but nonetheless, synapses are the point of communication between neurons and those can be strengthened so that certain neurons can talk to other neurons more robustly than they happened to before.\"],\n",
       "  [\"So you have a brain and a spinal cord and the neurons in your brain and spinal cord connect to one another and they connect to different areas of the body, including basically every organ of your body. And every organ of your body communicates back to your brain and spinal cord through direct or indirect pathways. For instance, you have neurons in your gut that sense what sorts of nutrients you've eaten or drank, and then send neural signals, electrical signals up to the brain. And indeed that whole process happens to be modulated by dopamine.\",\n",
       "   \"It is a hormone that acts also as a bit of a neurotransmitter, like many hormones, and it tends to be antagonistic or in opposite to dopamine. So dopamine is a neurochemical, it's actually a neuromodulator, meaning it modulates the activity of a bunch of neural circuits in the brain. It also controls the release of various hormones in the body. Dopamine is almost always associated with states of motivation, pursuit, and drive.\",\n",
       "   \"So you say, well, okay, so dopamine isn't involved in motivation and it isn't involved in pleasure. No, it absolutely is. They could still enjoy the food, but if they moved the rat literally one body length away from the lever, what they found was the animals that had dopamine would move over to the lever, press it and eat. And the ones, the rats that did not have dopamine available to them wouldn't even move one body length, one rat length to the lever in order to press it and get the food. Dopamine therefore is not about the ability to experience pleasure.\"],\n",
       "  ['But when I look at a patient, I create a dashboard. And the dashboard is what are all the things that are a threat to every component of your longevity, both lifespan and healthspan. We talked about a bunch of those things. So what is your risk for atherosclerosis and what are we doing about it? What is your risk for cancer? What are we doing about it? What is your risk for neurodegeneration? What are we doing about it? What is your risk for accidental death? What are we doing about it?',\n",
       "   \"Catechol-O-methyltransferase, as the name suggests, because it has an ace in there in the context of a discussion about biology that almost always means you're talking about an enzyme. Catechol-O-methyltransferase is an enzyme involved in the regulation of the so-called catecholamines. Catecholamines being dopamine, epinephrine, and norepinephrine. Okay, we've already talked about dopamine in the context of Parkinson's.\",\n",
       "   \"And it's evaluating a number of things like context, like what's going on in this room, what's going on in this scene, what's supposed to happen here, what might I do, what should I do, what should I not do, et cetera, et cetera.\"],\n",
       "  [\"If you'd like to learn more about Jocko's work and the various things he's involved in, please check out the Jocko podcast. Please also check out the various links in the show note captions to Jocko's excellent books on leadership, both for adults and for kids. And check out some of the other links that relate to some of his other business ventures. If you're learning from and or enjoying this podcast, please subscribe to our YouTube channel. That's a terrific zero cost way to support us.\",\n",
       "   \"Welcome to the Huberman Lab Podcast, where we discuss science and science-based tools for everyday life. I'm Andrew Huberman, and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine. Today, my guest is Jocko Willink. Jocko Willink is a retired Navy SEAL, an author of numerous important books on leadership and team dynamics, and the host of the Jocko podcast.\",\n",
       "   'During his 20-year career with the US Navy, Jocko served with SEAL Team 3 as commander of Task Unit Bruiser in Ramadi, Iraq, and elsewhere in the Middle East, as well as deployments in Asia and Europe. After retiring from the Navy, Jocko used his experience and knowledge gleaned from his time in the SEAL teams as a way to develop tools that anybody can use to develop their leadership skills, both for leading themselves and for leading others.'],\n",
       "  [\"So I think of artificial intelligence first as a big philosophical thing. Pamela McCordick said AI was the ancient wish to forge the gods or was born as an ancient wish to forge the gods. So I think at the big philosophical level, it's our longing to create other intelligent systems, perhaps systems more powerful than us. At the more narrow level, I think it's also a set of tools that are computational, mathematical tools to automate different tasks. And then also it's our attempt to understand our own mind.\",\n",
       "   \"We want to ask that algorithm, first of all, do you know what the hell you're doing? Do you know, do you understand the society level effects you're having? And can you explain the possible other trajectories? Like we would have that kind of conversation with a human. We want to be able to do that with an AI. And on my own personal level, I think it would be nice to talk to AI systems for stupid stuff, like robots when they fail to- Why do you fall down the stairs? Yeah, but not an engineering question, but almost like endearing question.\",\n",
       "   \"First of all, this is a beautiful description of terms that I've heard many times among my colleagues at Stanford, at meetings in the outside world. And there's so many fascinating things. I have so many questions, but I do want to ask one question about the culture of AI, because it does seem to be a community where, at least as an outsider, where it seems like there's very little consensus about what the terms and the operational definitions even mean.\"],\n",
       "  [\"And when people ask me, what's the one supplement I should take, if they were to only take one supplement, I always recommend AG1 for the simple reason that vitamins, the minerals, and the probiotics support metabolic health, they support endocrine health, they support brain health, and the probiotics and prebiotics in there in particular support the so-called gut-brain axis.\",\n",
       "   \"Many of you have graciously asked how you can help support the Huberman Lab podcast. There are several ways that you can do that. One is to check out our sponsors. The other is we've set up a Patreon account. You can go to patreon.com slash Andrew Huberman, and that allows you to donate to the podcast at a variety of different levels. In addition, if you could subscribe to the podcast on YouTube, that's terrific. If you haven't done that already, please do so. And please leave a comment.\",\n",
       "   \"If you have comments or feedback or suggestions about topics or guests that you'd like us to cover on the Huberman Lab Podcast, please put those in the comment section on YouTube. We do read all the comments. Please also check out the sponsors mentioned at the beginning of today's episode. That is the best way to support this podcast. As also mentioned at the beginning of the episode, we are now partnered with Momentous Supplements.\"],\n",
       "  [\"And what they end up doing is destructive, right? And it's very clearly destructive. It's a great example because it's destructive of the science, which is ostensibly the reason that you're there, right? It's the reason you were there. But someone who needs to exert over control is there not just for that reason. And then the other reasons can trump the generative reason that they're there. And that's how envy, when it is the product of aggression or pleasure-seeking being too high, always, unfailingly, creates destruction.\",\n",
       "   \"So the idea that I want more, I need more, I don't have enough, I can't get enough, then fosters envy, which is not the desire to be better or to have more, but it's just the desire to feel better about the self, whether that involves raising the self up or bringing someone else down. That's why envy is destructive. So very high levels of aggression that are not tempered, for example, by a generative drive that would also be high, then create a circumstance of envy and the envy is destructive.\",\n",
       "   \"And you always see that when people are enacting narcissism, whether it's, okay, a bunch of bad things have happened. And for whatever reason, like I'm in an unhealthy place and I'm enacting it right now. Or if I'm enacting it every day of my life, because it's in my character structure and I have it recognized and changed it, it's always destructive.\"],\n",
       "  [\"The Perfect Your Sleep is a little bit more like this episode, more focused on protocols. Master Your Sleep includes protocols and mechanism. Again, you can find those at hubermanlab.com. We also have a sleep toolkit, a distilled list of things to do in order to optimize your sleep. I highly recommend that you download that. You can go to hubermanlab.com, go to the Neural Network newsletter. It is listed there. If you want, you can sign up for the newsletter, but you don't have to.\",\n",
       "   \"I personally have been using a gratitude protocol for the last several years, but that protocol was based on my ignorance really about the scientific literature and was mainly based on what I'd heard out there on the internet, which is that I should list out or think about or verbally recite the things that I'm grateful for. The sort of protocol that we arrived at today based on the scientific literature is distinctly different from that. And as a consequence, I've started to script out a protocol identical to the one I just described, and I intend to use that going forward.\",\n",
       "   \"And to the chagrin of parents, across the night, it's basically the same. They're awake, they're asleep, they're awake, they're asleep. And that's more the schedule that these types of protocols have suggested. And there was a really great comprehensive review that found not only that they weren't necessarily helpful, but they were actually really quite detrimental.\"],\n",
       "  [\"I must say that the conversation with Lex was, without question, one of the most fascinating conversations that I've ever had, not just in my career, but in my lifetime. I knew that Lex worked on these topics, and I think many of you are probably familiar with Lex and his interest in these topics from his incredible podcast, the Lex Friedman Podcast. If you're not already watching that podcast, please subscribe to it. It is absolutely fantastic. But in holding this conversation with Lex, I realized something far more important.\",\n",
       "   'Lex has a phenomenal, I would say a one in an 8 billion ability to find these people, make them comfortable, and in that comfort, both try to understand them and to confront them and to push them so that we all learn. All of which is to say that Lex Friedman is no longer just an accomplished scientist. He certainly is that, but he has also become one of the more preeminent thought leaders on the planet.',\n",
       "   \"And if there's anything that really captures the essence of Lex Friedman, it's his love of learning, his desire to share with us the human experience and to broaden that experience so that we all may benefit. In many ways, our discussion during today's episode captures the many facets of Lex Friedman, although no conversation, of course, could capture them all. We sit down to the conversation just days after Lex returned from Ukraine, where he deliberately placed himself into the tension of that environment in order to understand the geopolitics of the region and to understand exactly what was happening at the level of the ground and the people there.\"],\n",
       "  ['And we discussed the multiple roles that AI is very likely to have in all of our lives in the near future. Mark explains how not too long from now, all of us are very likely to have AI assistants. For instance, assistants that give us highly informed health advice, highly informed psychological advice. Indeed, it is very likely that all of us will soon have AI assistants that govern most, if not all of our daily decisions. And Mark explains how if done correctly, this can be a tremendously positive addition to our life.',\n",
       "   \"When they tend to engage in more things, if they have a positive outlook on life, presumably they are engaging in adaptive things, things like social relationships, job-related, school-related, goal-related behavior. So it's important to understand that a discussion of neural circuit changes in response to ketamine is really a discussion of neural circuit changes in response to ketamine that shift one's overall system toward having yet further neural circuit changes in response to daily activities and thereby bolstering health, or in this case, mental health.\",\n",
       "   \"Yeah, conceivably. Yeah, not yet, but yeah, someday. So going back to AI, most people who hear about AI are afraid of AI. Well, I think most people who aren't informed. This goes back to our elites versus masses thing. Oh, interesting. Well, I heard you say that, and this is from a really wonderful tweet thread that we will link in the show note captions that you put out not long ago and that I've read now several times and that everyone really should take the time to read.\"]],\n",
       " 'answers': [\"Neuroplasticity refers to the nervous system's ability to change in response to experience. At a cellular level, neuroplasticity involves mechanisms such as long-term potentiation, which is the strengthening of specific connections between neurons at synapses. Synapses are the communication points between neurons, and through long-term potentiation, these connections can be reinforced, allowing certain neurons to communicate more effectively with each other. This process of strengthening synaptic connections enables the nervous system, including the brain and spinal cord, to adapt and learn new behaviors or skills based on experiences.\",\n",
       "  'The role of dopamine in the body is multifaceted based on the series of transcripts from the Huberman Lab podcast. Dopamine is highlighted as a critical neurotransmitter that plays a key role in motivation, pleasure, movement, and reward. It is not only associated with pleasure but is also a significant driver of motivation, pursuit, and drive. Dopamine is involved in modulating neural circuits in the brain, controlling the release of various hormones in the body, and influencing our actions and behaviors. Dopamine is crucial for states of motivation, effort exertion, and anticipation, as well as in motivating individuals to pursue goals and avoid future pain. It is emphasized that dopamine is not solely about experiencing pleasure but is deeply intertwined with our ability to feel motivated, driven, and engaged in various activities.',\n",
       "  \"A catecholamine is a type of neurotransmitter that includes dopamine, epinephrine, and norepinephrine. These neurotransmitters play crucial roles in various physiological functions in the body, such as regulating mood, stress response, heart rate, and blood pressure. Catecholamines are involved in the body's fight-or-flight response and are essential for overall brain and body function.\",\n",
       "  \"Jocko Willink discusses leadership in the context of sharing tools for leadership development that are applicable to both self-leadership and leading others. These tools are derived from his military experience serving with SEAL Team 3 and as commander of Task Unit Bruiser in Ramadi, Iraq, and elsewhere in the Middle East, as well as deployments in Asia and Europe. After retiring from the Navy, Jocko used his experience and knowledge to develop tools that can be utilized by anyone to enhance their leadership skills. The conversation with Andrew Huberman emphasizes the alignment between the leadership tools used by SEAL teams and the science-based tools studied in Huberman's lab, highlighting their practical effectiveness in enhancing mental and physical health and performance.\",\n",
       "  \"Lex Fridman believes that the evolution of AI involves both a philosophical aspect and a practical aspect. Philosophically, he sees AI as humanity's desire to create intelligent systems, potentially more powerful than humans, reflecting an ancient wish to forge gods. He also views AI as a means to understand our own minds. On a more practical level, Fridman describes AI as a set of computational and mathematical tools to automate tasks. He envisions AI not only transforming individuals but also potentially humanity as a whole. Fridman emphasizes the importance of understanding the societal impacts of AI and the need to be able to engage in conversations with AI systems similar to how we interact with humans. Additionally, he expresses a desire to have casual conversations with AI systems for non-engineering purposes, suggesting a more human-like interaction with machines.\",\n",
       "  \"To support the Huberman Lab podcast, you can do the following:\\n\\n1. Check out the sponsors mentioned in the episodes.\\n2. Consider donating to the podcast through their Patreon account at patreon.com/AndrewHuberman.\\n3. Subscribe to the podcast on YouTube if you haven't already done so.\\n4. Leave comments and feedback on the podcast's YouTube channel, as they do read all the comments.\\n5. Support the podcast by checking out the sponsors mentioned at the beginning of the episodes.\\n6. Note that the podcast is also partnered with Momentous Supplements, which could be another way to support them.\",\n",
       "  'People make self-destructive decisions because of imbalances in their personal drives, specifically aggressive and pleasure-seeking drives that are not tempered by a strong generative drive. When individuals have very high levels of aggression or pleasure-seeking behaviors that are not counterbalanced by a generative drive, it can lead to destructive outcomes such as envy. Envy, in this context, is described as not just the desire to be better or have more, but rather a desire to feel better about oneself, even if it involves bringing others down. This imbalance in drives can result in destructive behaviors and decisions that stem from a lack of self-awareness and an unhealthy character structure, leading individuals to enact destructive patterns like narcissism. Ultimately, these imbalances and lack of self-awareness can drive individuals to make choices that are harmful to themselves and potentially others, manifesting as self-destructive decisions.',\n",
       "  \"```\\n1. Align sleep schedule with natural circadian rhythms.\\n2. Create a sleep environment conducive to rest, including controlling light and temperature.\\n3. Avoid substances like alcohol and caffeine close to bedtime.\\n4. Implement a consistent bedtime routine to signal the body it's time to sleep.\\n5. Prioritize both REM and non-REM sleep stages throughout the night.\\n6. Minimize disruptions during the night to promote uninterrupted sleep cycles.\\n7. Consider the impact of factors like diet, exercise, and stress on sleep quality.\\n```\",\n",
       "  \"Lex Fridman discusses a range of topics in the series of interviews with Dr. Andrew Huberman. Some of the key topics include:\\n1. The future of humans and machines, focusing on how AI can transform our understanding of ourselves and our interactions with the world.\\n2. Various aspects of AI and machine learning, such as supervised and self-supervised learning, the role of neural networks, and the potential for machines to provide insights about ourselves that we may not fully comprehend.\\n3. The importance of relationships, both with living beings and machines, and how these interactions can serve as educational experiences.\\n4. Fridman's experiences in Ukraine during the conflict, exploring human adaptation to war, the impact of propaganda, and the ability of humans to generalize hate towards entire groups.\\n5. The challenges faced by science and academia during times of conflict, including scientists being compelled to join military efforts.\\n6. The value of in-person teaching, the slow yet rewarding process of scientific research and publishing, and critiques of the traditional peer review system.\\n7. The psychology of social media platforms like Twitter and Instagram, as well as Fridman's approach to spreading positivity online.\",\n",
       "  'Yes, there is a generally positive outlook on the future of AI based on the transcripts provided. Both Marc Andreessen and the discussion in the episode featuring him emphasize the transformative potential of emerging technologies like AI. Andreessen believes that AI will greatly improve human experiences by becoming an integral part of daily decision-making through AI assistants. He mentions that if AI is leveraged correctly, it can be a tremendously positive addition to our lives. Additionally, despite fears surrounding AI diminishing human experience, there is a vision presented where AI enhances life if used appropriately. Therefore, the overall sentiment expressed in the transcripts is optimistic about the future of AI and its potential to positively impact human life.'],\n",
       " 'ground_truths': [\"Brain neuroplasticity refers to the nervous system's ability to change in response to experience in ways that are adaptive, allowing us to do things we could not do before. This encompasses changes in the brain, spinal cord, and the connections between them and the organs and tissues of the body. At a cellular level, neuroplasticity involves mechanisms such as long-term potentiation, which is the strengthening of connections between neurons. These connections, or synapses, are the points of communication between neurons and can be reinforced so that certain neurons can communicate more robustly with other neurons than they did previously. This strengthening of synaptic connections is a key aspect of how neuroplasticity enables the acquisition of new skills and the adaptation to new experiences.\",\n",
       "  'Dopamine plays several roles in the body as described in the provided transcripts from the Huberman Lab podcast. Firstly, dopamine is a neuromodulator that modulates the activity of various neural circuits in the brain and controls the release of various hormones in the body. It is associated with states of motivation, pursuit, and drive, as it influences our actions and the effort we invest in pursuing goals. Dopamine is not only linked to pleasure but is also a key driver in our pursuit of goals. It is involved in the anticipation and craving that motivates us to pursue more to avoid future pain, rather than just the ability to experience pleasure. Additionally, dopamine dynamics, including peaks, troughs, and baseline levels, can be managed to optimize motivation and goal achievement. It is also mentioned that dopamine can be antagonistic to certain hormones, implying that it has a regulatory role in the hormonal balance of the body.',\n",
       "  'Catecholamines are dopamine, epinephrine, and norepinephrine, as mentioned in the transcript from the Huberman Lab podcast episode discussing placebo effects. These are neuromodulators involved in the regulation of various physiological functions.',\n",
       "  'Based on the provided context, Jocko Willink shares tools for leadership development that are applicable to both self-leadership and leading others. These tools are derived from his military experience with the SEAL teams and have been adapted for use in various life contexts, such as business and personal growth. The context suggests that Jocko emphasizes the practical effectiveness of these tools in enhancing mental and physical health and performance. However, the specific details of what Jocko has to say about leadership are not included in the provided transcripts. Therefore, I cannot answer the question with the provided context.',\n",
       "  \"Based on the provided context, Lex Fridman views the evolution of AI from a philosophical and practical standpoint. Philosophically, he sees AI as humanity's ancient wish to create intelligent systems, potentially more powerful than ourselves, reflecting our longing to understand and replicate intelligence. Practically, he considers AI as a set of computational and mathematical tools designed to automate tasks and as an attempt to understand the human mind. Fridman also expresses a desire for AI to be able to communicate with humans about its actions and the societal impacts it may have, similar to how we would discuss such topics with another human. He envisions a future where AI can transform both the individual self and humanity as a whole, and he highlights the importance of relationships with machines, suggesting that these interactions can teach us about ourselves. However, he also points out the lack of consensus within the AI community regarding the definitions and terms used, indicating that the field is still developing and that its cultural and conceptual frameworks are not yet fully established.\",\n",
       "  'You can support the Huberman Lab podcast in several ways as mentioned in the provided transcripts:\\n\\n1. Check out and consider supporting the sponsors mentioned in the episodes.\\n2. Donate to the podcast through the Patreon account at patreon.com/AndrewHuberman, where you can contribute at various levels.\\n3. Subscribe to the podcast on YouTube and leave a comment there.\\n4. Provide comments, feedback, or suggestions about topics or guests in the comment section on YouTube.',\n",
       "  'Based on the context provided from the transcripts of the Huberman Lab podcast episode with Dr. Paul Conti, people make self-destructive decisions due to an imbalance in their personal drives, specifically when aggressive and pleasure-seeking drives are too high and not tempered by a generative drive. This imbalance can foster envy, which is not merely the desire to be better or to have more, but rather the desire to feel better about oneself, which can involve raising oneself up or bringing someone else down. Envy, as a result of untempered aggression or excessive pleasure-seeking, is inherently destructive. Additionally, when people enact narcissism, whether due to a temporary unhealthy state or as a part of their character structure that has not been recognized and changed, it leads to destructive behaviors. These self-destructive decisions are influenced by internal narratives that stem from childhood experiences and a lack of self-awareness.',\n",
       "  'Based on the provided context, I cannot answer the question with a detailed sleep protocol as the transcripts do not provide specific steps or guidelines for a sleep protocol. The context mentions the existence of a sleep toolkit and protocols available on the Huberman Lab website, but the actual content of these protocols is not included in the transcripts.',\n",
       "  'Based on the provided context, Lex Fridman discusses the following topics:\\n\\n1. The future of humans and machines, including how artificial intelligence (AI) can transform our understanding of ourselves and our interactions with the world.\\n2. Various aspects of AI and machine learning, such as supervised and self-supervised learning, the role of neural networks, and the potential for machines to inform us about ourselves in ways we cannot yet comprehend.\\n3. The importance of relationships with both living beings and machines, and how these interactions can educate us about ourselves.\\n4. His experiences in Ukraine during the conflict, the human capacity to adapt to war, and the importance of love over hate.\\n5. The power of propaganda, the generational impact of war, and the tendency of humans to generalize hate towards entire groups.\\n6. The challenges faced by science and academia during the war, including the pressure on scientists to join the military effort.\\n7. The value of in-person teaching, the process of scientific research and publishing, and critiques of the traditional peer review system.\\n8. Alternative models for scientific communication.\\n9. The psychology of social media platforms like Twitter and Instagram, and his approach to spreading positivity online.\\n\\nThese topics are synthesized from the summaries and transcripts of the interviews with Lex Fridman on the Huberman Lab podcast episodes 29 and 100.',\n",
       "  'Based on the provided context, there is a generally positive outlook on the future of AI as presented by Marc Andreessen in the Huberman Lab podcast. Andreessen discusses the likelihood of AI becoming an integral part of daily decision-making through AI assistants, which he believes can be a \"tremendously positive addition to our life\" if leveraged correctly. He envisions AI assistants giving highly informed health and psychological advice, and enhancing human experiences. This positive stance is further supported by his view that fears surrounding AI diminishing human experience are held by those who are not informed, suggesting that with proper understanding and use, AI has the potential to greatly benefit society. Therefore, within the context provided, the outlook on the future of AI is portrayed as optimistic.']}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'fa5\\xa1y\\xb5=\\x1by\\x82C\\x98\\x89>M\\xcf\\xde\\x0e m_\\xad\\xb9\\xa8\\xe8\\xac#6\\xf8\\xef\\xda\\x17G\\xa1t\\xbc\\xff\\xc9M\\xf2\\x9b$\\xbd(\\xce\\xa5\\x1d\\x85 \\xd3{\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00', b'\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 e\\xcd\\xa6\\x1dY\\xeb\\xddR\\x05\\x9f\\xced\\xd8H=|?cA\\xccDrPk\\x01\\t\\xca\\xe8\\xce:\\xf5\\x16']\n",
      "Bad pipe message: %s [b'\\x86\\x1e/\\x8d$fDI@k3\\x97\\x1d6\\xec_+\\xe9 g-\\x17\\x81(U_:7\\xde\\x0f\\xfbF\\xd1\\xc8\\xc4\\x8a7\\xfe\\xbb\\x0e\\xa4P\\xa4\\x05\\xcd\\x03\\xb3\\xee\\x0c\\xe5s\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08']\n",
      "Bad pipe message: %s [b'\\x08\\x08\\t\\x08\\n\\x08']\n",
      "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'\\x94s2r\\xaa\\x98U\\xa7L\\xfc\\x9ep\\xc8F\\xc2s\\x1cS\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0', b\"S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\"]\n",
      "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\x12V\\x02\\x02*,\\xbd^\\xee\\x83\\xb34(}>\\xeb\\xa2z\\x86\\xe8A\\xab']\n",
      "Bad pipe message: %s [b'\\x11\\x00\\x96\\x00\\x05\\x00']\n",
      "Bad pipe message: %s [b'\\xbd\\x0c\\x96\\x9f\\xa1x\\xa9c\\x9f6l?\\xcf\\x80!\\xd0\\xc0$\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00']\n",
      "Bad pipe message: %s [b'\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00']\n",
      "Bad pipe message: %s [b')\\xa8$\\xc8Md0\\xa9\\xd9\\xb9\\x9b\\x88\\xa0.|+m\\x9d\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02']\n",
      "Bad pipe message: %s [b'\\xc8[\\x9f\\xb9\\x17\\x12\\x7f#\\xe6[\\x83$O\\xac\\x98\\xb2\\x02\\xe3\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0', b'\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00']\n",
      "Bad pipe message: %s [b'\\xaa\\x15\\x90\\xd2\\xe7\\\\\\xf9', b'6\\x9c(\\xe1\\xe8CX\\x03]\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88']\n",
      "Bad pipe message: %s [b\"\\x16\\xa6\\xf5\\xe2Z{\\xf6\\xf0\\x15/^\\x19\\x08\\xb2\\xc4\\xf5KO\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\"]\n",
      "Bad pipe message: %s [b'\\x03', b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\n",
      "Bad pipe message: %s [b\"\\x1c=\\xf4'\\xde\\xb5\\x9f\\x02p\\x1c@\\x06\\x87\\xf0Z\\x16\\xcf\\x0e\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\"]\n"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "766a8a26-c10b-4d13-af2e-9379409eadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_dataset(questions: list[str],\n",
    "                        contexts: list[list[str]],\n",
    "                        answers: list[str]\n",
    "                       ) -> EvaluationDataset:\n",
    "    assert len(questions) == len(contexts) == len(answers), 'Mismatched lengths in input values, retry after correcting'\n",
    "    test_cases = []\n",
    "    for i in range(len(questions)):\n",
    "        test_case = LLMTestCase(input=questions[i],\n",
    "                                actual_output=answers[i],\n",
    "                                retrieval_context=contexts[i])\n",
    "        test_cases.append(test_case)\n",
    "    return EvaluationDataset(alias='Initial test', test_cases=test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ce481-bae0-4d01-ae76-f57b36434c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsa",
   "language": "python",
   "name": "vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
