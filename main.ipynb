{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ddf3f52-c9f4-4c33-99b7-90c968e36b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from listennotes import podcast_api\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env', override=True)\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from math import ceil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor\n",
    "from preprocess_helpers import Splitters\n",
    "import openai\n",
    "from retrieval import Retriever\n",
    "from reranker import ReRanker\n",
    "from tiktoken_functions import Tokenizer\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fc919-6968-48bd-a755-e0e470ab6639",
   "metadata": {},
   "source": [
    "### 1.) Import Podcast Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f8ed14-32ee-48e2-94a5-8697d112e79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_folder = '/home/elastic/notebooks/podcast_transcripts/'\n",
    "podcasts = [os.path.join(podcast_folder, file) for file in os.listdir(podcast_folder) if file.endswith('.txt')]\n",
    "len(podcasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8197b9-d246-437a-a8b2-ab536c08b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_podcasts(files: List[str]) -> List[str]:\n",
    "    transcripts = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            text = f.read().strip()\n",
    "            transcripts.append(text)\n",
    "    return transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ccc38ee-5d39-495f-9722-c81e00f9dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 ms, sys: 4.69 ms, total: 7.42 ms\n",
      "Wall time: 7.18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transcripts = load_podcasts(podcasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76177d5-d8e7-4e93-a0e2-5a99469ce578",
   "metadata": {},
   "source": [
    "### 2a.) Split Text into Sentences - Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2dcb452-5760-4c19-8fff-9e40ab64e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysbd import Segmenter\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "biencoder = 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d79a5cfd-0794-47b6-ab6c-eb1a70b05e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d7b3676-484c-49b8-a15a-6c5691157d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_texts(texts: List[str]) -> List[List[str]]:\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    all_texts = []\n",
    "    start = time.perf_counter()\n",
    "    for text in tqdm(texts, 'Texts'):\n",
    "        doc = nlp(text)\n",
    "        sentences = [str(sent).strip() for sent in doc.sents]\n",
    "        # half = int(ceil(len(sentences)/2))\n",
    "        # sentences[:half]\n",
    "        all_texts.append(sentences)\n",
    "    end = time.perf_counter() - start\n",
    "    print(f'Total Time: {round(end/60, 2)} minutes')\n",
    "    return all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc8c73f3-3792-40c0-be11-71fb0938ceb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Texts: 100%|███████████████████████████████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 1.23 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_sentences = split_texts(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9515d8ac-84ef-40ff-91b3-7e0a68782770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>313.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.056032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>235.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>267.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>604.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  100.000000\n",
       "mean   313.220000\n",
       "std    115.056032\n",
       "min    162.000000\n",
       "25%    235.750000\n",
       "50%    267.500000\n",
       "75%    371.000000\n",
       "max    604.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([len(corpus) for corpus in text_sentences]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4bb15-7493-446a-8963-f975c43a8c1f",
   "metadata": {},
   "source": [
    "### 2b.) Split Text into Sentences - SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e060b8-3eaf-44f4-9d6a-6f5ece2f143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 513 ms, sys: 8.08 ms, total: 521 ms\n",
      "Wall time: 520 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_sentences = [Splitters().split_into_sentences(text) for text in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10169dc9-9429-4428-87ca-9b8f8f0a25ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>313.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>114.630995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>236.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>271.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>371.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>604.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  100.000000\n",
       "mean   313.760000\n",
       "std    114.630995\n",
       "min    162.000000\n",
       "25%    236.750000\n",
       "50%    271.500000\n",
       "75%    371.750000\n",
       "max    604.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([len(corpus) for corpus in split_sentences]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083cde5b-9497-4085-8b42-af7e389acbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "103\n",
      "128\n",
      "110\n",
      "192\n",
      "100\n",
      "140\n",
      "154\n",
      "197\n",
      "130\n",
      "166\n",
      "127\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,len(split_sentences),8):\n",
    "    print(sum([len(sentence.split()) for sentence in split_sentences[0][x:x+8]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833d72e-c856-44b4-bf4f-17121834dc53",
   "metadata": {},
   "source": [
    "### 2c.) Split Text into Sentences - PyBSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f96538f-7623-430f-857f-3280826de251",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = Segmenter(clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b3dd0b-7572-4255-bb02-061957778a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# results = [seg.segment(text) for text in tqdm(transcripts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04c6a9a1-b82e-4952-ae28-273661a9ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment(text: str) -> List[str]:\n",
    "    alist = seg.segment(text)\n",
    "    return alist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f682a4-efd9-4bd6-8228-167101e5f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_segment(transcripts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd741d-f3d4-4135-8234-8e58f80652ed",
   "metadata": {},
   "source": [
    "### 3. Group Sentences into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "badb2aed-97d9-46d2-956f-fa507575a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(text_sentences: List[List[str]], sent_chunk_length: int=8) -> List[List[str]]:\n",
    "    if isinstance(text_sentences[0], str):\n",
    "        text_sentences = [text_sentences]\n",
    "    chunks = []\n",
    "    for corpus in text_sentences:\n",
    "        for x in range(0,len(corpus),sent_chunk_length):\n",
    "            achunk = []\n",
    "            achunk.append(' '.join(corpus[x:x+sent_chunk_length]))\n",
    "            chunks.append(achunk)\n",
    "    return [string for alist in chunks for string in alist]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26304f35-ed11-42d9-8b3c-f86d6e9b1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = split_sentences[0][:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201c69a9-78fa-4160-88fd-31405f72e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = grouper(split_sentences)\n",
    "chunks = grouper(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7100e1-f905-4bdd-b961-aa6cca918d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello and welcome to The Intelligence from The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And not just any crisp, a particular flavor of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The battle between the FTC and Microsoft rolls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ms. Kahn isn't just aggressively going after b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But whatever your view, she is really shaking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>And so what does that approach look like in pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A few weeks ago, I sat down with her to find o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How are the cases that they're bringing workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The most notable one occurred last year in Jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kahn has argued that it could suppress competi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And coming in and telling people that the agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Biden administration so far has prioritize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>But it is actually possible that we see a cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>When you download the Kroger app, you have eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>For decades, economic growth in China seemed l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yet early indications show that after a strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>And everybody's watching the slowdown for what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>And Don, what exactly is driving this change? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>China's response to a lot of these problems ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>So as the central bank cuts interest rates, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>We have seen some small targeted stimulus prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>We really have not seen that so far. The small...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>And I'd say that's a welcome surprise for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Open it. Oh, that first whiff. Oh, it's so goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>First of all, every kind of potato from countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>But these are cheese and onion crisps. So spri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>You know, Seamus Heaney, who is one of Ireland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>And thanks to a very globalised food system an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>And yet for me, they're very much a snack that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>That's all for this episode of The Intelligenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Chunks\n",
       "0   Hello and welcome to The Intelligence from The...\n",
       "1   And not just any crisp, a particular flavor of...\n",
       "2   The battle between the FTC and Microsoft rolls...\n",
       "3   Ms. Kahn isn't just aggressively going after b...\n",
       "4   But whatever your view, she is really shaking ...\n",
       "5   And so what does that approach look like in pr...\n",
       "6   A few weeks ago, I sat down with her to find o...\n",
       "7   How are the cases that they're bringing workin...\n",
       "8   The most notable one occurred last year in Jul...\n",
       "9   Kahn has argued that it could suppress competi...\n",
       "10  And coming in and telling people that the agen...\n",
       "11  The Biden administration so far has prioritize...\n",
       "12  But it is actually possible that we see a cont...\n",
       "13  When you download the Kroger app, you have eas...\n",
       "14  For decades, economic growth in China seemed l...\n",
       "15  Yet early indications show that after a strong...\n",
       "16  And everybody's watching the slowdown for what...\n",
       "17  And Don, what exactly is driving this change? ...\n",
       "18  China's response to a lot of these problems ov...\n",
       "19  So as the central bank cuts interest rates, it...\n",
       "20  We have seen some small targeted stimulus prog...\n",
       "21  We really have not seen that so far. The small...\n",
       "22  And I'd say that's a welcome surprise for the ...\n",
       "23  Open it. Oh, that first whiff. Oh, it's so goo...\n",
       "24  First of all, every kind of potato from countr...\n",
       "25  But these are cheese and onion crisps. So spri...\n",
       "26  You know, Seamus Heaney, who is one of Ireland...\n",
       "27  And thanks to a very globalised food system an...\n",
       "28  And yet for me, they're very much a snack that...\n",
       "29  That's all for this episode of The Intelligenc..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = pd.read_parquet('./test_chunks.parquet')\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d101bf79-6095-42a5-95c6-9b3d451c74c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello and welcome to The Intelligence from The Economist. I'm Aure Ogunbiyi. And I'm Jason Palmer. Every weekday we provide a fresh perspective on the events shaping your world. China was one of the last countries to abandon pandemic lockdowns, and investors and analysts alike were waiting anxiously for its recovery. The comeback came, but things aren't going quite the way that many expected. And what's the best possible fate for a potato? Our correspondent argues passionately that the answer is a crisp, a potato chip.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(chunks, columns=['Chunks'])\n",
    "# df.to_parquet('./test_chunks.parquet')\n",
    "df.loc[0,'Chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c07222c6-143d-43db-8ae3-a999323b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create docs\n",
    "docs = df.Chunks.values.tolist()\n",
    "#create ids\n",
    "ids = df.index.tolist()\n",
    "dicts = [{'content': doc, 'name': 'Intelligent Economist'} for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fae97-f211-41b3-ad9c-05c6f66c7a24",
   "metadata": {},
   "source": [
    "### 4. Encode Chunks as Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89720b-8b68-44a8-8ee9-4c6c59f7b121",
   "metadata": {},
   "source": [
    "### 4a.) SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e26b5d8-f716-4712-ac11-ed047dc8bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daae1c56-98a6-4dd6-9b91-04fef6a39734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cadbc1e1-b38f-447a-85c6-75d0af4f5c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = model.encode(sentences=chunks, show_progress_bar=True, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5214304-bdeb-4c03-b369-866333915e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./test_vectors.npy', vectors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab7a7381-7e5d-4ecf-8069-a7a6a1671347",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = model.encode(sentences)\n",
    "query = 'discussion on taking chances in life'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd9599-57cd-4e58-9522-fab80917e256",
   "metadata": {},
   "source": [
    "### 4b.) OpenAI Ada Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73176902-10a2-48d9-a656-cecae55353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "model = \"text-embedding-ada-002\"\n",
    "\n",
    "#get cost first\n",
    "tokenizer = Tokenizer(model_type=\"cl100k_base\", price=0.001)\n",
    "\n",
    "cost = tokenizer.get_cost(docs)\n",
    "\n",
    "results = openai.Embedding.create(input=docs, engine=model)\n",
    "vectors = results['data']\n",
    "vectors = [vec['embedding'] for vec in vectors]\n",
    "len(vectors)\n",
    "\n",
    "### Indexing (Qdrant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5780c8a9-cd7f-4129-9907-f238361c7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23272330-b086-40a1-8063-f63f4c2b842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient('localhost', port=6333)\n",
    "collection = 'test_collection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab849a9b-f52f-4aca-a627-51556d378652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.recreate_collection(collection_name=collection, vectors_config=VectorParams(size=1536, distance=Distance.COSINE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c49c9008-15ee-4d0d-9fee-2ac0ffc34a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('models/my-128dim-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "381dd08e-1fd2-46c2-a10e-0aa481ad97c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='test_collection')])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f625d094-7286-46e7-82b5-b51bb4a100d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_collection(collection_name=collection, vectors=vectors, payload=dicts, ids=ids, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6769753e-a9f0-4ffa-8d66-d1cf6cf65234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe880e41-6bb1-4427-bd50-e2582067ca44",
   "metadata": {},
   "source": [
    "### Search (Qdrant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1db376e6-ee5f-4bf3-abd7-8731040b5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(model_type=model)\n",
    "reranker = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fa413937-f9c1-48b6-9e77-25bb06271400",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'GOP thoughts on antitrust law'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e14f94fc-2a21-49c1-89fc-497db4b06ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.4 ms, sys: 7.15 ms, total: 47.6 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = retriever.search(query, collection=collection, limit=25, return_all=False)\n",
    "sorted_scores = reranker.rerank(results, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "84ae70ff-8cbb-41bb-b6bb-ae3274d66355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('generate.py', <http.client.HTTPMessage at 0x7fadcaceb1c0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://artifacts.opensearch.org/models/ml-models/amazon/gpt/GPT2_xl_sqg/1.0.0/generate.py\", \"generate.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2330e0a-26ed-4861-8f95-cfc9cc06f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " \u001b[0m\u001b[01;34mIRIS\u001b[0m/                            \u001b[01;34mpodcast_summary_demo\u001b[0m/\n",
      " \u001b[01;34mPC_Metrics\u001b[0m/                      \u001b[01;34mpodcast_transcripts\u001b[0m/\n",
      " \u001b[01;34m__pycache__\u001b[0m/                     podcast_vectors.npy\n",
      " bert_similarity.ipynb            preprocess_helpers.py\n",
      " calculating_similarities.ipynb   \u001b[01;34mqdrant_storage\u001b[0m/\n",
      " chunks.parquet                  'query_data(4).csv'\n",
      " \u001b[01;34mdata\u001b[0m/                            ray_data_practice.ipynb\n",
      " \u001b[01;34mdatasets\u001b[0m/                        reranker.py\n",
      " embeddings_helper.py             retrieval.py\n",
      " generate.py                      \u001b[01;34mroberta-stsb-cross-encoder\u001b[0m/\n",
      " install_kernel.sh                \u001b[01;34mspace\u001b[0m/\n",
      " \u001b[01;34mmodel\u001b[0m/                           test_chunks.parquet\n",
      " \u001b[01;34mmodels\u001b[0m/                          test_vectors.npy\n",
      " \u001b[01;34mopenai\u001b[0m/                          tiktoken_functions.py\n",
      " pca.py                           vectors_search.ipynb\n",
      " playing_with_umap.ipynb          vectors_search.py\n",
      " \u001b[01;34mpodcast_mp3_files\u001b[0m/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xf0{u\\xbaQ_y\\x16)(']\n",
      "Bad pipe message: %s [b'\\x88\\xd3\\xc9E\\xc9\\xf6 M\\x96\\xac\"2{\\xb6\\x81y\\x81g\\x02\\x19\\x03\"\\xf54\\xcc\\xa0q\\xc7\\xa85\\x19\\xd9A\\x8a\\xdf\\x00\\x07\\x9f\\xbc\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00']\n",
      "Bad pipe message: %s [b\"U7A\\xa4\\x1f\\xdbB\\xd6`W\\xeb\\xbb\\xfe\\xdd\\x13\\xeb\\xfc\\xc9\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x00\", b'\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00']\n",
      "Bad pipe message: %s [b\"\\x19\\xd0y\\xa2\\x8f.\\xf7\\x82v\\x07\\x8f`T\\xb5-}f\\xe8\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\"]\n",
      "Bad pipe message: %s [b'\\x11\\xc0\\x08\\xc0\\x12\\x00']\n",
      "Bad pipe message: %s [b'\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0']\n",
      "Bad pipe message: %s [b'\\xe7\\xdf`\\xe9\\xda{\\x0f?f\\xc0\\xb3\\xb7|\\x82\\x19\\xea\\x84\\x98\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00']\n",
      "Bad pipe message: %s [b'\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b']\n",
      "Bad pipe message: %s [b'\\xd4B\\xbb\\xcb\\xad\\xc3\\xce&\\x05|e4\\x80\\x84\\x99\\xc9\\xf7\\x13\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f']\n",
      "Bad pipe message: %s [b\"\\xa9\\r\\xfa\\x04\\xea\\xf7l\\x1e\\xa5\\xa2y\\xdf\\xfb\\x996*'t\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.\"]\n",
      "Bad pipe message: %s [b'\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01']\n",
      "Bad pipe message: %s [b\"H'\\xe4\\xdeX\\x10#$\\x11\\x9d [\\x80\\x03 \\x00\\xf1\\xf1\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\", b'D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00']\n",
      "Bad pipe message: %s [b'\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00']\n",
      "Bad pipe message: %s [b'\\x17\\x00\\x03\\xc0\\x10']\n",
      "Bad pipe message: %s [b'\\x12\\xfc(\\xf6\\x19\\xe0\\t\\xf3\\xf7\\x03\\xb6\\xb3*\\x8e0\\xabv\\x91\\x00\\x00\\x86\\xc0', b',\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d']\n",
      "Bad pipe message: %s [b\"\\xfb\\x0e\\x8f\\xf9\\xab\\xc7O(CD\\xd3_\\x8b\\x9cP\\xbc\\xc1'\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\"]\n",
      "Bad pipe message: %s [b'\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f']\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96ac9e-fe85-4d9d-ad58-466e8cb84689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
