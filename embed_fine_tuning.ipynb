{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b201b4c9-b3a4-46ea-9fda-3a026c1d1265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "    \n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from preprocessing import FileIO\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.node_parser import NodeParser, SimpleNodeParser\n",
    "from llama_index import Document\n",
    "from tqdm.notebook import tqdm\n",
    "from openai_interface import GPT_Turbo\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067317f-3cc2-4e15-9f9f-d155e4b691a1",
   "metadata": {},
   "source": [
    "# 1. Data Ingest and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "534bd78a-7ecd-4bc0-bdfb-12b8beda5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/impact_theory_data.json'\n",
    "parquet_path = './data/impact_theory_minilm_256.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcde62ba-5e15-436d-b5b0-12e32514b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d797bd8d-ad32-4a61-b7d3-945017108ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (26448, 12)\n",
      "Memory Usage: 2.42+ MB\n"
     ]
    }
   ],
   "source": [
    "parquet = FileIO().load_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53c273fb-97ed-4817-92e5-299bd13986f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(data: List[dict]) -> List[Document]:\n",
    "    '''\n",
    "    Given a dataset of a list of dictionaries converts each dict \n",
    "    to a llama_index Document and returns a List of Documents.\n",
    "    '''\n",
    "    docs = []\n",
    "    for d in tqdm(data):\n",
    "        unwanted_fields = ['content', 'content_embedding']\n",
    "        emb = d['content_embedding']\n",
    "        content=d['content']\n",
    "        meta = {k:v for k,v in d.items() if k not in unwanted_fields}\n",
    "        doc = Document(embedding=emb, metadata=meta, text=content)\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db9d9c51-240c-4027-9026-628d8c1afcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_fields = ['content', 'content_embedding']\n",
    "# Document(text=parquet[0]['content'], embedding=parquet[0]['content_embedding'], metadata={k:v for k,v in parquet[0].items() if k not in unwanted_fields}).dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6a0035a-b3dc-45f0-acb0-653cf4891b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ca03a664de46e8b7adc1eeaea4c1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = create_documents(parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b066f2eb-fe30-47e4-95f2-215600123670",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/elastic/notebooks/vsa_practice/practice_data/individual_jsons_vectors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4389f30-dd80-43d7-b56f-a2b07473c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_json_files(data: List[dict], output_dir: str=output_dir) -> None:\n",
    "    '''\n",
    "    Given a dataset consisting of a list of dicts i.e. one dict\n",
    "    per pdocast episode, function will save each episode (dict)\n",
    "    to disk in json format.\n",
    "    '''\n",
    "    for i, d in enumerate(data, 1):\n",
    "        try:\n",
    "            video_id = d['video_id']\n",
    "            filename = f'{video_id}_Episode_{i}.json'\n",
    "            path = os.path.join(output_dir, filename)\n",
    "            with open(path, 'w') as f:\n",
    "                json.dump(d, f)\n",
    "        except Exception:\n",
    "            print(Exception)\n",
    "            continue\n",
    "            \n",
    "    print(f'Completed saving {i} json files')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d651dc2-97f1-4098-b5e7-c1d01ee70e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_individual_json_files(parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ef727-c196-4ba1-b287-60abcded5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(docs, for_training=False, verbose=False):\n",
    "    parser = SimpleNodeParser.from_defaults()\n",
    "    if for_training:\n",
    "        nodes = parser.get_nodes_from_documents(docs[:90], show_progress=verbose)\n",
    "    else:\n",
    "        nodes = parser.get_nodes_from_documents(docs[91:], show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Parsed {len(nodes)} nodes')\n",
    "\n",
    "    return nodes\n",
    "\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=SEC_FILE)\n",
    "docs = reader.load_data()\n",
    "print(f'Loaded {len(docs)} docs')\n",
    "\n",
    "train_nodes = load_corpus(docs, for_training=True, verbose=True)\n",
    "val_nodes = load_corpus(docs, for_training=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1014171-0017-4aad-9dfc-724a3306f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SimpleNodeParser.from_defaults(chunk_size=800, chunk_overlap=0, include_prev_next_rel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2dd26198-3514-4d19-813f-778384fadf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2d2af37ef549cc981745422f58f61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/26448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = parser.get_nodes_from_documents(docs, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8aca48-6e00-4fa6-bceb-c3fc016bc67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "859dca8f-0ffa-47d8-a33e-8e50dc5dbacd",
   "metadata": {},
   "source": [
    "# 2. Question Answer Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b5922ed5-7f51-46e1-b734-220680edd48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.finetuning import (\n",
    "    generate_qa_embedding_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "import openai\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a77d7ce3-7b55-4202-b8ca-5a6a7c623a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a4971ea6-c34a-4cdd-bcbc-7ac9cb22329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "37a2099e-5953-42f3-891a-3497b6c04a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = nodes[:125]\n",
    "val_nodes = nodes[125:175]\n",
    "test_nodes = nodes[300:310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "72b3e9c4-7e58-4e8f-8dc5-2c8aec0821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model='gpt-3.5-turbo-0613')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335be4f3-b7b8-4bd4-a93e-8a4517fe194c",
   "metadata": {},
   "source": [
    "### 250 Questions Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fa464-4627-4241-9a29-c218334c9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = generate_qa_embedding_pairs(train_nodes, llm=llm, num_questions_per_chunk=1)\n",
    "# val_dataset = generate_qa_embedding_pairs(val_nodes, num_questions_per_chunk=1)\n",
    "\n",
    "# train_dataset.save_json(\"train_dataset.json\")\n",
    "# val_dataset.save_json(\"val_dataset.json\")\n",
    "\n",
    "# train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
    "# val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dc6f958a-d4bf-4e88-ad26-7675a3166c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:45<00:00,  4.51s/it]\n"
     ]
    }
   ],
   "source": [
    "test = generate_qa_embedding_pairs(test_nodes, llm=llm, num_questions_per_chunk=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b3e5b321-cc5a-4bcf-a873-21a2d8589e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.dict()['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1e273e45-53be-4db3-9338-fac9421bcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import MetadataMode, TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6097c09c-6ab1-4374-abcc-4d2b1c1d34c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this episode, Donald Hoffman discusses the concept of cause and effect and its relationship to our perception of reality. He argues that cause and effect is a useful fiction created by evolution, comparing it to the fictional causality in video games. He suggests that our perception of cause and effect is an illusion within the \"headset\" of space and time, and that outside of this headset, cause and effect may not exist. He also explores the idea of consciousness and its relationship to mathematical structure, referencing Gödel\\'s incompleteness theorem to suggest that there is an endless exploration of mathematical structure. Hoffman\\'s theory of conscious agents proposes that consciousness is fundamental and that our perception of reality is a construction created by these conscious agents. He also discusses the implications of this theory on the concept of self and the nature of consciousness after death. Throughout the conversation, Hoffman emphasizes the importance of using mathematics to precisely articulate scientific theories and the limitations of our perception in understanding the true nature of reality.'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].dict()['metadata']['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6712f4b5-a9af-49df-8bfd-e99f4a532993",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_prompt = '''\n",
    "Show summary and show guest are below.\n",
    "\n",
    "---------------------\n",
    "Summary: {summary}\n",
    "---------------------\n",
    "Guest: {guest}\n",
    "---------------------\n",
    "Given the show Summary and Guest of the show as context \\\n",
    "use the following randomly selected transcript section \\  \n",
    "of the show and not prior knowledge, generate questions that can \\\n",
    "be answered by the transcript section: \n",
    "\n",
    "---------------------\n",
    "{transcript}\n",
    "---------------------\n",
    "\n",
    "Your task is to create {num_questions_per_chunk} questions that can \\\n",
    "only be answered given the previous context and transcript details. \\\n",
    "When possible try to use questions that start with How or Why.  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "08604ace-c4aa-47f4-954f-986ae9cac191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_embedding_pairs(\n",
    "    nodes: List[TextNode],\n",
    "    llm: GPT_Turbo,\n",
    "    qa_generate_prompt_tmpl: str,\n",
    "    num_questions_per_chunk: int = 2,\n",
    ") -> EmbeddingQAFinetuneDataset:\n",
    "    \"\"\"Generate examples given a set of nodes.\"\"\"\n",
    "   \n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    corpus = {node.node_id: node.get_text() for node in nodes}\n",
    "    for node in tqdm(nodes):\n",
    "        node_dict = node.dict()\n",
    "        summary = node_dict['metadata']['summary']\n",
    "        guest = node_dict['metadata']['guest']\n",
    "        transcript = node_dict['text']\n",
    "        node_id = node_dict['id_']\n",
    "        query = qa_generate_prompt_tmpl.format(summary=summary, \n",
    "                                               guest=guest,\n",
    "                                               transcript=transcript,\n",
    "                                               num_questions_per_chunk=num_questions_per_chunk)\n",
    "        try:\n",
    "            response = llm.get_completion_from_messages(prompt=query, temperature=0.1, max_tokens=100)\n",
    "        except Exception:\n",
    "            print(Exception)\n",
    "            continue\n",
    "        result = str(response).strip().split(\"\\n\")\n",
    "        questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "        ]\n",
    "        questions = [question for question in questions if len(question) > 0]\n",
    "\n",
    "        for question in questions:\n",
    "            question_id = str(uuid.uuid4())\n",
    "            queries[question_id] = question\n",
    "            relevant_docs[question_id] = [node_id]\n",
    "\n",
    "    # construct dataset\n",
    "    return EmbeddingQAFinetuneDataset(\n",
    "        queries=queries, corpus=corpus, relevant_docs=relevant_docs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8bcf9098-d5ad-43d2-998c-4047f9b8afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT_Turbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a1bf5382-1731-4d22-afe0-9e767a48748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbf46feed464cdc9e21cdcbb9af0d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 716 ms, sys: 30.4 ms, total: 747 ms\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testqa = generate_qa_embedding_pairs(train_nodes, gpt, qa_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9ee1f982-b8e0-4713-8a25-c74b35564478",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainqa = testqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d6a02a2f-1f20-42f0-b70f-beb20f52ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "testqa.save_json('train_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "910611c4-f318-4818-a242-3c5173ca41b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4937665c0c154143bc5763bfcfbcb98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validqa = generate_qa_embedding_pairs(val_nodes, gpt , qa_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2c7a1359-0bc3-4d2e-8020-ea4788b86653",
   "metadata": {},
   "outputs": [],
   "source": [
    "validqa.save_json('valid_dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde1892-e22e-4291-ba6b-a8209f3d9c45",
   "metadata": {},
   "source": [
    "# 3. Fine Tune Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eed61ac2-160e-4ffd-a293-81c7f6678587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "model_path = 'sentence-transformers/all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6c74eb06-9b96-4756-8ff5-076bf8c4eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    trainqa,\n",
    "    batch_size=32,\n",
    "    model_id=model_path,\n",
    "    model_output_path=\"fine_tuned_minilm\",\n",
    "    val_dataset=validqa,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c0d73b14-de31-4ae2-b5a0-977d8d6fd00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dae51e8d3a14b8c90ec62e4f7f98491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa3c5cff6b34abe9f827a9d9dceb503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716d6bab4203455aa6cd31ad7acad98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca003ecbef924ebf9ec898072824c7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d527b944894feda52c2ed7c6d905a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfd57e9b5034a7b9b10d27db6dbd6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa6fb1752b147bfbd1b5571114414a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6f1f5616e543589e71d367654fcae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdedc59677544bb893ce2cb8a269165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859478e729b348c9b337783bfe2cafa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2467c6b62b41baa9c4042244974fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1476216eabe847b599db1bce8ccb81a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9a5a518e5a492ead21bb7f15364b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b6a9296c7f4108ac1a2fa524769ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6157204852045128aeb4c9a43244fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263f4d8f45424c209c4c209fe5c6d6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 1.21 s, total: 20.1 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8a43411a-f8c2-461e-bd37-4e6376a8762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1e60250b-10fc-462c-844d-239fa6b0488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "018d97c5-27d8-4f4a-b2eb-e04646977c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b16fa725-f5de-42dd-9274-12f0e0995240",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = SentenceTransformer('./fine_tuned_minilm/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384c53f-1840-41d9-979a-9ca24e40d339",
   "metadata": {},
   "source": [
    "# Evaluate Model on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "39a18a1b-b7ec-47ba-81ee-87de8c575141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import OpenAIEmbedding, HuggingFaceEmbedding\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# function for hit rate evals\n",
    "def evaluate(\n",
    "    dataset: EmbeddingQAFinetuneDataset,\n",
    "    embed_model,\n",
    "    top_k=1,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
    "    index = VectorStoreIndex(nodes, service_context=service_context, show_progress=True)\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
    "\n",
    "        eval_result = {\n",
    "            \"is_hit\": is_hit,\n",
    "            \"retrieved\": retrieved_ids,\n",
    "            \"expected\": expected_id,\n",
    "            \"query\": query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8ab84ce0-bd88-46b6-bb2c-a52f1ecda0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='sentence-transformers/all-MiniLM-L6-v2', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7f4e9a31b370>, tokenizer_name='sentence-transformers/all-MiniLM-L6-v2', max_length=512, pooling='cls', query_instruction=None, text_instruction=None, cache_folder=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minilm = SentenceTransformer(model_path)\n",
    "minilm = HuggingFaceEmbedding(model_path)\n",
    "minilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a7de6478-6cca-44e7-b0d4-0943a918cd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6154b0ac3a249148754f582c0ec62b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9eafee83e854614b425af7b390bca00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = evaluate(validqa, minilm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "289b7783-47f8-4353-8e64-31861ff21933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7b69031a-6dae-45d9-8a94-7649bc56f784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([d['is_hit'] for d in eval_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "be13cb15-759f-40c6-9a77-cffdafdcfc1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'EmbeddingQAFinetuneDataset' and 'EmbeddingQAFinetuneDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[225], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainqa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidqa\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'EmbeddingQAFinetuneDataset' and 'EmbeddingQAFinetuneDataset'"
     ]
    }
   ],
   "source": [
    "trainqa + validqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bab3a-b5d8-4fca-8321-7c5d2c045633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
