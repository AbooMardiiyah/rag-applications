{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b201b4c9-b3a4-46ea-9fda-3a026c1d1265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "    \n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from preprocessing import FileIO\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.node_parser import NodeParser, SimpleNodeParser\n",
    "from llama_index import Document\n",
    "from llama_index.schema import TextNode\n",
    "from tqdm.notebook import tqdm\n",
    "from openai_interface import GPT_Turbo\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067317f-3cc2-4e15-9f9f-d155e4b691a1",
   "metadata": {},
   "source": [
    "# 1. Data Ingest and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534bd78a-7ecd-4bc0-bdfb-12b8beda5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/impact_theory_data.json'\n",
    "parquet_path = './data/impact_theory_minilm_256.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcde62ba-5e15-436d-b5b0-12e32514b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d797bd8d-ad32-4a61-b7d3-945017108ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (26448, 12)\n",
      "Memory Usage: 2.42+ MB\n"
     ]
    }
   ],
   "source": [
    "parquet = FileIO().load_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c273fb-97ed-4817-92e5-299bd13986f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(data: List[dict]) -> List[Document]:\n",
    "    '''\n",
    "    Given a dataset of a list of dictionaries converts each dict \n",
    "    to a llama_index Document and returns a List of Documents.\n",
    "    '''\n",
    "    docs = []\n",
    "    for d in tqdm(data):\n",
    "        unwanted_fields = ['content', 'content_embedding']\n",
    "        emb = d['content_embedding']\n",
    "        content=d['content']\n",
    "        meta = {k:v for k,v in d.items() if k not in unwanted_fields}\n",
    "        doc = Document(embedding=emb, metadata=meta, text=content, excluded_embed_metadata_keys=list(meta.keys()))\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bda2742f-ddfc-4c17-bdc3-07716dfb137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_nodes(data: List[dict]) -> List[TextNode]:\n",
    "    '''\n",
    "    Given a dataset of a list of dictionaries converts each dict \n",
    "    to a llama_index Document and returns a List of Documents.\n",
    "    '''\n",
    "    docs = []\n",
    "    for d in tqdm(data):\n",
    "        unwanted_fields = ['content', 'content_embedding']\n",
    "        emb = d['content_embedding']\n",
    "        content=d['content']\n",
    "        meta = {k:v for k,v in d.items() if k not in unwanted_fields}\n",
    "        doc = TextNode(embedding=emb, metadata=meta, text=content, excluded_embed_metadata_keys=list(meta.keys()))\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6a0035a-b3dc-45f0-acb0-653cf4891b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad32f2b8eda946e98a0c637c18d45d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = create_documents(parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7424db73-3ecd-42c4-9a1d-3061d71bb675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7396da31f94c25ae7160185db9a657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = create_text_nodes(parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b066f2eb-fe30-47e4-95f2-215600123670",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/elastic/notebooks/vsa_practice/practice_data/individual_jsons_vectors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4389f30-dd80-43d7-b56f-a2b07473c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_json_files(data: List[dict], output_dir: str=output_dir) -> None:\n",
    "    '''\n",
    "    Given a dataset consisting of a list of dicts i.e. one dict\n",
    "    per pdocast episode, function will save each episode (dict)\n",
    "    to disk in json format.\n",
    "    '''\n",
    "    for i, d in enumerate(data, 1):\n",
    "        try:\n",
    "            video_id = d['video_id']\n",
    "            filename = f'{video_id}_Episode_{i}.json'\n",
    "            path = os.path.join(output_dir, filename)\n",
    "            with open(path, 'w') as f:\n",
    "                json.dump(d, f)\n",
    "        except Exception:\n",
    "            print(Exception)\n",
    "            continue\n",
    "            \n",
    "    print(f'Completed saving {i} json files')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d651dc2-97f1-4098-b5e7-c1d01ee70e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_individual_json_files(parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859dca8f-0ffa-47d8-a33e-8e50dc5dbacd",
   "metadata": {},
   "source": [
    "# 2. Question Answer Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5922ed5-7f51-46e1-b734-220680edd48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.finetuning import (\n",
    "    generate_qa_embedding_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "import openai\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a77d7ce3-7b55-4202-b8ca-5a6a7c623a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a7f50be-961c-45d9-84c6-6cfc5ad722da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def train_val_split(n_train_questions: int, \n",
    "                    n_val_questions: int, \n",
    "                    nodes: List[TextNode], \n",
    "                    n_questions_per_chunk: int=2):\n",
    "    training_data = deepcopy(nodes)\n",
    "    random.shuffle(training_data)\n",
    "    train_index = n_train_questions//n_questions_per_chunk\n",
    "    valid_index = n_val_questions//n_questions_per_chunk\n",
    "    train_nodes = training_data[:train_index]\n",
    "    valid_nodes = training_data[train_index:valid_index + train_index]\n",
    "    print(f'Length Training Nodes: {len(train_nodes)}')\n",
    "    print(f'Length Validation Nodes: {len(valid_nodes)}')\n",
    "    return train_nodes, valid_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3172f460-2b42-4417-a36a-cdb5ede31329",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_questions = 250\n",
    "num_valid_questions = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e0f2b24-0e9c-40a9-bc61-29a5b1c3d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Training Nodes: 125\n",
      "Length Validation Nodes: 50\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set = train_val_split(250, 100, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72b3e9c4-7e58-4e8f-8dc5-2c8aec0821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model='gpt-3.5-turbo-0613')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335be4f3-b7b8-4bd4-a93e-8a4517fe194c",
   "metadata": {},
   "source": [
    "### 250 Questions Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fa464-4627-4241-9a29-c218334c9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = generate_qa_embedding_pairs(train_nodes, llm=llm, num_questions_per_chunk=1)\n",
    "# val_dataset = generate_qa_embedding_pairs(val_nodes, num_questions_per_chunk=1)\n",
    "\n",
    "# train_dataset.save_json(\"train_dataset.json\")\n",
    "# val_dataset.save_json(\"val_dataset.json\")\n",
    "\n",
    "# train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
    "# val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e273e45-53be-4db3-9338-fac9421bcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import MetadataMode, TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6712f4b5-a9af-49df-8bfd-e99f4a532993",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_prompt = '''\n",
    "Show summary and show guest are below.\n",
    "\n",
    "---------------------\n",
    "Summary: {summary}\n",
    "---------------------\n",
    "Guest: {guest}\n",
    "---------------------\n",
    "Given the show Summary and Guest of the show as context \\\n",
    "use the following randomly selected transcript section \\  \n",
    "of the show and not prior knowledge, generate questions that can \\\n",
    "be answered by the transcript section: \n",
    "\n",
    "---------------------\n",
    "{transcript}\n",
    "---------------------\n",
    "\n",
    "Your task is to create {num_questions_per_chunk} questions that can \\\n",
    "only be answered given the previous context and transcript details. \\\n",
    "When possible try to use questions that start with How or Why.  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c257971-268d-4f5e-b980-c31548ded315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PeK9EeKNXDM_11'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0].metadata['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08604ace-c4aa-47f4-954f-986ae9cac191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_embedding_pairs(\n",
    "    nodes: List[TextNode],\n",
    "    llm: GPT_Turbo,\n",
    "    qa_generate_prompt_tmpl: str,\n",
    "    num_questions_per_chunk: int = 2,\n",
    ") -> EmbeddingQAFinetuneDataset:\n",
    "    \"\"\"Generate examples given a set of nodes.\"\"\"\n",
    "   \n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    corpus = {node.metadata['doc_id'] : node.get_text() for node in nodes}\n",
    "    for node in tqdm(nodes):\n",
    "        summary = node.metadata['summary']\n",
    "        guest = node.metadata['guest']\n",
    "        transcript = node.get_text() \n",
    "        node_id = node.metadata['doc_id']\n",
    "        query = qa_generate_prompt_tmpl.format(summary=summary, \n",
    "                                               guest=guest,\n",
    "                                               transcript=transcript,\n",
    "                                               num_questions_per_chunk=num_questions_per_chunk)\n",
    "        try:\n",
    "            response = llm.get_completion_from_messages(prompt=query, temperature=0.1, max_tokens=100)\n",
    "        except Exception:\n",
    "            print(Exception)\n",
    "            continue\n",
    "        result = str(response).strip().split(\"\\n\")\n",
    "        questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "        ]\n",
    "        questions = [question for question in questions if len(question) > 0]\n",
    "\n",
    "        for question in questions:\n",
    "            question_id = str(uuid.uuid4())\n",
    "            queries[question_id] = question\n",
    "            relevant_docs[question_id] = [node_id]\n",
    "\n",
    "    # construct dataset\n",
    "    return EmbeddingQAFinetuneDataset(\n",
    "        queries=queries, corpus=corpus, relevant_docs=relevant_docs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bcf9098-d5ad-43d2-998c-4047f9b8afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT_Turbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1bf5382-1731-4d22-afe0-9e767a48748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8722fa96fe494e7bb870798c92167a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 618 ms, sys: 58.1 ms, total: 676 ms\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qa = generate_qa_embedding_pairs(train_set, gpt, qa_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6a02a2f-1f20-42f0-b70f-beb20f52ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa.save_json('training_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "910611c4-f318-4818-a242-3c5173ca41b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a2a1b1a0b7470db89565c09eebf917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_qa = generate_qa_embedding_pairs(valid_set, gpt , qa_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c7a1359-0bc3-4d2e-8020-ea4788b86653",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_qa.save_json('validation_dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde1892-e22e-4291-ba6b-a8209f3d9c45",
   "metadata": {},
   "source": [
    "# 3. Fine Tune Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eed61ac2-160e-4ffd-a293-81c7f6678587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "model_path = 'sentence-transformers/all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c74eb06-9b96-4756-8ff5-076bf8c4eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_qa,\n",
    "    batch_size=32,\n",
    "    model_id=\"fine_tuned_minilm\",\n",
    "    model_output_path=\"new_ft_model\",\n",
    "    val_dataset=valid_qa,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0d73b14-de31-4ae2-b5a0-977d8d6fd00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd224d8cfc7488fac0c3caa189833ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ba14c8ad63424399e8408ac10f5dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1f2a1b7363494eb5fa8556a3342402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a7d5c510b842e7b6b6772bd8392d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b06f03cefa64dcbbef89a72657bafa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a963e67a7a4ee684c16dbb19277a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c7facaf049432c9f8377232bfa5fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc226cb5d9bd47628c7f23658dac60d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3145d8498d4e475d82d113eb830a85c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f0268daf2d41aea54276668706100b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745854f44330464ebdb7e6896d3a4dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1d76eefa204c44acbba3b0be412f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e67f2c75be5456fb6841b603e2b31e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dca0e2ab5a4147a57186c3fcc74b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3f75824baa402d8271aad0965dee9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e3a144c2ef46c09ab9f6d4b09c4681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 1.1 s, total: 21.1 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8a43411a-f8c2-461e-bd37-4e6376a8762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1e60250b-10fc-462c-844d-239fa6b0488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "018d97c5-27d8-4f4a-b2eb-e04646977c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b16fa725-f5de-42dd-9274-12f0e0995240",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = SentenceTransformer('./new_ft_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384c53f-1840-41d9-979a-9ca24e40d339",
   "metadata": {},
   "source": [
    "# Evaluate Model on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd899619-e14a-435e-bd57-2712ce82a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e21036196649a99cb18b109f897985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing = [TextNode(id_=node.metadata['doc_id'], text=node.get_text()) for node in tqdm(nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5680b7f0-1973-40d3-bf3c-54b5c5f177b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='nXJBccSwtB8_0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='18b2e122be4b09e3d0cc93aa4f09b594b0c2e7343d3de626575cf49e906de4b7', text=\"You said these are dangerous times. The world order is shifting before our eyes. We also both know that with hyper disruptive technologies like AI on the horizon, a good outcome is not guaranteed. Why do you think big tech will become the third superpower and what are the dangers and opportunities if it does? Big tech is essentially sovereign over the digital world. The fact that former President Trump was de-platformed from Facebook and from Twitter when he was president, you know, most powerful political figure on the planet. And he's just taken off of those networks and as a consequence, hundreds of millions of people that would be regularly engaging with him in real time suddenly can't see it. That wasn't a decision that was made by a government. It wasn't a decision made by a judge or by a regulatory authority or even by a multinational organization like, you know, the UN. It was made by individuals that own tech companies. The same thing is true in the decision to help Ukraine in the war. In the early days, the U.S. didn't provide much military support.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39a18a1b-b7ec-47ba-81ee-87de8c575141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import OpenAIEmbedding, HuggingFaceEmbedding\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# function for hit rate evals\n",
    "def evaluate(\n",
    "    dataset: EmbeddingQAFinetuneDataset,\n",
    "    full_corpus: List[TextNode],\n",
    "    embed_model: HuggingFaceEmbedding,\n",
    "    top_k=3,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "    nodes = [TextNode(id_=node.metadata['doc_id'], text=node.get_text()) for node in tqdm(full_corpus, 'Text Nodes')]\n",
    "    index = VectorStoreIndex(nodes, service_context=service_context, show_progress=True)\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items(), \"Submitting Queries\"):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
    "\n",
    "        eval_result = {\n",
    "            \"is_hit\": is_hit,\n",
    "            \"retrieved\": retrieved_ids,\n",
    "            \"expected\": expected_id,\n",
    "            \"query\": query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ab84ce0-bd88-46b6-bb2c-a52f1ecda0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='./new_ft_model/', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7feb681a5d30>, tokenizer_name='./new_ft_model/', max_length=512, pooling='cls', query_instruction=None, text_instruction=None, cache_folder=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minilm = HuggingFaceEmbedding('./new_ft_model/')\n",
    "minilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7de6478-6cca-44e7-b0d4-0943a918cd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405458b94e9f4848a6ee8b7f847712a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text Nodes:   0%|          | 0/26448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be1bd8b16614191b6f3ef41e05d0669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/26448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2e110f20f44beabd211ac4d63568a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Submitting Queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = evaluate(valid_qa, nodes, minilm, top_k=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "289b7783-47f8-4353-8e64-31861ff21933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe4bab3a-b5d8-4fca-8321-7c5d2c045633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'`\\x14:\\x0e+\\xf8\\xea,\\xe6\\xea]c\\xe8DD7q\\x07 \\xafT\\xbb\\x8d\\x0f\\xa3\\xdea\\xabl\\xf7h\\\\.t{\\xcb\\xf5i`\\x07\\x9bN7<\\x02\\xa1\\x08S\\x03Z~\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07', b'\\x08\\t\\x08\\n\\x08\\x0b\\x08']\n",
      "Bad pipe message: %s [b'\\x05\\x08\\x06']\n",
      "Bad pipe message: %s [b'\\x05\\x01\\x06', b'']\n",
      "Bad pipe message: %s [b'\\xdc\\x92\\x83\\xeb\\x97\\xf7(Oa\\x8a\\xc8\\xa0?\\r&\\xd28\\xf6 \\x1c\\xfb\\t+\\xd6\\xa4\\x9cu\\x98\\xcd\\x13\\xbbX\\xef\\xe8$o\\xb2>t\\x15\\x87\\xfez\\xcf\\xe1~\\x04C\\xc4\\xbeL\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 rN\\x08']\n",
      "Bad pipe message: %s [b'P\\x9ao\\xb4\\xfdX\\xfb\\x06\\x94\\xf9_r\"\\xc3Q, \\xca\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0\\'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03']\n",
      "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 _\\r\\xf2/\\xa2\\x8950.8\\xfeA\\x7f\\xf8\\xc4.\\xf3\\xb0K\\xb6A\\xab']\n",
      "Bad pipe message: %s [b'\\x02\\x01', b'\\x02\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\xbe\\x10y\\xfa\\xc7H\\x07\\x0c\\xc7M{\\x8a\\x99h\\xf5\\x81\\xe6)\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00']\n",
      "Bad pipe message: %s [b'\\x04\\x00\\xff\\x02']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'Z\\x93\\xbc\\x9c\\x19D?\\\\\\xd3Q\\x1d\\xdah\"\\x03!\\xb1\\x18\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00']\n",
      "Bad pipe message: %s [b'C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f']\n",
      "Bad pipe message: %s [b'\\x963I5\\xfa\\xe8Z:\\x1b>^\\xb1n\\\\\\xdc\\xe8\\xde\\t\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x15\\x03\\x00\\x00\\x02\\x02']\n",
      "Bad pipe message: %s [b'\\xb1\\xa4\\xe0\\xde\\x902{\\xd7\\x990\\xce\\xf5w\\x00U\\x8a\\x07\\x95\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00']\n",
      "Bad pipe message: %s [b'\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0']\n",
      "Bad pipe message: %s [b'\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00']\n",
      "Bad pipe message: %s [b\"\\xf7-\\xcd\\xfe\\x9a\\xe3\\xfd\\x07\\xb0\\x9c\\xe6\\xdcl\\xf9vz\\x11\\x9c\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\"]\n"
     ]
    }
   ],
   "source": [
    "sum([d['is_hit'] for d in eval_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60879b-7442-48e3-a85c-e8abfdf73571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
